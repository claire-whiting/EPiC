{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3588DgWyYJGg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount GDrive to access GDrive files\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldl0my8zej2S",
        "outputId": "a3d1224d-33f8-49bc-8f87-d446dd492d09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory\n",
        "os.chdir(\"/content/gdrive/Shareddrives/emo-challenge\")"
      ],
      "metadata": {
        "id": "qldrmMdCeka1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check working directory (should be .../emo-challenge)\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8llqNqJse_on",
        "outputId": "bd5f5bcf-3fb2-4a76-dee1-67674069ddcc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/Shareddrives/emo-challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Load in training data - separately assembled\n",
        "\n",
        "annot = pd.read_csv(\"data/scenario_1/train/annotations_train.csv\")\n",
        "\n",
        "phys = pd.read_csv('data/scenario_1/train/physiology_train.csv')"
      ],
      "metadata": {
        "id": "rhAhn9_7d7E3"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Load in test data - modified provided function\n",
        "\n",
        "def load_data_no_folds(scenario_dir_path, dataset_type):\n",
        "    # make dict to store data\n",
        "    storage_list = list()\n",
        "    # make paths for the specified dataset\n",
        "    train_annotations_dir = Path(scenario_dir_path, dataset_type, \"annotations\")\n",
        "    train_physiology_dir = Path(scenario_dir_path, dataset_type, \"physiology\")\n",
        "    # sort contents of dirs, so that physiology and annotations are in the same order  \n",
        "    train_physiology_files = sorted([f for f in Path(train_physiology_dir).iterdir()])\n",
        "    train_annotation_files = sorted([f for f in Path(train_annotations_dir).iterdir()])\n",
        "\n",
        "    #print(train_physiology_files)\n",
        "    #print(train_annotation_files)\n",
        "    # iterate over annotation and physiology files\n",
        "    full_df = pd.DataFrame()\n",
        "    for physiology_file_path, annotations_file_path in zip(train_physiology_files, train_annotation_files):\n",
        "        # make sure that we load corresponding physiology and annotations\n",
        "        #print(physiology_file_path)\n",
        "        #print(annotations_file_path)\n",
        "        assert physiology_file_path.name == annotations_file_path.name, \"Order mismatch\"\n",
        "        # load data from files\n",
        "        df_physiology = pd.read_csv(physiology_file_path, index_col=\"time\")\n",
        "        df_annotations = pd.read_csv(annotations_file_path, index_col=\"time\")\n",
        "\n",
        "        split_name = annotations_file_path.name.split('.')[0].split('_')\n",
        "        sub_no = split_name[1]\n",
        "        vid_no = split_name[3]\n",
        "\n",
        "        current_df = pd.merge(df_physiology, df_annotations, on=\"time\", how=\"outer\")\n",
        "        current_df[\"sub\"] = [sub_no] * len(current_df)\n",
        "        current_df[\"vid\"] = [vid_no] * len(current_df)\n",
        "        \n",
        "        full_df = pd.concat([full_df, current_df], ignore_index=True)\n",
        "       \n",
        "        #continue # comment / delete this line if you want to store data in data_store list\n",
        "        # store data\n",
        "        #storage_list.append((annotations_file_path.name, df_physiology, df_annotations))\n",
        "        \n",
        "    \n",
        "    return full_df\n",
        "      \n",
        "# specify scenario path\n",
        "scenario_dir = \"data/scenario_1\"\n",
        "\n",
        "# train data\n",
        "#print(\"Loading train data\")\n",
        "#load_data_no_folds(scenario_dir, \"train\")\n",
        "\n",
        "# test data\n",
        "print(\"Loading test data\")\n",
        "test_data = load_data_no_folds(scenario_dir, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoHdiEa3jjvM",
        "outputId": "5fe61932-30d0-41bc-dad9-f6329c33a73b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Save assembled test data  for later\n",
        "\n",
        "test_data.to_csv('data/scenario_1/test/test_data.csv')"
      ],
      "metadata": {
        "id": "p7FlHE1x1k02"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkDnhYlSOYpn"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YVUYM3ryOayL"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "##### TRAINING DATA PROCESSING ######\n",
        "#####################################\n",
        "\n",
        "# Initialize training and validation datasets with zeros\n",
        "X_train = np.zeros((240,2238,4600))\n",
        "Y_train = np.zeros((240,2238,2))\n",
        "X_val = np.zeros((240,300,4600))\n",
        "Y_val = np.zeros((240,300,2))\n",
        "\n",
        "# Set window size and define maximum number of windows\n",
        "window_size = 100\n",
        "max_n_windows = 2538\n",
        "\n",
        "for s,sub in enumerate(list(set(annot['sub']))):\n",
        "    for v,vid in enumerate(list(set(annot['vid']))):\n",
        "\n",
        "        # Load physiological data\n",
        "        phys_data = np.array(phys.loc[phys['sub']==sub].loc[phys['vid']==vid].iloc[:,2:10])\n",
        "\n",
        "        # Create one-hot encodings for subject and video\n",
        "        one_hot = np.zeros((len(phys_data),38))\n",
        "        one_hot[:,s] = 1\n",
        "        one_hot[:,30+v] = 1\n",
        "\n",
        "        # Stack phys data with one-hot\n",
        "        phys_data = np.column_stack((phys_data,one_hot))\n",
        "        \n",
        "        # Load ratings of valence and arousal\n",
        "        ratings = np.array(annot.loc[annot['sub']==sub].loc[annot['vid']==vid][['valence','arousal']])\n",
        "        \n",
        "        # Stack physiological data and one-hot with ratings across time - define time windows\n",
        "        num_windows = ratings.shape[0] - 2\n",
        "        stacked_data = np.zeros((num_windows, int(46*window_size)+2))\n",
        "        for i in range(num_windows):\n",
        "            stacked_data[i] = np.hstack((phys_data[50*i:50*(i+2)].flatten(), ratings[i]))\n",
        "\n",
        "        # Assign batch to the full dataset with pre-padding (leaving 0s in the beginning)\n",
        "        # Also, use last 300 ratings (15s) as validation set\n",
        "        X_train[s*8+v][(max_n_windows-num_windows):][:] = stacked_data[:-300,:-2]\n",
        "        X_val[s*8+v][:][:] = stacked_data[-300:,:-2]\n",
        "\n",
        "        Y_train[s*8+v][(max_n_windows-num_windows):][:] = stacked_data[:-300,-2:]\n",
        "        Y_val[s*8+v][:][:] = stacked_data[-300:,-2:]\n",
        "        #break\n",
        "    #break"
      ],
      "metadata": {
        "id": "aZ4fswlAByKa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Save subject and video orderings to match the test data\n",
        "\n",
        "sub_list_train = list(set(annot['sub']))\n",
        "\n",
        "vid_list_train = list(set(annot['vid']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC6LK_Sm9Gig",
        "outputId": "fff5ca4d-a984-48e5-fe75-41c029444f47"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12',\n",
              " '33',\n",
              " '32',\n",
              " '18',\n",
              " '34',\n",
              " '22',\n",
              " '8',\n",
              " '31',\n",
              " '4',\n",
              " '6',\n",
              " '35',\n",
              " '37',\n",
              " '9',\n",
              " '30',\n",
              " '41',\n",
              " '13',\n",
              " '14',\n",
              " '43',\n",
              " '17',\n",
              " '1',\n",
              " '29',\n",
              " '26',\n",
              " '19',\n",
              " '7',\n",
              " '11',\n",
              " '28',\n",
              " '36',\n",
              " '45',\n",
              " '38',\n",
              " '20']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################\n",
        "##### TEST DATA PROCESSING ######\n",
        "#####################################\n",
        "\n",
        "# Initialize test dataset - only features\n",
        "X_test = np.zeros((240,601,4600))\n",
        "window_size = 100\n",
        "\n",
        "for s,sub in enumerate(sub_list_train):\n",
        "    for v,vid in enumerate(vid_list_train):\n",
        "        print('Subject #',sub,'; video #',vid)\n",
        "        \n",
        "        # Load physiological data\n",
        "        phys_data = np.array(test_data.loc[test_data['sub']==str(sub)].loc[test_data['vid']==str(vid)].iloc[9950:40050,:8])\n",
        "\n",
        "        # Create one-hot encodings for subject and video\n",
        "        one_hot = np.zeros((len(phys_data),38))\n",
        "        one_hot[:,s] = 1\n",
        "        one_hot[:,30+v] = 1\n",
        "\n",
        "        # Combine the two\n",
        "        phys_data = np.column_stack((phys_data,one_hot))\n",
        "        \n",
        "        \n",
        "        # Create sliding windows\n",
        "        num_windows = 601\n",
        "        stacked_data = np.zeros((num_windows, int(46*window_size)))\n",
        "        for i in range(num_windows):\n",
        "            stacked_data[i] = phys_data[50*i:50*(i+2)].flatten()\n",
        " \n",
        "\n",
        "        # Add sliding windows data to the larger dataset\n",
        "        X_test[s*8+v][:][:] = stacked_data\n",
        "        #break\n",
        "    #break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLFO_TJx7p3B",
        "outputId": "c37de35c-41e9-4c9f-b3dc-8b1524b88682"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject # 1 ; video # 1\n",
            "Subject # 1 ; video # 9\n",
            "Subject # 1 ; video # 10\n",
            "Subject # 1 ; video # 11\n",
            "Subject # 1 ; video # 13\n",
            "Subject # 1 ; video # 14\n",
            "Subject # 1 ; video # 18\n",
            "Subject # 1 ; video # 20\n",
            "Subject # 4 ; video # 1\n",
            "Subject # 4 ; video # 9\n",
            "Subject # 4 ; video # 10\n",
            "Subject # 4 ; video # 11\n",
            "Subject # 4 ; video # 13\n",
            "Subject # 4 ; video # 14\n",
            "Subject # 4 ; video # 18\n",
            "Subject # 4 ; video # 20\n",
            "Subject # 6 ; video # 1\n",
            "Subject # 6 ; video # 9\n",
            "Subject # 6 ; video # 10\n",
            "Subject # 6 ; video # 11\n",
            "Subject # 6 ; video # 13\n",
            "Subject # 6 ; video # 14\n",
            "Subject # 6 ; video # 18\n",
            "Subject # 6 ; video # 20\n",
            "Subject # 7 ; video # 1\n",
            "Subject # 7 ; video # 9\n",
            "Subject # 7 ; video # 10\n",
            "Subject # 7 ; video # 11\n",
            "Subject # 7 ; video # 13\n",
            "Subject # 7 ; video # 14\n",
            "Subject # 7 ; video # 18\n",
            "Subject # 7 ; video # 20\n",
            "Subject # 8 ; video # 1\n",
            "Subject # 8 ; video # 9\n",
            "Subject # 8 ; video # 10\n",
            "Subject # 8 ; video # 11\n",
            "Subject # 8 ; video # 13\n",
            "Subject # 8 ; video # 14\n",
            "Subject # 8 ; video # 18\n",
            "Subject # 8 ; video # 20\n",
            "Subject # 9 ; video # 1\n",
            "Subject # 9 ; video # 9\n",
            "Subject # 9 ; video # 10\n",
            "Subject # 9 ; video # 11\n",
            "Subject # 9 ; video # 13\n",
            "Subject # 9 ; video # 14\n",
            "Subject # 9 ; video # 18\n",
            "Subject # 9 ; video # 20\n",
            "Subject # 11 ; video # 1\n",
            "Subject # 11 ; video # 9\n",
            "Subject # 11 ; video # 10\n",
            "Subject # 11 ; video # 11\n",
            "Subject # 11 ; video # 13\n",
            "Subject # 11 ; video # 14\n",
            "Subject # 11 ; video # 18\n",
            "Subject # 11 ; video # 20\n",
            "Subject # 12 ; video # 1\n",
            "Subject # 12 ; video # 9\n",
            "Subject # 12 ; video # 10\n",
            "Subject # 12 ; video # 11\n",
            "Subject # 12 ; video # 13\n",
            "Subject # 12 ; video # 14\n",
            "Subject # 12 ; video # 18\n",
            "Subject # 12 ; video # 20\n",
            "Subject # 13 ; video # 1\n",
            "Subject # 13 ; video # 9\n",
            "Subject # 13 ; video # 10\n",
            "Subject # 13 ; video # 11\n",
            "Subject # 13 ; video # 13\n",
            "Subject # 13 ; video # 14\n",
            "Subject # 13 ; video # 18\n",
            "Subject # 13 ; video # 20\n",
            "Subject # 14 ; video # 1\n",
            "Subject # 14 ; video # 9\n",
            "Subject # 14 ; video # 10\n",
            "Subject # 14 ; video # 11\n",
            "Subject # 14 ; video # 13\n",
            "Subject # 14 ; video # 14\n",
            "Subject # 14 ; video # 18\n",
            "Subject # 14 ; video # 20\n",
            "Subject # 17 ; video # 1\n",
            "Subject # 17 ; video # 9\n",
            "Subject # 17 ; video # 10\n",
            "Subject # 17 ; video # 11\n",
            "Subject # 17 ; video # 13\n",
            "Subject # 17 ; video # 14\n",
            "Subject # 17 ; video # 18\n",
            "Subject # 17 ; video # 20\n",
            "Subject # 18 ; video # 1\n",
            "Subject # 18 ; video # 9\n",
            "Subject # 18 ; video # 10\n",
            "Subject # 18 ; video # 11\n",
            "Subject # 18 ; video # 13\n",
            "Subject # 18 ; video # 14\n",
            "Subject # 18 ; video # 18\n",
            "Subject # 18 ; video # 20\n",
            "Subject # 19 ; video # 1\n",
            "Subject # 19 ; video # 9\n",
            "Subject # 19 ; video # 10\n",
            "Subject # 19 ; video # 11\n",
            "Subject # 19 ; video # 13\n",
            "Subject # 19 ; video # 14\n",
            "Subject # 19 ; video # 18\n",
            "Subject # 19 ; video # 20\n",
            "Subject # 20 ; video # 1\n",
            "Subject # 20 ; video # 9\n",
            "Subject # 20 ; video # 10\n",
            "Subject # 20 ; video # 11\n",
            "Subject # 20 ; video # 13\n",
            "Subject # 20 ; video # 14\n",
            "Subject # 20 ; video # 18\n",
            "Subject # 20 ; video # 20\n",
            "Subject # 22 ; video # 1\n",
            "Subject # 22 ; video # 9\n",
            "Subject # 22 ; video # 10\n",
            "Subject # 22 ; video # 11\n",
            "Subject # 22 ; video # 13\n",
            "Subject # 22 ; video # 14\n",
            "Subject # 22 ; video # 18\n",
            "Subject # 22 ; video # 20\n",
            "Subject # 26 ; video # 1\n",
            "Subject # 26 ; video # 9\n",
            "Subject # 26 ; video # 10\n",
            "Subject # 26 ; video # 11\n",
            "Subject # 26 ; video # 13\n",
            "Subject # 26 ; video # 14\n",
            "Subject # 26 ; video # 18\n",
            "Subject # 26 ; video # 20\n",
            "Subject # 28 ; video # 1\n",
            "Subject # 28 ; video # 9\n",
            "Subject # 28 ; video # 10\n",
            "Subject # 28 ; video # 11\n",
            "Subject # 28 ; video # 13\n",
            "Subject # 28 ; video # 14\n",
            "Subject # 28 ; video # 18\n",
            "Subject # 28 ; video # 20\n",
            "Subject # 29 ; video # 1\n",
            "Subject # 29 ; video # 9\n",
            "Subject # 29 ; video # 10\n",
            "Subject # 29 ; video # 11\n",
            "Subject # 29 ; video # 13\n",
            "Subject # 29 ; video # 14\n",
            "Subject # 29 ; video # 18\n",
            "Subject # 29 ; video # 20\n",
            "Subject # 30 ; video # 1\n",
            "Subject # 30 ; video # 9\n",
            "Subject # 30 ; video # 10\n",
            "Subject # 30 ; video # 11\n",
            "Subject # 30 ; video # 13\n",
            "Subject # 30 ; video # 14\n",
            "Subject # 30 ; video # 18\n",
            "Subject # 30 ; video # 20\n",
            "Subject # 31 ; video # 1\n",
            "Subject # 31 ; video # 9\n",
            "Subject # 31 ; video # 10\n",
            "Subject # 31 ; video # 11\n",
            "Subject # 31 ; video # 13\n",
            "Subject # 31 ; video # 14\n",
            "Subject # 31 ; video # 18\n",
            "Subject # 31 ; video # 20\n",
            "Subject # 32 ; video # 1\n",
            "Subject # 32 ; video # 9\n",
            "Subject # 32 ; video # 10\n",
            "Subject # 32 ; video # 11\n",
            "Subject # 32 ; video # 13\n",
            "Subject # 32 ; video # 14\n",
            "Subject # 32 ; video # 18\n",
            "Subject # 32 ; video # 20\n",
            "Subject # 33 ; video # 1\n",
            "Subject # 33 ; video # 9\n",
            "Subject # 33 ; video # 10\n",
            "Subject # 33 ; video # 11\n",
            "Subject # 33 ; video # 13\n",
            "Subject # 33 ; video # 14\n",
            "Subject # 33 ; video # 18\n",
            "Subject # 33 ; video # 20\n",
            "Subject # 34 ; video # 1\n",
            "Subject # 34 ; video # 9\n",
            "Subject # 34 ; video # 10\n",
            "Subject # 34 ; video # 11\n",
            "Subject # 34 ; video # 13\n",
            "Subject # 34 ; video # 14\n",
            "Subject # 34 ; video # 18\n",
            "Subject # 34 ; video # 20\n",
            "Subject # 35 ; video # 1\n",
            "Subject # 35 ; video # 9\n",
            "Subject # 35 ; video # 10\n",
            "Subject # 35 ; video # 11\n",
            "Subject # 35 ; video # 13\n",
            "Subject # 35 ; video # 14\n",
            "Subject # 35 ; video # 18\n",
            "Subject # 35 ; video # 20\n",
            "Subject # 36 ; video # 1\n",
            "Subject # 36 ; video # 9\n",
            "Subject # 36 ; video # 10\n",
            "Subject # 36 ; video # 11\n",
            "Subject # 36 ; video # 13\n",
            "Subject # 36 ; video # 14\n",
            "Subject # 36 ; video # 18\n",
            "Subject # 36 ; video # 20\n",
            "Subject # 37 ; video # 1\n",
            "Subject # 37 ; video # 9\n",
            "Subject # 37 ; video # 10\n",
            "Subject # 37 ; video # 11\n",
            "Subject # 37 ; video # 13\n",
            "Subject # 37 ; video # 14\n",
            "Subject # 37 ; video # 18\n",
            "Subject # 37 ; video # 20\n",
            "Subject # 38 ; video # 1\n",
            "Subject # 38 ; video # 9\n",
            "Subject # 38 ; video # 10\n",
            "Subject # 38 ; video # 11\n",
            "Subject # 38 ; video # 13\n",
            "Subject # 38 ; video # 14\n",
            "Subject # 38 ; video # 18\n",
            "Subject # 38 ; video # 20\n",
            "Subject # 41 ; video # 1\n",
            "Subject # 41 ; video # 9\n",
            "Subject # 41 ; video # 10\n",
            "Subject # 41 ; video # 11\n",
            "Subject # 41 ; video # 13\n",
            "Subject # 41 ; video # 14\n",
            "Subject # 41 ; video # 18\n",
            "Subject # 41 ; video # 20\n",
            "Subject # 43 ; video # 1\n",
            "Subject # 43 ; video # 9\n",
            "Subject # 43 ; video # 10\n",
            "Subject # 43 ; video # 11\n",
            "Subject # 43 ; video # 13\n",
            "Subject # 43 ; video # 14\n",
            "Subject # 43 ; video # 18\n",
            "Subject # 43 ; video # 20\n",
            "Subject # 45 ; video # 1\n",
            "Subject # 45 ; video # 9\n",
            "Subject # 45 ; video # 10\n",
            "Subject # 45 ; video # 11\n",
            "Subject # 45 ; video # 13\n",
            "Subject # 45 ; video # 14\n",
            "Subject # 45 ; video # 18\n",
            "Subject # 45 ; video # 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del phys, annot, phys_data, ratings, one_hot, stacked_data #to save memory"
      ],
      "metadata": {
        "id": "kfd5BsT7Ytga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data to prepare for timeseries batching - turn 4600 into 100x46 (timepoints x features)\n",
        "X_train = X_train.reshape(240,2238,100,46)\n",
        "y_train = Y_train.reshape(240,2238,2)\n",
        "\n",
        "X_val = X_val.reshape(240,300,100,46)\n",
        "y_val = Y_val.reshape(240,300,2)"
      ],
      "metadata": {
        "id": "_RReYOYoiz9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "2ea52ab7-31e6-4063-8648-c3b2a1c83956"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-a1d9b2eb4173>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reshape data to prepare for timeseries batching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2238\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2238\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape test data in the same way\n",
        "X_test = X_test.reshape(240,601,100,46)"
      ],
      "metadata": {
        "id": "73ycVPu5HTZQ"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X_train) # check shapes"
      ],
      "metadata": {
        "id": "bjkPE2kpZpnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01bcb1f-5677-40e4-d361-8431735c9511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 2538, 100, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBvX2HRmHqLQ",
        "outputId": "93a08668-581d-4da5-cc19-da7849e7844b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 601, 100, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "#### MODEL ARCHITECTURE ####\n",
        "############################\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Masking(mask_value=0.0, input_shape=(100, 46)))\n",
        "model.add(keras.layers.LSTM(units=128))\n",
        "print(model.output_shape)  \n",
        "model.add(keras.layers.Dense(units=2, activation='linear'))\n",
        "print(model.output_shape)  \n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")"
      ],
      "metadata": {
        "id": "xxYwW34TNPD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0bda24-cfa1-421f-eba2-d3a32e7c74dd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 128)\n",
            "(None, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "###### MODEL FITTING #######\n",
        "############################\n",
        "\n",
        "# Create an empty dictionary to store the history\n",
        "history_dict = {}\n",
        "\n",
        "# Create callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"scen1_lstm_128_gradual_epochs.keras\",\n",
        "                                   save_best_only=True)\n",
        "]\n",
        "\n",
        "# Fitting batches serially, one epoch at a time to avoid overfitting (due to resource constraints could not fit in parallel)\n",
        "for e in range(20):\n",
        "  for i in range(240):\n",
        "      model.reset_states()  # reset the LSTM layer state between batches\n",
        "      history = model.fit(X_train[i], y_train[i], batch_size=2238, epochs=1,\n",
        "                        validation_data=(X_val[i], y_val[i]),\n",
        "                        callbacks=callbacks, shuffle=False)\n",
        "      history_dict[f'batch_{i+1}_epoch{e+1}'] = history.history\n",
        "    #break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZkmS-Irfs2T",
        "outputId": "55e44e4c-81ac-4122-bf61-85f2faa1b893"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step - loss: 33.8023 - val_loss: 42.9717\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 7.8196 - val_loss: 18.4646\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 11.7060 - val_loss: 13.2020\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 10.0989 - val_loss: 12.3109\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 10.4905 - val_loss: 23.4407\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 12.1996 - val_loss: 22.4110\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 14.0958 - val_loss: 9.9191\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 8.9793 - val_loss: 16.5886\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 6.1145 - val_loss: 9.2510\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 2.5685 - val_loss: 5.9071\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 5.0974 - val_loss: 3.2141\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 4.7974 - val_loss: 5.9304\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 3.0634 - val_loss: 6.2735\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 8.9724 - val_loss: 4.6040\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 9.0517 - val_loss: 12.0223\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 1.8880 - val_loss: 3.0248\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 2.4885 - val_loss: 3.4857\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.7795 - val_loss: 3.2082\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 1.1548 - val_loss: 1.7753\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 1.1945 - val_loss: 1.4064\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.8394 - val_loss: 2.1041\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 1.4956 - val_loss: 1.1197\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 1.8867 - val_loss: 3.3962\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1584 - val_loss: 0.4351\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 1.4818 - val_loss: 3.0183\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.3494 - val_loss: 3.6988\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3280 - val_loss: 1.3061\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.6298 - val_loss: 8.8419\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 1.4509 - val_loss: 10.8700\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.6077 - val_loss: 1.0220\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 8.2578 - val_loss: 16.8689\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.2051 - val_loss: 1.0120\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.4353 - val_loss: 9.7429\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.3917 - val_loss: 3.1640\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.3980 - val_loss: 0.2841\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.5182 - val_loss: 3.3973\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 1.2048 - val_loss: 1.1619\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 7.7517 - val_loss: 9.6001\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 3.4656 - val_loss: 6.0573\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2372 - val_loss: 0.3476\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 1.4890 - val_loss: 4.8283\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1432 - val_loss: 1.2471\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.6757 - val_loss: 6.5732\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.4029 - val_loss: 8.5587\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 1.3454 - val_loss: 3.8564\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 2.5130 - val_loss: 3.0667\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 12.7472 - val_loss: 19.9579\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.9108 - val_loss: 3.1859\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.7239 - val_loss: 0.9087\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.3930 - val_loss: 2.2978\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 1.4532 - val_loss: 2.4904\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.9006 - val_loss: 2.4119\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.6042 - val_loss: 2.3667\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4339 - val_loss: 0.1154\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 2.1398 - val_loss: 0.7554\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.8265 - val_loss: 1.0216\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.4181 - val_loss: 0.5807\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1449 - val_loss: 0.4575\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.1758 - val_loss: 0.1702\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.3192 - val_loss: 1.2303\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.6779 - val_loss: 2.9286\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 1.0986 - val_loss: 2.3896\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 8.3254 - val_loss: 19.8377\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.3934 - val_loss: 0.3580\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.6978 - val_loss: 0.5932\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.5294 - val_loss: 6.1144\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.1946 - val_loss: 0.3146\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2078 - val_loss: 2.0280\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.8482 - val_loss: 4.2313\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 3.6634 - val_loss: 4.1145\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 8.1328 - val_loss: 17.2871\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1968 - val_loss: 0.6566\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0544 - val_loss: 0.0525\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.1127 - val_loss: 2.2938\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.6701 - val_loss: 1.1808\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.6619 - val_loss: 2.2145\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6439 - val_loss: 0.4157\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 1.5786 - val_loss: 1.9812\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 1.6163 - val_loss: 3.3853\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5737 - val_loss: 0.8336\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 1.1033 - val_loss: 2.9014\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.0955 - val_loss: 0.9387\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 1.1353 - val_loss: 2.4343\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.6616 - val_loss: 1.4441\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0439 - val_loss: 0.8062\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.5568 - val_loss: 0.8302\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 2.0647 - val_loss: 3.1612\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2973 - val_loss: 0.6292\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.4559 - val_loss: 1.0118\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.3349 - val_loss: 3.1048\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.3880 - val_loss: 0.9873\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.7053 - val_loss: 2.4043\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.4602 - val_loss: 1.4728\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3685 - val_loss: 0.5216\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 5.9328 - val_loss: 9.4585\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.2047 - val_loss: 0.5108\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 5.4066 - val_loss: 7.1030\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.0747 - val_loss: 0.9771\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 1.1334 - val_loss: 2.1413\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.4902 - val_loss: 0.6176\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6685 - val_loss: 3.7102\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 1.8926 - val_loss: 2.2059\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 9.9253 - val_loss: 19.1240\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1447 - val_loss: 0.2661\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0425 - val_loss: 0.1513\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0635 - val_loss: 0.4968\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.2195 - val_loss: 0.8830\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.3351 - val_loss: 1.2071\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.3887 - val_loss: 0.9836\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 1.0786 - val_loss: 1.4243\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.2947 - val_loss: 0.6179\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.4349 - val_loss: 1.4484\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.7919 - val_loss: 1.5707\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.1073 - val_loss: 0.3477\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 1.3769 - val_loss: 3.7258\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.8026 - val_loss: 3.1198\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.1497 - val_loss: 1.2413\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 3.8482 - val_loss: 4.1003\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 5.7524 - val_loss: 14.1038\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1628 - val_loss: 0.2489\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.2375 - val_loss: 0.4364\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0800 - val_loss: 0.1998\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1375 - val_loss: 0.1984\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 4.1609 - val_loss: 7.3804\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.1277 - val_loss: 0.1916\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 1.4300 - val_loss: 3.3611\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 7.5519 - val_loss: 18.0029\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0883 - val_loss: 0.1448\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.3604 - val_loss: 1.1594\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.0509 - val_loss: 0.1490\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2546 - val_loss: 0.1107\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 1.2049 - val_loss: 1.4771\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1915 - val_loss: 2.0916\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 4.0642 - val_loss: 3.5723\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 6.3686 - val_loss: 14.7742\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 1.0492 - val_loss: 3.2714\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 1.2877 - val_loss: 0.2231\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2924 - val_loss: 1.1945\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 1.2554 - val_loss: 1.4993\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.1227 - val_loss: 0.7832\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.1297 - val_loss: 0.3675\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.3911 - val_loss: 0.3881\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 2.1231 - val_loss: 3.5247\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1988 - val_loss: 0.4780\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 1.4059 - val_loss: 1.9150\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0390 - val_loss: 0.2327\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0655 - val_loss: 0.4112\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2674 - val_loss: 1.3573\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2008 - val_loss: 1.1849\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 3.6177 - val_loss: 6.8636\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 4.3521 - val_loss: 3.2424\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0080 - val_loss: 0.0185\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0886 - val_loss: 0.8901\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1843 - val_loss: 1.8670\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.7411 - val_loss: 1.6188\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.4862 - val_loss: 2.6677\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0146 - val_loss: 0.5939\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 1.8279 - val_loss: 3.0143\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 2.5387 - val_loss: 2.7288\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.4877 - val_loss: 1.2270\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.7164 - val_loss: 0.6146\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1849 - val_loss: 1.2850\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2993 - val_loss: 0.1671\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 1.2322 - val_loss: 4.1915\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1791 - val_loss: 0.9401\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.5782 - val_loss: 0.4314\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 3.8974 - val_loss: 10.4319\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.4210 - val_loss: 1.7739\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 2.0439 - val_loss: 1.0707\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1338 - val_loss: 0.5361\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 2.7729 - val_loss: 0.5170\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.5669 - val_loss: 1.1405\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.9803 - val_loss: 4.9632\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.1939 - val_loss: 1.7731\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 8.5737 - val_loss: 16.6924\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4588 - val_loss: 2.7260\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2846 - val_loss: 0.2020\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3562 - val_loss: 3.9346\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.1224 - val_loss: 3.9634\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0380 - val_loss: 0.3918\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0528 - val_loss: 0.1180\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0733 - val_loss: 0.0496\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 2.5532 - val_loss: 3.6744\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.0311 - val_loss: 0.0458\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.0962 - val_loss: 0.2562\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.6338 - val_loss: 4.4874\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6092 - val_loss: 1.9892\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 1.8960 - val_loss: 4.2091\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.6039 - val_loss: 1.7672\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.3767 - val_loss: 1.2768\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 4.1898 - val_loss: 10.2693\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.6271 - val_loss: 4.1617\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 7.5628 - val_loss: 5.5185\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 3.3226 - val_loss: 6.2755\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 4.7824 - val_loss: 4.7640\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 3.7680 - val_loss: 6.9260\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 2.8045 - val_loss: 6.5540\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 3.7855 - val_loss: 5.9105\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 8.6588 - val_loss: 8.4400\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.4671 - val_loss: 1.2323\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 3.3879 - val_loss: 0.2820\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.0653 - val_loss: 0.2340\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.8872 - val_loss: 5.3627\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.8307 - val_loss: 2.8697\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.4089 - val_loss: 0.3031\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.7193 - val_loss: 0.9899\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 2.4452 - val_loss: 6.5452\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 2.9774 - val_loss: 15.8380\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.6589 - val_loss: 1.2841\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.1034 - val_loss: 0.8210\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.8744 - val_loss: 1.3930\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.6120 - val_loss: 3.8610\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5718 - val_loss: 1.8881\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2563 - val_loss: 0.4928\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 3.8157 - val_loss: 8.4493\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2391 - val_loss: 0.2799\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0575 - val_loss: 0.0589\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0412 - val_loss: 0.1230\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2051 - val_loss: 0.1000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.1946 - val_loss: 0.1995\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0529 - val_loss: 0.0768\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1432 - val_loss: 0.3138\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.1769 - val_loss: 0.6887\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1121 - val_loss: 0.2515\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.6735 - val_loss: 0.9347\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.1110 - val_loss: 0.7055\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2949 - val_loss: 0.0178\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2243 - val_loss: 0.3257\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2983 - val_loss: 2.2148\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2656 - val_loss: 0.4796\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 1.2141 - val_loss: 3.6486\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2024 - val_loss: 0.0631\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.1461 - val_loss: 0.4504\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.4201 - val_loss: 3.1880\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6413 - val_loss: 3.2390\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 1.6015 - val_loss: 3.7257\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2203 - val_loss: 0.8457\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 1.1646 - val_loss: 1.1612\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 1.3949 - val_loss: 1.9539\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0742 - val_loss: 0.2001\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.8573 - val_loss: 1.4758\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0491 - val_loss: 1.0041\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 2.1622 - val_loss: 4.4963\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3296 - val_loss: 2.5260\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.3765 - val_loss: 2.0971\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.7881 - val_loss: 0.8325\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 2.6866 - val_loss: 3.8041\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2858 - val_loss: 0.6382\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 1.3903 - val_loss: 0.0379\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.0210 - val_loss: 0.3221\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1127 - val_loss: 2.1517\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1554 - val_loss: 0.0260\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0230 - val_loss: 0.1856\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.9105 - val_loss: 0.0228\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 2.9264 - val_loss: 4.9304\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0242 - val_loss: 0.1201\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0881 - val_loss: 0.8520\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.9748 - val_loss: 6.8646\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4179 - val_loss: 1.2426\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.2663 - val_loss: 1.1118\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1373 - val_loss: 0.5878\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2970 - val_loss: 0.5098\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.7964 - val_loss: 2.3275\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.2618 - val_loss: 0.6859\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.7668 - val_loss: 2.3736\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4417 - val_loss: 4.2265\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.4483 - val_loss: 1.6379\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.6867 - val_loss: 8.7137\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 1.1688 - val_loss: 9.5030\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.5635 - val_loss: 1.0872\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 7.6426 - val_loss: 16.1983\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.3764 - val_loss: 1.9290\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.6196 - val_loss: 4.9088\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2610 - val_loss: 2.3667\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.1118 - val_loss: 0.0224\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2002 - val_loss: 2.4476\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.9091 - val_loss: 1.5202\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 5.7546 - val_loss: 7.2018\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 3.3406 - val_loss: 6.1398\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.3370 - val_loss: 1.0397\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 2.3499 - val_loss: 7.3379\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.3645 - val_loss: 1.2146\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 2.8848 - val_loss: 5.6430\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.6989 - val_loss: 7.9480\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.5760 - val_loss: 2.7996\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 4.1546 - val_loss: 5.2064\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 10.6571 - val_loss: 19.2032\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.5212 - val_loss: 1.7050\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2548 - val_loss: 0.1827\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.3108 - val_loss: 2.1445\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.1192 - val_loss: 1.8621\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.9171 - val_loss: 2.3982\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.4980 - val_loss: 1.9640\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.4184 - val_loss: 0.1480\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 2.2604 - val_loss: 0.8607\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.8438 - val_loss: 0.9283\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.5329 - val_loss: 0.4585\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1304 - val_loss: 0.4866\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.2436 - val_loss: 0.2618\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4070 - val_loss: 1.5078\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.5642 - val_loss: 2.5290\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6566 - val_loss: 1.2545\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 7.7031 - val_loss: 18.4805\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.4294 - val_loss: 0.2278\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.4626 - val_loss: 0.0916\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.6925 - val_loss: 7.3632\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.4915 - val_loss: 0.7729\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2073 - val_loss: 2.1450\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 1.9902 - val_loss: 4.1566\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 2.2788 - val_loss: 2.6711\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 8.0189 - val_loss: 16.9085\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2109 - val_loss: 0.5738\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.0347 - val_loss: 0.0347\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.1174 - val_loss: 2.2869\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.6335 - val_loss: 1.0752\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6473 - val_loss: 2.2145\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.6539 - val_loss: 0.4038\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 1.5215 - val_loss: 1.9008\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 1.5489 - val_loss: 3.3067\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.5820 - val_loss: 0.9013\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 1.1211 - val_loss: 2.8725\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0942 - val_loss: 0.8979\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 1.0997 - val_loss: 2.2335\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.6252 - val_loss: 1.4926\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0553 - val_loss: 0.8157\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.5859 - val_loss: 0.7471\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 2.0499 - val_loss: 3.2893\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2781 - val_loss: 0.7091\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.4618 - val_loss: 0.9959\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2928 - val_loss: 2.8360\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.3205 - val_loss: 0.8281\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.6641 - val_loss: 2.3281\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4906 - val_loss: 1.6134\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.3110 - val_loss: 0.4590\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 6.1368 - val_loss: 9.8774\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1681 - val_loss: 0.5137\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 5.5421 - val_loss: 7.6684\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0598 - val_loss: 0.8619\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.1343 - val_loss: 2.1466\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.4605 - val_loss: 0.7605\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.7223 - val_loss: 3.9045\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 1.8475 - val_loss: 2.3495\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 9.9048 - val_loss: 18.8845\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1614 - val_loss: 0.3022\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0507 - val_loss: 0.1081\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.0557 - val_loss: 0.4262\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.1938 - val_loss: 0.8193\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.3152 - val_loss: 1.0962\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.3739 - val_loss: 0.9296\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 1.0253 - val_loss: 1.3061\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2987 - val_loss: 0.5780\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.4177 - val_loss: 1.3695\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.7991 - val_loss: 1.5797\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.1016 - val_loss: 0.3201\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 1.3198 - val_loss: 3.5836\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.7781 - val_loss: 3.0510\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.1448 - val_loss: 1.1996\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 3.7691 - val_loss: 3.9749\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 5.6890 - val_loss: 14.0059\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1580 - val_loss: 0.2386\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.2396 - val_loss: 0.4370\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0755 - val_loss: 0.1799\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.1493 - val_loss: 0.1992\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 3.9748 - val_loss: 7.0072\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.1175 - val_loss: 0.1614\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.4141 - val_loss: 3.3113\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 7.3054 - val_loss: 17.2379\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.1055 - val_loss: 0.1584\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3408 - val_loss: 1.1134\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.0456 - val_loss: 0.1139\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2327 - val_loss: 0.0857\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 1.2016 - val_loss: 1.4440\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.1753 - val_loss: 2.0335\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 3.9089 - val_loss: 3.3649\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 6.1864 - val_loss: 14.5039\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 1.0249 - val_loss: 3.2437\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 1.2415 - val_loss: 0.2110\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2852 - val_loss: 1.1527\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 1.2292 - val_loss: 1.3986\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.1328 - val_loss: 0.7659\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1401 - val_loss: 0.3861\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3738 - val_loss: 0.3622\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 2.1259 - val_loss: 3.5638\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.1974 - val_loss: 0.4861\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 1.2171 - val_loss: 1.3948\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.0369 - val_loss: 0.1897\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.0713 - val_loss: 0.4471\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2432 - val_loss: 1.2350\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.2116 - val_loss: 1.2262\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 3.1191 - val_loss: 6.1423\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 4.3605 - val_loss: 3.2310\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0078 - val_loss: 0.0146\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0890 - val_loss: 0.9369\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1651 - val_loss: 1.7143\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.6752 - val_loss: 1.4787\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.4510 - val_loss: 2.5008\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0068 - val_loss: 0.5865\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.8882 - val_loss: 3.1286\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 2.4059 - val_loss: 2.4757\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.4625 - val_loss: 1.1720\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.6144 - val_loss: 0.4853\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1903 - val_loss: 1.2649\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.3337 - val_loss: 0.1834\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.1970 - val_loss: 4.1290\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1690 - val_loss: 0.8558\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.5975 - val_loss: 0.4562\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 3.7295 - val_loss: 10.5346\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.3343 - val_loss: 1.5283\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 1.9217 - val_loss: 0.9842\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1236 - val_loss: 0.4662\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 2.7804 - val_loss: 0.5302\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.5328 - val_loss: 1.0935\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.9506 - val_loss: 4.8275\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1741 - val_loss: 1.4109\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 8.6450 - val_loss: 17.1552\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.4647 - val_loss: 2.5646\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.1904 - val_loss: 0.0892\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.2804 - val_loss: 3.4762\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.9848 - val_loss: 3.6238\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.0215 - val_loss: 0.6481\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.0081 - val_loss: 0.0371\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0230 - val_loss: 0.0173\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 2.4510 - val_loss: 3.5105\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0056 - val_loss: 0.0144\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.1258 - val_loss: 0.3893\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.6103 - val_loss: 4.3133\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.6226 - val_loss: 2.0073\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 1.9338 - val_loss: 4.2602\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.5778 - val_loss: 1.6946\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.3498 - val_loss: 1.1336\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 4.0372 - val_loss: 9.7907\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.6111 - val_loss: 4.1071\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 1.2524 - val_loss: 0.7178\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.3596 - val_loss: 2.2183\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 1.3372 - val_loss: 1.6071\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 2.6439 - val_loss: 4.1924\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0869 - val_loss: 2.6948\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.8561 - val_loss: 1.4710\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 6.3299 - val_loss: 8.3424\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0265 - val_loss: 0.1795\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.9497 - val_loss: 0.2903\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0463 - val_loss: 0.1634\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.8234 - val_loss: 4.8187\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.7537 - val_loss: 2.6578\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.2886 - val_loss: 0.3693\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.5649 - val_loss: 0.2850\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 2.4929 - val_loss: 7.0387\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 1.1762 - val_loss: 6.8790\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.5272 - val_loss: 1.1190\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.0609 - val_loss: 0.5319\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.6362 - val_loss: 1.2914\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.4725 - val_loss: 3.2751\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6977 - val_loss: 2.2270\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.2986 - val_loss: 0.5585\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 4.0843 - val_loss: 8.6855\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.1790 - val_loss: 0.3775\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0180 - val_loss: 0.0140\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0226 - val_loss: 0.0779\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.1362 - val_loss: 0.0434\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.1666 - val_loss: 0.1758\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0352 - val_loss: 0.0729\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1372 - val_loss: 0.3210\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1841 - val_loss: 0.7157\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1015 - val_loss: 0.2277\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.7002 - val_loss: 0.9959\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1012 - val_loss: 0.7054\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.3098 - val_loss: 0.0202\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2471 - val_loss: 0.3901\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2420 - val_loss: 1.9412\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3313 - val_loss: 0.5446\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 1.0452 - val_loss: 3.2201\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.2150 - val_loss: 0.0330\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.0932 - val_loss: 0.2800\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.4649 - val_loss: 3.4271\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.7487 - val_loss: 3.5225\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 1.4885 - val_loss: 3.4856\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.1824 - val_loss: 0.7664\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.9515 - val_loss: 1.0559\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 1.3149 - val_loss: 1.7799\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0954 - val_loss: 0.2370\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.8902 - val_loss: 1.5743\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.0287 - val_loss: 0.8371\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 2.0281 - val_loss: 4.2383\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.2909 - val_loss: 2.3767\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3525 - val_loss: 2.0671\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.7369 - val_loss: 0.8839\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 2.4681 - val_loss: 3.4275\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2969 - val_loss: 0.6644\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 1.3562 - val_loss: 0.0544\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.0212 - val_loss: 0.2839\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.1089 - val_loss: 2.0424\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.1459 - val_loss: 0.0385\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.0189 - val_loss: 0.1709\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.8507 - val_loss: 0.0251\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 2.8291 - val_loss: 4.6990\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0231 - val_loss: 0.1238\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.0876 - val_loss: 0.8665\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.9748 - val_loss: 6.7991\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.4215 - val_loss: 1.2826\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2756 - val_loss: 1.1451\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1146 - val_loss: 0.5136\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.3110 - val_loss: 0.5540\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.6944 - val_loss: 2.0463\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.2718 - val_loss: 0.6904\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.7898 - val_loss: 2.4095\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4436 - val_loss: 4.1606\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4304 - val_loss: 1.5801\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.6718 - val_loss: 8.5703\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 1.1226 - val_loss: 9.3338\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.5448 - val_loss: 0.9719\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 7.4350 - val_loss: 15.6487\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.3798 - val_loss: 1.8427\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.5989 - val_loss: 4.8837\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.2596 - val_loss: 2.3190\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.1219 - val_loss: 0.0183\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.2046 - val_loss: 2.4565\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.9060 - val_loss: 1.4796\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 5.7032 - val_loss: 7.0741\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 3.2591 - val_loss: 5.9990\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.3161 - val_loss: 0.9767\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 2.2830 - val_loss: 7.1008\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.3901 - val_loss: 1.1953\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 2.7624 - val_loss: 5.4309\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.6840 - val_loss: 7.7019\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.5771 - val_loss: 2.8269\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 4.0581 - val_loss: 5.0637\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 10.5988 - val_loss: 18.8771\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.4861 - val_loss: 1.6598\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.2212 - val_loss: 0.1354\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2559 - val_loss: 1.8810\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.9448 - val_loss: 1.6138\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.8762 - val_loss: 2.3477\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.4708 - val_loss: 1.8743\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.4454 - val_loss: 0.1545\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 2.1030 - val_loss: 0.7372\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.8430 - val_loss: 0.9892\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.5149 - val_loss: 0.4793\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1238 - val_loss: 0.4665\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.2405 - val_loss: 0.2592\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.3930 - val_loss: 1.4474\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5742 - val_loss: 2.4756\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.6508 - val_loss: 1.2513\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 7.5396 - val_loss: 18.0038\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4486 - val_loss: 0.2492\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.4716 - val_loss: 0.0796\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.6704 - val_loss: 7.2851\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.4454 - val_loss: 0.7215\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2083 - val_loss: 2.1271\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 1.8650 - val_loss: 3.8518\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 2.2761 - val_loss: 2.6557\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 7.5391 - val_loss: 16.0194\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2154 - val_loss: 0.6038\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0507 - val_loss: 0.0546\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.1242 - val_loss: 2.3584\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.6405 - val_loss: 1.0849\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.5592 - val_loss: 1.9835\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.6123 - val_loss: 0.3607\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 1.2490 - val_loss: 1.5783\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 1.5454 - val_loss: 3.4242\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.5660 - val_loss: 0.8649\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 1.0693 - val_loss: 2.7447\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.0855 - val_loss: 0.8087\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.9947 - val_loss: 2.0233\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.5630 - val_loss: 1.3129\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.0612 - val_loss: 0.8876\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.5353 - val_loss: 0.6308\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 2.1467 - val_loss: 3.5829\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2250 - val_loss: 0.6108\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.4315 - val_loss: 0.9409\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.2517 - val_loss: 2.5723\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2547 - val_loss: 0.6917\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.6085 - val_loss: 2.1823\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.5227 - val_loss: 1.7304\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2576 - val_loss: 0.3992\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 6.3237 - val_loss: 10.3350\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1294 - val_loss: 0.4769\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 5.1805 - val_loss: 7.2747\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0616 - val_loss: 0.8337\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.9699 - val_loss: 1.8529\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.3861 - val_loss: 0.9557\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.7758 - val_loss: 4.0024\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 1.7092 - val_loss: 2.4163\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 9.8586 - val_loss: 18.9006\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.1914 - val_loss: 0.3452\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.0603 - val_loss: 0.0756\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0509 - val_loss: 0.3757\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1730 - val_loss: 0.7533\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2963 - val_loss: 1.0054\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.3769 - val_loss: 0.9341\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.9424 - val_loss: 1.1807\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2879 - val_loss: 0.5086\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.4076 - val_loss: 1.3310\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.7938 - val_loss: 1.5739\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0905 - val_loss: 0.2830\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 1.2851 - val_loss: 3.4928\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.7944 - val_loss: 3.0620\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.1396 - val_loss: 1.0894\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 3.7642 - val_loss: 3.9356\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 5.4532 - val_loss: 13.4855\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1508 - val_loss: 0.2521\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.2234 - val_loss: 0.4560\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.0550 - val_loss: 0.1203\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.1071 - val_loss: 0.1399\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 4.0168 - val_loss: 7.0594\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0959 - val_loss: 0.1126\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 1.3478 - val_loss: 3.1731\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 6.8967 - val_loss: 16.3539\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0862 - val_loss: 0.1226\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.3499 - val_loss: 1.1847\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0435 - val_loss: 0.0690\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1914 - val_loss: 0.0492\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 1.2586 - val_loss: 1.4877\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.1425 - val_loss: 1.8844\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 3.9162 - val_loss: 3.3544\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 5.7985 - val_loss: 13.7406\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 1.0406 - val_loss: 3.2906\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.2235 - val_loss: 0.2105\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.2632 - val_loss: 1.0729\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 1.2121 - val_loss: 1.3360\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1357 - val_loss: 0.7651\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.1480 - val_loss: 0.3497\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.3849 - val_loss: 0.3267\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 1.9743 - val_loss: 3.2382\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.1964 - val_loss: 0.4624\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 1.0725 - val_loss: 1.1926\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0370 - val_loss: 0.1815\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0763 - val_loss: 0.4674\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2321 - val_loss: 1.1255\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1918 - val_loss: 1.1470\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 2.8177 - val_loss: 5.6152\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 4.2077 - val_loss: 3.0149\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0163 - val_loss: 0.0279\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.0803 - val_loss: 0.8517\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.1630 - val_loss: 1.6669\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.6404 - val_loss: 1.3812\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.4384 - val_loss: 2.5067\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0052 - val_loss: 0.5559\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.7890 - val_loss: 2.9317\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 2.2477 - val_loss: 2.2443\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.4483 - val_loss: 1.1209\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6475 - val_loss: 0.4635\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1878 - val_loss: 1.2279\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.3461 - val_loss: 0.1963\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 1.2586 - val_loss: 4.3522\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1721 - val_loss: 0.7669\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.5063 - val_loss: 0.4743\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 3.5402 - val_loss: 10.0568\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2892 - val_loss: 1.3631\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 1.8187 - val_loss: 0.9217\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.1265 - val_loss: 0.5192\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 2.6973 - val_loss: 0.5558\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5579 - val_loss: 1.0861\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.9545 - val_loss: 4.8002\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.1762 - val_loss: 1.1211\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 8.3485 - val_loss: 16.3334\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.4604 - val_loss: 2.4042\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1815 - val_loss: 0.0750\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2491 - val_loss: 3.2431\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.9021 - val_loss: 3.4067\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0245 - val_loss: 0.7102\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0086 - val_loss: 0.0344\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.0206 - val_loss: 0.0207\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 2.3571 - val_loss: 3.3391\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0080 - val_loss: 0.0266\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1404 - val_loss: 0.4236\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.5969 - val_loss: 4.1064\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6219 - val_loss: 1.9665\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 2.1149 - val_loss: 4.5112\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.5260 - val_loss: 1.5068\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.3314 - val_loss: 1.1111\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 3.8122 - val_loss: 9.0774\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.6396 - val_loss: 4.2071\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2575 - val_loss: 0.1054\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.0564 - val_loss: 0.3764\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.2527 - val_loss: 0.4835\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 1.1095 - val_loss: 2.5270\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2719 - val_loss: 4.5167\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3454 - val_loss: 1.1751\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 7.5467 - val_loss: 9.2328\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0126 - val_loss: 0.2264\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.5900 - val_loss: 0.5423\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.0953 - val_loss: 0.3501\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 1.1314 - val_loss: 5.7770\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.8356 - val_loss: 2.7782\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.5269 - val_loss: 0.6795\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.8733 - val_loss: 0.6843\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 2.1684 - val_loss: 5.9098\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4931 - val_loss: 2.5506\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.7184 - val_loss: 1.3885\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0915 - val_loss: 0.7492\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.8250 - val_loss: 1.5072\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.5572 - val_loss: 3.5552\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.5447 - val_loss: 1.8288\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2393 - val_loss: 0.4809\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 3.6609 - val_loss: 8.0785\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2088 - val_loss: 0.3861\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0152 - val_loss: 0.0041\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.0202 - val_loss: 0.0674\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.1234 - val_loss: 0.0191\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1641 - val_loss: 0.1515\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0323 - val_loss: 0.0649\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1186 - val_loss: 0.2434\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.1536 - val_loss: 0.6757\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0633 - val_loss: 0.1485\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5940 - val_loss: 0.8443\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.0724 - val_loss: 0.5104\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2254 - val_loss: 0.0084\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1559 - val_loss: 0.2360\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.2855 - val_loss: 2.1751\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2332 - val_loss: 0.3000\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 1.1087 - val_loss: 3.2648\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1818 - val_loss: 0.0585\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.0784 - val_loss: 0.1978\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4618 - val_loss: 3.4441\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.7588 - val_loss: 3.5188\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 1.3734 - val_loss: 3.2235\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1827 - val_loss: 0.7785\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.8080 - val_loss: 0.8909\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 1.2630 - val_loss: 1.6347\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.1166 - val_loss: 0.2803\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.8064 - val_loss: 1.4567\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.0262 - val_loss: 0.8154\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 1.9778 - val_loss: 4.1490\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2939 - val_loss: 2.3455\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3029 - val_loss: 1.8447\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.7626 - val_loss: 0.8254\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 2.3190 - val_loss: 3.2179\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.2762 - val_loss: 0.6278\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 1.3731 - val_loss: 0.0689\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0210 - val_loss: 0.2817\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1155 - val_loss: 1.9620\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1386 - val_loss: 0.0459\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0147 - val_loss: 0.1480\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.7918 - val_loss: 0.0271\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6228 - val_loss: 4.2820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0216 - val_loss: 0.1279\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0983 - val_loss: 0.9722\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.9910 - val_loss: 6.8121\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.4314 - val_loss: 1.3210\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3009 - val_loss: 1.2102\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0889 - val_loss: 0.4185\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3144 - val_loss: 0.5784\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6132 - val_loss: 1.8100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2860 - val_loss: 0.7288\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7251 - val_loss: 2.2198\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4259 - val_loss: 3.9796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3799 - val_loss: 1.3862\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5802 - val_loss: 8.1774\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1471 - val_loss: 9.5294\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5293 - val_loss: 0.8655\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.5658 - val_loss: 16.3161\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3819 - val_loss: 1.7924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5270 - val_loss: 4.1725\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2381 - val_loss: 2.1514\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1052 - val_loss: 0.0284\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2187 - val_loss: 2.4206\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8801 - val_loss: 1.5160\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.4189 - val_loss: 6.3581\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.1271 - val_loss: 5.7267\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.2956 - val_loss: 0.9489\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1619 - val_loss: 6.7438\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4105 - val_loss: 1.1535\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7212 - val_loss: 5.3051\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6643 - val_loss: 7.5551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5320 - val_loss: 2.6600\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.7748 - val_loss: 4.6739\n",
            "1/1 [==============================] - 1s 1s/step - loss: 10.1508 - val_loss: 17.4319\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4955 - val_loss: 1.7153\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2164 - val_loss: 0.1512\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2341 - val_loss: 1.8816\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9175 - val_loss: 1.5787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9865 - val_loss: 2.5758\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.4067 - val_loss: 1.3746\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4710 - val_loss: 0.2754\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7773 - val_loss: 0.5159\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0089 - val_loss: 1.2701\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5270 - val_loss: 0.5487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1226 - val_loss: 0.4924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2519 - val_loss: 0.2729\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4074 - val_loss: 1.4596\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5117 - val_loss: 2.1804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5282 - val_loss: 1.1050\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.9772 - val_loss: 16.6870\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4237 - val_loss: 0.2397\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4544 - val_loss: 0.0763\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6374 - val_loss: 7.0893\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4028 - val_loss: 0.6508\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1787 - val_loss: 1.9177\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 1.7675 - val_loss: 3.7166\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 2.1524 - val_loss: 2.4947\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.2127 - val_loss: 15.1138\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1873 - val_loss: 0.5041\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0417 - val_loss: 0.0425\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1001 - val_loss: 2.1085\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5331 - val_loss: 0.8805\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.5144 - val_loss: 1.8863\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.5639 - val_loss: 0.3115\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 1.1127 - val_loss: 1.4458\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 1.5190 - val_loss: 3.3602\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.5604 - val_loss: 0.9059\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.9789 - val_loss: 2.5614\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.0761 - val_loss: 0.7276\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.8894 - val_loss: 1.8090\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.5282 - val_loss: 1.2597\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0714 - val_loss: 0.8356\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.5035 - val_loss: 0.5515\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 2.1292 - val_loss: 3.6224\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1924 - val_loss: 0.5758\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.3929 - val_loss: 0.8436\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.2279 - val_loss: 2.4001\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2046 - val_loss: 0.5606\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.5448 - val_loss: 2.0097\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.5530 - val_loss: 1.8024\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.2136 - val_loss: 0.3164\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 6.3264 - val_loss: 10.0290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1045 - val_loss: 0.4510\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 5.1926 - val_loss: 7.2552\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0804 - val_loss: 0.9985\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.9754 - val_loss: 1.7554\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.3467 - val_loss: 1.1380\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.7680 - val_loss: 4.0250\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 1.5191 - val_loss: 2.4132\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 9.3199 - val_loss: 17.6375\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2443 - val_loss: 0.3959\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.0806 - val_loss: 0.0521\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0554 - val_loss: 0.4261\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1794 - val_loss: 0.8417\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.3303 - val_loss: 1.1389\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.4910 - val_loss: 1.2223\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.9786 - val_loss: 1.2840\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.2755 - val_loss: 0.2727\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.4575 - val_loss: 1.5023\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.7737 - val_loss: 1.4902\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0701 - val_loss: 0.2045\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 1.1345 - val_loss: 3.1030\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.8077 - val_loss: 2.9667\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.1125 - val_loss: 0.9069\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 3.7223 - val_loss: 3.8106\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 5.1695 - val_loss: 12.9069\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1187 - val_loss: 0.1717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1694 - val_loss: 0.2929\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0396 - val_loss: 0.0941\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0868 - val_loss: 0.1122\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.8426 - val_loss: 6.5906\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0972 - val_loss: 0.1149\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 1.4241 - val_loss: 3.3173\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 6.7452 - val_loss: 16.0984\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.0958 - val_loss: 0.1223\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.3117 - val_loss: 1.0742\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.0372 - val_loss: 0.0495\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.1812 - val_loss: 0.0355\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 1.2020 - val_loss: 1.4192\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1200 - val_loss: 1.7191\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 3.7519 - val_loss: 3.2004\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 5.3088 - val_loss: 12.6507\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 1.0219 - val_loss: 3.2716\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 1.1925 - val_loss: 0.2048\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.2255 - val_loss: 0.9189\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 1.1283 - val_loss: 1.1901\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1154 - val_loss: 0.7807\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.1876 - val_loss: 0.3138\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.3829 - val_loss: 0.3255\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 1.6603 - val_loss: 2.5876\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1909 - val_loss: 0.3969\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.9678 - val_loss: 0.9350\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.0340 - val_loss: 0.1586\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0950 - val_loss: 0.5350\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.2184 - val_loss: 1.0063\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.1631 - val_loss: 1.0383\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 2.4959 - val_loss: 5.0067\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 3.9057 - val_loss: 2.6670\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0281 - val_loss: 0.0483\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.0708 - val_loss: 0.7438\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.1266 - val_loss: 1.4672\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.5297 - val_loss: 1.1436\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3894 - val_loss: 2.4296\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.0024 - val_loss: 0.5626\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 1.6518 - val_loss: 2.6324\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 2.1062 - val_loss: 2.0316\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.4115 - val_loss: 1.0185\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5961 - val_loss: 0.4063\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1728 - val_loss: 1.0776\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.4140 - val_loss: 0.2408\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 1.4191 - val_loss: 4.8446\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1898 - val_loss: 0.6308\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.3988 - val_loss: 0.5658\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 3.2436 - val_loss: 9.6211\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.2668 - val_loss: 1.2724\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 1.6736 - val_loss: 0.8595\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1289 - val_loss: 0.5932\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 2.6152 - val_loss: 0.5827\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5822 - val_loss: 1.0551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8767 - val_loss: 4.4110\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.1923 - val_loss: 0.9232\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 7.7856 - val_loss: 15.0668\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.4611 - val_loss: 2.1132\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1721 - val_loss: 0.0544\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.2127 - val_loss: 2.9717\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.8283 - val_loss: 3.2003\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0485 - val_loss: 0.9293\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0441 - val_loss: 0.0939\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.0316 - val_loss: 0.0469\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 2.2524 - val_loss: 3.1148\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0288 - val_loss: 0.0796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1753 - val_loss: 0.4846\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.5906 - val_loss: 3.9129\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6306 - val_loss: 1.9185\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 2.2272 - val_loss: 4.5228\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4846 - val_loss: 1.3697\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3451 - val_loss: 1.2019\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 3.6084 - val_loss: 8.3158\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.6083 - val_loss: 3.9431\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3810 - val_loss: 0.3856\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.1145 - val_loss: 1.0641\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.4148 - val_loss: 0.6928\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 1.5237 - val_loss: 2.9468\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1153 - val_loss: 3.2901\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.4629 - val_loss: 1.1937\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 6.2537 - val_loss: 7.7010\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.0163 - val_loss: 0.2113\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5219 - val_loss: 0.5349\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.0740 - val_loss: 0.2369\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9893 - val_loss: 5.3498\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6358 - val_loss: 2.1682\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.3873 - val_loss: 0.6550\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.5241 - val_loss: 0.1831\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 2.2800 - val_loss: 6.0578\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.1519 - val_loss: 1.1532\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.5396 - val_loss: 1.0916\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.0639 - val_loss: 0.5314\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.5695 - val_loss: 1.2248\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.4269 - val_loss: 2.8599\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6218 - val_loss: 2.0822\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.3063 - val_loss: 0.5684\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 3.6412 - val_loss: 7.9165\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.1430 - val_loss: 0.4505\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0232 - val_loss: 0.0142\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0119 - val_loss: 0.0537\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0994 - val_loss: 0.0112\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1694 - val_loss: 0.1791\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0550 - val_loss: 0.1332\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.1762 - val_loss: 0.3646\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.1735 - val_loss: 0.5773\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0734 - val_loss: 0.1616\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.6717 - val_loss: 0.9158\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.0794 - val_loss: 0.5197\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2397 - val_loss: 0.0022\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.1527 - val_loss: 0.2203\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2250 - val_loss: 1.9112\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.2623 - val_loss: 0.2884\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.9201 - val_loss: 2.7614\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.1790 - val_loss: 0.0574\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.0680 - val_loss: 0.1079\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4788 - val_loss: 3.5517\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.8120 - val_loss: 3.5042\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2285 - val_loss: 2.8427\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.1452 - val_loss: 0.7070\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6477 - val_loss: 0.7836\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 1.0800 - val_loss: 1.2935\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.1574 - val_loss: 0.3779\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.7472 - val_loss: 1.3396\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0259 - val_loss: 0.7668\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 1.8574 - val_loss: 3.8586\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.2943 - val_loss: 2.1646\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.2562 - val_loss: 1.6525\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.7976 - val_loss: 0.7991\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 1.9997 - val_loss: 2.5951\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.2923 - val_loss: 0.6762\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3475 - val_loss: 0.0933\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0190 - val_loss: 0.2361\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1235 - val_loss: 1.7851\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.1406 - val_loss: 0.0564\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0116 - val_loss: 0.1379\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.7932 - val_loss: 0.0262\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 2.3423 - val_loss: 3.6554\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.0229 - val_loss: 0.1483\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1162 - val_loss: 1.0902\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 1.0041 - val_loss: 6.7680\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.4149 - val_loss: 1.2608\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.3142 - val_loss: 1.1820\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0772 - val_loss: 0.3423\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2983 - val_loss: 0.5295\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.5467 - val_loss: 1.5663\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.2597 - val_loss: 0.6222\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6314 - val_loss: 2.0187\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.3523 - val_loss: 3.5093\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2852 - val_loss: 1.0463\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4537 - val_loss: 7.4977\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2004 - val_loss: 9.7707\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5228 - val_loss: 0.6850\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 7.6238 - val_loss: 16.3875\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.3941 - val_loss: 1.6898\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.4382 - val_loss: 4.1275\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.2397 - val_loss: 2.1359\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1053 - val_loss: 0.0392\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.2315 - val_loss: 2.4971\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.8964 - val_loss: 1.1933\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 5.2644 - val_loss: 6.6017\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5477 - val_loss: 4.7318\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.2922 - val_loss: 0.8925\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 2.2117 - val_loss: 6.7271\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4378 - val_loss: 1.3835\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 2.9785 - val_loss: 5.5077\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 0.6554 - val_loss: 7.3147\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.3834 - val_loss: 2.2439\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 3.6382 - val_loss: 4.4188\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 9.1752 - val_loss: 15.6338\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.4766 - val_loss: 1.8028\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.2170 - val_loss: 0.1149\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2242 - val_loss: 1.8333\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.8818 - val_loss: 1.5122\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.9880 - val_loss: 2.4889\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.3964 - val_loss: 1.2039\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.4596 - val_loss: 0.2653\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 1.6907 - val_loss: 0.4784\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.9798 - val_loss: 1.1367\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.3759 - val_loss: 0.6083\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.1053 - val_loss: 0.3827\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1404 - val_loss: 0.1187\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.2742 - val_loss: 0.9502\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.5692 - val_loss: 2.3331\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.5435 - val_loss: 1.2533\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 7.0182 - val_loss: 16.0859\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.4063 - val_loss: 0.4050\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.2969 - val_loss: 0.1555\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5845 - val_loss: 6.6932\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.4226 - val_loss: 0.6720\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.1193 - val_loss: 1.6223\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 1.6639 - val_loss: 3.3043\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 1.9450 - val_loss: 2.3100\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 6.2457 - val_loss: 13.0348\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.1777 - val_loss: 0.4929\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0656 - val_loss: 0.0439\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0870 - val_loss: 2.0134\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.4518 - val_loss: 0.7494\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.5617 - val_loss: 2.0286\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.4681 - val_loss: 0.2078\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 1.3555 - val_loss: 1.7545\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 1.1831 - val_loss: 2.4851\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.5455 - val_loss: 0.8895\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0274 - val_loss: 2.5599\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.0789 - val_loss: 0.6616\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.7767 - val_loss: 1.4963\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.4381 - val_loss: 1.0531\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.0823 - val_loss: 0.8181\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5054 - val_loss: 0.4445\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8299 - val_loss: 3.1848\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1279 - val_loss: 0.4156\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3521 - val_loss: 0.7623\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1892 - val_loss: 2.0979\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.1474 - val_loss: 0.3953\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.4099 - val_loss: 1.5610\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.5527 - val_loss: 1.8015\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1858 - val_loss: 0.2633\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 6.2869 - val_loss: 9.3631\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.0596 - val_loss: 0.3390\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 5.3094 - val_loss: 7.4825\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.0824 - val_loss: 1.0586\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.9746 - val_loss: 1.8064\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.3541 - val_loss: 1.0614\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.6040 - val_loss: 3.3804\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 1.4245 - val_loss: 2.1183\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 8.1496 - val_loss: 15.5461\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.2191 - val_loss: 0.3509\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.0986 - val_loss: 0.0402\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.0593 - val_loss: 0.4698\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1758 - val_loss: 0.8180\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.3492 - val_loss: 1.1497\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.5983 - val_loss: 1.4012\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.8885 - val_loss: 1.1518\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.3642 - val_loss: 0.1747\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.4460 - val_loss: 1.3979\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.7289 - val_loss: 1.3672\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.0555 - val_loss: 0.1477\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 1.0103 - val_loss: 2.7138\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.7644 - val_loss: 2.6401\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.1088 - val_loss: 0.8072\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 3.5540 - val_loss: 3.4821\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 4.8519 - val_loss: 12.1198\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1056 - val_loss: 0.0763\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.1408 - val_loss: 0.1270\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.0373 - val_loss: 0.1292\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1048 - val_loss: 0.1564\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 3.6010 - val_loss: 6.1227\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1125 - val_loss: 0.1291\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 1.6401 - val_loss: 3.7166\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 6.1607 - val_loss: 14.3402\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.1066 - val_loss: 0.1415\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.2949 - val_loss: 0.9166\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.0288 - val_loss: 0.0694\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.2298 - val_loss: 0.0678\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 1.0290 - val_loss: 1.2052\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0978 - val_loss: 1.4134\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 3.3362 - val_loss: 2.7693\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.8885 - val_loss: 11.4731\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.9089 - val_loss: 2.9540\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 1.1183 - val_loss: 0.1304\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.2386 - val_loss: 0.9606\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 1.0919 - val_loss: 1.0566\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1100 - val_loss: 0.8373\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.1913 - val_loss: 0.2587\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3698 - val_loss: 0.2250\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3798 - val_loss: 1.8537\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.2037 - val_loss: 0.3801\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7829 - val_loss: 0.7209\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0428 - val_loss: 0.1439\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1081 - val_loss: 0.5677\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.2057 - val_loss: 0.8376\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1261 - val_loss: 0.8581\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.2764 - val_loss: 4.5740\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.3327 - val_loss: 2.0372\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.0565 - val_loss: 0.1116\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.1010 - val_loss: 0.5721\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.1065 - val_loss: 1.3187\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.4451 - val_loss: 0.8901\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.3577 - val_loss: 2.4506\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.0017 - val_loss: 0.6156\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 1.4477 - val_loss: 2.2777\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 1.9314 - val_loss: 1.7616\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.3406 - val_loss: 0.8123\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.6380 - val_loss: 0.4275\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.1859 - val_loss: 1.0600\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4329 - val_loss: 0.2167\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.5450 - val_loss: 5.1813\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2778 - val_loss: 0.6449\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3296 - val_loss: 0.6685\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9435 - val_loss: 8.4290\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.2901 - val_loss: 1.3215\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 1.7444 - val_loss: 0.9861\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1336 - val_loss: 0.6698\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 2.5140 - val_loss: 0.6895\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.5401 - val_loss: 0.9923\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.7392 - val_loss: 3.8900\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.2110 - val_loss: 0.8787\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 6.6887 - val_loss: 12.9107\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.5224 - val_loss: 1.8061\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.2044 - val_loss: 0.0860\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1864 - val_loss: 2.7540\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7125 - val_loss: 2.8424\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0462 - val_loss: 0.8660\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0908 - val_loss: 0.1685\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.0256 - val_loss: 0.0369\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 2.0849 - val_loss: 2.7588\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.0239 - val_loss: 0.0765\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1237 - val_loss: 0.3346\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.5633 - val_loss: 3.7696\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5699 - val_loss: 1.6893\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 2.1111 - val_loss: 3.9847\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.4413 - val_loss: 1.2771\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.4858 - val_loss: 1.6472\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 3.3214 - val_loss: 7.4373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4855 - val_loss: 3.2715\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.2048 - val_loss: 0.2758\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0382 - val_loss: 0.6232\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3322 - val_loss: 0.6140\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 1.1589 - val_loss: 2.3507\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1423 - val_loss: 3.3049\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.3215 - val_loss: 0.9166\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 6.1497 - val_loss: 7.4762\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0235 - val_loss: 0.1891\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.4123 - val_loss: 0.6494\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0842 - val_loss: 0.2627\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 1.0523 - val_loss: 5.3955\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.5442 - val_loss: 1.9043\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.4042 - val_loss: 0.7669\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6131 - val_loss: 0.3084\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9462 - val_loss: 5.3004\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1419 - val_loss: 0.7277\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5276 - val_loss: 1.0336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0660 - val_loss: 0.5274\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5498 - val_loss: 1.2001\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.4285 - val_loss: 2.7782\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.5019 - val_loss: 1.7252\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.2985 - val_loss: 0.5598\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 3.0075 - val_loss: 6.7234\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1374 - val_loss: 0.4772\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.0706 - val_loss: 0.0738\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.0251 - val_loss: 0.1163\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.0972 - val_loss: 0.0118\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.2494 - val_loss: 0.2635\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0979 - val_loss: 0.2524\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2493 - val_loss: 0.4100\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.2524 - val_loss: 0.4593\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0314 - val_loss: 0.0712\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5017 - val_loss: 0.6862\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.0549 - val_loss: 0.3447\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1727 - val_loss: 0.0440\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.0829 - val_loss: 0.1541\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.2175 - val_loss: 1.9106\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.1686 - val_loss: 0.1574\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.8079 - val_loss: 2.2544\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.1927 - val_loss: 0.1586\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.1100 - val_loss: 0.1078\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.4927 - val_loss: 3.5282\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.8263 - val_loss: 3.3624\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 1.1225 - val_loss: 2.6071\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.1514 - val_loss: 0.7784\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5991 - val_loss: 0.7249\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.9242 - val_loss: 0.9575\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2003 - val_loss: 0.4552\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6982 - val_loss: 1.2723\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0256 - val_loss: 0.7304\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 1.7718 - val_loss: 3.6999\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.3111 - val_loss: 2.1485\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1785 - val_loss: 1.2674\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.8034 - val_loss: 0.7750\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 1.6501 - val_loss: 2.0074\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.2805 - val_loss: 0.6767\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 1.4316 - val_loss: 0.1567\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0235 - val_loss: 0.2298\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1523 - val_loss: 1.7177\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.1268 - val_loss: 0.0832\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0264 - val_loss: 0.1274\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.6809 - val_loss: 0.0395\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 2.0238 - val_loss: 2.9795\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0190 - val_loss: 0.1170\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1061 - val_loss: 1.0249\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.9786 - val_loss: 6.5759\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.3421 - val_loss: 1.0074\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.2481 - val_loss: 0.9350\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.0834 - val_loss: 0.3096\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.2378 - val_loss: 0.3805\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.5218 - val_loss: 1.3527\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.1987 - val_loss: 0.4311\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.5432 - val_loss: 1.8014\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3139 - val_loss: 3.1752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2315 - val_loss: 0.8072\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.3607 - val_loss: 6.9656\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 1.0257 - val_loss: 9.0740\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.5312 - val_loss: 0.5299\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 7.1252 - val_loss: 15.3499\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.4127 - val_loss: 1.6856\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3824 - val_loss: 3.9568\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.2296 - val_loss: 2.0693\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1146 - val_loss: 0.0603\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.2403 - val_loss: 2.4894\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.9589 - val_loss: 0.9662\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 5.2514 - val_loss: 6.3787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0127 - val_loss: 3.8231\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.2728 - val_loss: 0.8575\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 2.1718 - val_loss: 6.4311\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.4669 - val_loss: 1.4113\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 3.0112 - val_loss: 5.1307\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6252 - val_loss: 6.7990\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.2996 - val_loss: 2.0419\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 3.5587 - val_loss: 4.2755\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.5508 - val_loss: 14.3067\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4227 - val_loss: 1.8614\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2281 - val_loss: 0.1859\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.1945 - val_loss: 1.4907\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.7574 - val_loss: 1.2458\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.9584 - val_loss: 2.1897\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.3986 - val_loss: 1.0066\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.4395 - val_loss: 0.1901\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 1.5928 - val_loss: 0.4377\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.9010 - val_loss: 0.8872\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.3274 - val_loss: 0.6057\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.0927 - val_loss: 0.3421\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.1140 - val_loss: 0.0997\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2603 - val_loss: 0.9237\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.4633 - val_loss: 1.8742\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.5452 - val_loss: 1.2714\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 6.3221 - val_loss: 14.3482\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.3967 - val_loss: 0.4283\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.2457 - val_loss: 0.2034\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.5548 - val_loss: 6.3537\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4394 - val_loss: 0.6894\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1041 - val_loss: 1.4625\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.5728 - val_loss: 2.9648\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 1.7055 - val_loss: 2.0646\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 5.3277 - val_loss: 11.6902\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.1569 - val_loss: 0.4529\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0694 - val_loss: 0.0466\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0773 - val_loss: 1.9380\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.4151 - val_loss: 0.6743\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.5415 - val_loss: 2.0296\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3637 - val_loss: 0.1539\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 1.5741 - val_loss: 2.0149\n",
            "1/1 [==============================] - 1s 1000ms/step - loss: 1.0136 - val_loss: 1.7745\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5467 - val_loss: 0.8882\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 1.0116 - val_loss: 2.4487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0727 - val_loss: 0.5065\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.5930 - val_loss: 1.1279\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.3404 - val_loss: 0.8431\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.0979 - val_loss: 0.8399\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.4351 - val_loss: 0.2964\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 1.7255 - val_loss: 3.0887\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.0947 - val_loss: 0.3317\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.3256 - val_loss: 0.6843\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.1425 - val_loss: 1.7529\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.1122 - val_loss: 0.2773\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.3187 - val_loss: 1.2976\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.5591 - val_loss: 1.7444\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1677 - val_loss: 0.2141\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 5.7822 - val_loss: 8.3196\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0505 - val_loss: 0.2994\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 5.3267 - val_loss: 7.6295\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0912 - val_loss: 1.1388\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.8955 - val_loss: 1.6406\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.3132 - val_loss: 1.2750\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.5581 - val_loss: 3.0677\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 1.3096 - val_loss: 2.0809\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 6.9833 - val_loss: 13.0692\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.2487 - val_loss: 0.3771\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.1438 - val_loss: 0.0150\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0583 - val_loss: 0.4999\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1642 - val_loss: 0.8264\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.3758 - val_loss: 1.2571\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.8173 - val_loss: 1.8852\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8944 - val_loss: 1.1599\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.6029 - val_loss: 0.1554\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.4217 - val_loss: 1.3235\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.6989 - val_loss: 1.2472\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.0403 - val_loss: 0.0877\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.8199 - val_loss: 2.1443\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.7300 - val_loss: 2.3315\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.1041 - val_loss: 0.7279\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 3.3771 - val_loss: 3.2150\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 4.4562 - val_loss: 11.1936\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.1468 - val_loss: 0.0628\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.1860 - val_loss: 0.0439\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.0610 - val_loss: 0.2416\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1660 - val_loss: 0.2651\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 3.4921 - val_loss: 5.8570\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.1089 - val_loss: 0.0980\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 1.8611 - val_loss: 4.1237\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 5.2214 - val_loss: 12.2203\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1424 - val_loss: 0.2018\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3149 - val_loss: 0.8102\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.0313 - val_loss: 0.1210\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.2979 - val_loss: 0.1252\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.8829 - val_loss: 1.0172\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.0876 - val_loss: 1.1069\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 3.0908 - val_loss: 2.5345\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 4.4924 - val_loss: 10.1320\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.8414 - val_loss: 2.7527\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 1.0379 - val_loss: 0.0865\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.2490 - val_loss: 0.9861\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 1.0315 - val_loss: 0.9106\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.1301 - val_loss: 0.7898\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.2520 - val_loss: 0.2146\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3597 - val_loss: 0.1893\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2580 - val_loss: 1.2074\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1947 - val_loss: 0.3559\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7222 - val_loss: 0.6771\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.0516 - val_loss: 0.1193\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.1529 - val_loss: 0.6760\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.1869 - val_loss: 0.6129\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.1027 - val_loss: 0.6859\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 2.1765 - val_loss: 4.3518\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 2.8238 - val_loss: 1.5237\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.1118 - val_loss: 0.2216\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.1657 - val_loss: 0.5536\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0986 - val_loss: 1.1915\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.3904 - val_loss: 0.7113\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.3464 - val_loss: 2.4501\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0043 - val_loss: 0.5965\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3522 - val_loss: 2.0748\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 1.6417 - val_loss: 1.3069\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.3092 - val_loss: 0.6966\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.5507 - val_loss: 0.2993\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1985 - val_loss: 1.0321\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.3711 - val_loss: 0.1510\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 1.6823 - val_loss: 5.5298\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.3505 - val_loss: 0.6272\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.2915 - val_loss: 0.7388\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 2.7114 - val_loss: 7.5468\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.2461 - val_loss: 1.1483\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 1.7176 - val_loss: 0.9664\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.1395 - val_loss: 0.7026\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 2.4383 - val_loss: 0.7203\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.6010 - val_loss: 1.0346\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.6259 - val_loss: 3.3630\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.2238 - val_loss: 0.8014\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 5.7479 - val_loss: 11.0575\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.4928 - val_loss: 1.8867\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.2144 - val_loss: 0.0971\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.1671 - val_loss: 2.5702\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.6391 - val_loss: 2.5902\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0463 - val_loss: 0.8043\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1457 - val_loss: 0.2458\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.0255 - val_loss: 0.0372\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9108 - val_loss: 2.4428\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0224 - val_loss: 0.0668\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1085 - val_loss: 0.2913\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.5222 - val_loss: 3.5998\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.4412 - val_loss: 1.3588\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 1.8061 - val_loss: 3.5447\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.3981 - val_loss: 1.0580\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4690 - val_loss: 1.6011\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 3.0287 - val_loss: 6.1846\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.4877 - val_loss: 3.2290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4036 - val_loss: 0.4718\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1177 - val_loss: 1.0920\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.3658 - val_loss: 0.6247\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 1.3113 - val_loss: 2.4046\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.0976 - val_loss: 2.5841\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.4328 - val_loss: 0.9308\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 5.3303 - val_loss: 6.5195\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.0254 - val_loss: 0.2442\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.4238 - val_loss: 0.7052\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0805 - val_loss: 0.2397\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.9672 - val_loss: 5.2117\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.4482 - val_loss: 1.5795\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.4022 - val_loss: 0.8636\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4920 - val_loss: 0.0811\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 1.4937 - val_loss: 4.2814\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0780 - val_loss: 0.6252\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.4442 - val_loss: 0.8359\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.0566 - val_loss: 0.4122\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.3723 - val_loss: 1.0434\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.3722 - val_loss: 2.3231\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.4760 - val_loss: 1.6909\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.4340 - val_loss: 0.7161\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 2.7034 - val_loss: 6.2713\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.1072 - val_loss: 0.6324\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.2196 - val_loss: 0.2428\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0038 - val_loss: 0.0378\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0491 - val_loss: 0.0407\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.1599 - val_loss: 0.1573\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1135 - val_loss: 0.3382\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1986 - val_loss: 0.2903\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.4448 - val_loss: 0.5194\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.0279 - val_loss: 0.0647\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.4841 - val_loss: 0.6970\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0498 - val_loss: 0.3102\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.1864 - val_loss: 0.0478\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.0821 - val_loss: 0.1427\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.1895 - val_loss: 1.6589\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1828 - val_loss: 0.1546\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.7654 - val_loss: 1.9850\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.1804 - val_loss: 0.1648\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.1573 - val_loss: 0.0900\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5054 - val_loss: 3.6012\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.9206 - val_loss: 3.4408\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.9824 - val_loss: 2.2523\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.1196 - val_loss: 0.7251\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.4793 - val_loss: 0.5959\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6693 - val_loss: 0.5393\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.2522 - val_loss: 0.5736\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6260 - val_loss: 1.1173\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.0334 - val_loss: 0.6958\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 1.6444 - val_loss: 3.3966\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.3153 - val_loss: 1.9598\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1538 - val_loss: 1.0972\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.8675 - val_loss: 0.7154\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 1.3900 - val_loss: 1.3759\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.3112 - val_loss: 0.7257\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 1.3589 - val_loss: 0.2115\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0295 - val_loss: 0.1433\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1919 - val_loss: 1.4382\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.1472 - val_loss: 0.1326\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.0288 - val_loss: 0.1569\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.6871 - val_loss: 0.0416\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 1.8845 - val_loss: 2.5031\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0204 - val_loss: 0.0934\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0821 - val_loss: 0.7999\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.8488 - val_loss: 5.9981\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.2552 - val_loss: 0.7642\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.1912 - val_loss: 0.7681\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.1196 - val_loss: 0.2733\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.2307 - val_loss: 0.3525\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.5891 - val_loss: 0.9601\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.1854 - val_loss: 0.3720\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.5089 - val_loss: 1.7123\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2898 - val_loss: 3.0351\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.2129 - val_loss: 0.6982\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.3274 - val_loss: 6.8419\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.9029 - val_loss: 8.4308\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.5670 - val_loss: 0.5248\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.5838 - val_loss: 14.7415\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.4241 - val_loss: 1.6250\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3452 - val_loss: 3.8577\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.2281 - val_loss: 2.0460\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1356 - val_loss: 0.1036\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.2679 - val_loss: 2.5669\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 1.0582 - val_loss: 0.7253\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 5.3895 - val_loss: 6.7216\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 1.6240 - val_loss: 3.0388\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.2633 - val_loss: 0.8461\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 2.1815 - val_loss: 6.2843\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.4939 - val_loss: 1.4949\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 3.0039 - val_loss: 4.7565\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.5983 - val_loss: 6.3224\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.2254 - val_loss: 1.8410\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 3.4947 - val_loss: 4.1195\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 7.7708 - val_loss: 13.1354\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.3910 - val_loss: 1.9578\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2559 - val_loss: 0.1384\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.1750 - val_loss: 1.1724\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6315 - val_loss: 1.0405\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.7966 - val_loss: 1.7353\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.4084 - val_loss: 0.7968\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.4415 - val_loss: 0.1545\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 1.5893 - val_loss: 0.4816\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.7915 - val_loss: 0.7207\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2856 - val_loss: 0.6858\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.0988 - val_loss: 0.3616\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.1023 - val_loss: 0.0931\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.2394 - val_loss: 0.8280\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4591 - val_loss: 1.6009\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.5405 - val_loss: 1.3121\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 5.5600 - val_loss: 12.4085\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.4014 - val_loss: 0.4704\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2180 - val_loss: 0.3364\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.5165 - val_loss: 5.8538\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.4741 - val_loss: 0.7062\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.0909 - val_loss: 1.2770\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 1.4646 - val_loss: 2.6531\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 1.6003 - val_loss: 1.9067\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 4.3395 - val_loss: 10.4038\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1276 - val_loss: 0.3210\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1451 - val_loss: 0.0983\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0667 - val_loss: 1.7656\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.3376 - val_loss: 0.5521\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.4679 - val_loss: 1.8635\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.3106 - val_loss: 0.1850\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 1.6638 - val_loss: 2.1560\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 1.0650 - val_loss: 1.2945\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.4663 - val_loss: 0.7760\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.9733 - val_loss: 2.2972\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0639 - val_loss: 0.3304\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.4141 - val_loss: 0.7697\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.2366 - val_loss: 0.6066\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1124 - val_loss: 0.8506\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.3847 - val_loss: 0.1964\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 1.4624 - val_loss: 2.8189\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0875 - val_loss: 0.2963\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.3332 - val_loss: 0.6487\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1153 - val_loss: 1.4715\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.1143 - val_loss: 0.2032\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.2516 - val_loss: 1.0723\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.5560 - val_loss: 1.6610\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1699 - val_loss: 0.1915\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 4.9848 - val_loss: 7.1456\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.0427 - val_loss: 0.2814\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.6045 - val_loss: 8.1673\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.0977 - val_loss: 1.2228\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.9073 - val_loss: 1.6635\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.3103 - val_loss: 1.3260\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.4627 - val_loss: 2.5803\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 1.2823 - val_loss: 2.0538\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 5.8301 - val_loss: 10.9807\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.2598 - val_loss: 0.4221\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.2564 - val_loss: 0.0039\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0389 - val_loss: 0.3461\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1186 - val_loss: 0.6458\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.3124 - val_loss: 1.0099\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.8661 - val_loss: 2.0477\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.7983 - val_loss: 0.9659\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.8271 - val_loss: 0.2149\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.3333 - val_loss: 1.1279\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.6470 - val_loss: 1.1231\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.0270 - val_loss: 0.0530\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.7135 - val_loss: 1.7968\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.6619 - val_loss: 1.9637\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.1004 - val_loss: 0.6901\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 3.1391 - val_loss: 2.8715\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 3.9762 - val_loss: 9.8636\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.2019 - val_loss: 0.1007\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.2600 - val_loss: 0.0190\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.0793 - val_loss: 0.3145\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.2398 - val_loss: 0.3632\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 3.2107 - val_loss: 5.3443\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.0900 - val_loss: 0.0513\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 2.0671 - val_loss: 4.4192\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 4.4731 - val_loss: 10.2367\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.1600 - val_loss: 0.2281\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.3290 - val_loss: 0.6393\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.0425 - val_loss: 0.1912\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.3749 - val_loss: 0.2071\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.7505 - val_loss: 0.8370\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0897 - val_loss: 0.9550\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 2.6538 - val_loss: 2.1435\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 4.0130 - val_loss: 8.6438\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.7473 - val_loss: 2.4984\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.9123 - val_loss: 0.0569\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.2399 - val_loss: 0.9308\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.9280 - val_loss: 0.7496\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.1994 - val_loss: 0.6271\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.3033 - val_loss: 0.2736\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.3239 - val_loss: 0.1669\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 1.2973 - val_loss: 0.8204\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.1515 - val_loss: 0.3788\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6564 - val_loss: 0.5956\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0559 - val_loss: 0.0911\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.1989 - val_loss: 0.7937\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.1791 - val_loss: 0.5276\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.1133 - val_loss: 0.7164\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 1.9865 - val_loss: 4.1323\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 2.4047 - val_loss: 1.0007\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1198 - val_loss: 0.2340\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1823 - val_loss: 0.5597\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0904 - val_loss: 1.0858\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.3517 - val_loss: 0.6183\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.3362 - val_loss: 2.4092\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.0223 - val_loss: 0.5175\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 1.3287 - val_loss: 2.0493\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 1.3513 - val_loss: 0.8978\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.2918 - val_loss: 0.6309\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.4529 - val_loss: 0.1834\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.2343 - val_loss: 1.1125\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.3482 - val_loss: 0.1057\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.7483 - val_loss: 5.7410\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.4450 - val_loss: 0.7019\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.2648 - val_loss: 0.8599\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 2.6744 - val_loss: 7.1626\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.1889 - val_loss: 0.9315\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 1.7628 - val_loss: 1.0967\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1651 - val_loss: 0.9272\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 2.3072 - val_loss: 0.8538\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.6576 - val_loss: 1.0564\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.6169 - val_loss: 3.2790\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.2767 - val_loss: 0.6119\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 5.2909 - val_loss: 9.8951\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.4649 - val_loss: 2.1424\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.3135 - val_loss: 0.1971\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.1555 - val_loss: 2.3686\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.5503 - val_loss: 2.2607\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0441 - val_loss: 0.6475\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1944 - val_loss: 0.3393\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0268 - val_loss: 0.0285\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 1.7851 - val_loss: 2.1189\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0177 - val_loss: 0.0505\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0905 - val_loss: 0.2207\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4972 - val_loss: 3.4905\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4261 - val_loss: 1.3162\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 1.7022 - val_loss: 3.4129\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.3547 - val_loss: 0.8255\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.4505 - val_loss: 1.5661\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 2.8183 - val_loss: 5.1186\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4802 - val_loss: 3.1281\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.2218 - val_loss: 0.4117\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0354 - val_loss: 0.5232\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.2873 - val_loss: 0.5117\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.9512 - val_loss: 1.8724\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.1204 - val_loss: 2.8111\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.2790 - val_loss: 0.8476\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 4.8896 - val_loss: 5.6497\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0324 - val_loss: 0.2365\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.4041 - val_loss: 0.6655\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.0599 - val_loss: 0.1858\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.9566 - val_loss: 5.1230\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.4595 - val_loss: 1.6955\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.3715 - val_loss: 0.7014\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.5503 - val_loss: 0.1526\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 1.2708 - val_loss: 3.4366\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0683 - val_loss: 0.6063\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.3956 - val_loss: 0.7678\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0473 - val_loss: 0.3809\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.3565 - val_loss: 1.1554\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.3547 - val_loss: 2.2919\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.3531 - val_loss: 1.2516\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.3759 - val_loss: 0.6469\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 2.1993 - val_loss: 5.2244\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.1103 - val_loss: 0.6984\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.2528 - val_loss: 0.2997\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.0028 - val_loss: 0.0187\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0568 - val_loss: 0.1051\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.1092 - val_loss: 0.0842\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1094 - val_loss: 0.3446\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.1672 - val_loss: 0.1952\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6292 - val_loss: 0.6085\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.0422 - val_loss: 0.0848\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.2806 - val_loss: 0.4939\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0373 - val_loss: 0.1985\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1680 - val_loss: 0.1513\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0665 - val_loss: 0.1404\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.1738 - val_loss: 1.5164\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1311 - val_loss: 0.1408\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.8198 - val_loss: 1.6088\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2014 - val_loss: 0.2438\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2759 - val_loss: 0.3755\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.4493 - val_loss: 3.2095\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.7205 - val_loss: 2.5401\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 1.1203 - val_loss: 2.5415\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.1263 - val_loss: 0.7172\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.5445 - val_loss: 0.5439\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.5157 - val_loss: 0.2815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2302 - val_loss: 0.5338\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6000 - val_loss: 1.0536\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.0418 - val_loss: 0.6597\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 1.5532 - val_loss: 3.1762\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.3522 - val_loss: 1.9813\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.1795 - val_loss: 1.2125\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.9611 - val_loss: 0.6100\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 1.3435 - val_loss: 1.2664\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.3504 - val_loss: 0.7716\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 1.4789 - val_loss: 0.3166\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.0510 - val_loss: 0.1337\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.2579 - val_loss: 1.3208\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1493 - val_loss: 0.2320\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.0135 - val_loss: 0.1091\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.5121 - val_loss: 0.1072\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8112 - val_loss: 2.2684\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0315 - val_loss: 0.0480\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.0923 - val_loss: 0.4927\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.7406 - val_loss: 5.5680\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.2145 - val_loss: 0.6346\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.1445 - val_loss: 0.6768\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.1217 - val_loss: 0.2495\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.2224 - val_loss: 0.3825\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.7210 - val_loss: 0.5817\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.1911 - val_loss: 0.3938\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.6490 - val_loss: 1.8739\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.3712 - val_loss: 3.3636\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.2419 - val_loss: 0.8690\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.3735 - val_loss: 6.9220\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.6823 - val_loss: 7.3817\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.5301 - val_loss: 0.6208\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 5.8866 - val_loss: 13.2502\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.4861 - val_loss: 1.8550\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.3718 - val_loss: 3.0381\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2248 - val_loss: 1.7416\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.2051 - val_loss: 0.2390\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.3657 - val_loss: 2.6093\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.9817 - val_loss: 0.8400\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 4.5204 - val_loss: 5.2686\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 1.4431 - val_loss: 2.6463\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.2607 - val_loss: 0.8663\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 2.0796 - val_loss: 6.0878\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.5153 - val_loss: 1.4490\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6610 - val_loss: 4.4280\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6193 - val_loss: 6.3386\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1585 - val_loss: 1.4513\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 3.3639 - val_loss: 3.9417\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 6.3742 - val_loss: 11.0660\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.3892 - val_loss: 1.9627\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2623 - val_loss: 0.2065\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.1762 - val_loss: 1.1258\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.6110 - val_loss: 0.9912\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.7018 - val_loss: 1.5240\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.4875 - val_loss: 0.5856\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.4168 - val_loss: 0.1506\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 1.6879 - val_loss: 0.6011\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.7074 - val_loss: 0.5787\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.3245 - val_loss: 0.6967\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0621 - val_loss: 0.2072\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.1199 - val_loss: 0.1144\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.2417 - val_loss: 0.8091\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.3854 - val_loss: 1.7045\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.4895 - val_loss: 1.0779\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.2483 - val_loss: 11.0962\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.3534 - val_loss: 0.5515\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.2382 - val_loss: 0.5241\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.4991 - val_loss: 5.6038\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.5425 - val_loss: 0.7787\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1015 - val_loss: 1.1326\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 1.3362 - val_loss: 2.0105\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 1.3940 - val_loss: 1.7014\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 3.4660 - val_loss: 9.2329\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1271 - val_loss: 0.3354\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.1004 - val_loss: 0.0636\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.0656 - val_loss: 1.8696\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.3366 - val_loss: 0.5222\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.5170 - val_loss: 2.0088\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.2748 - val_loss: 0.2850\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 1.9112 - val_loss: 2.4161\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 1.1783 - val_loss: 0.9886\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.4389 - val_loss: 0.7828\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7776 - val_loss: 1.7022\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0493 - val_loss: 0.1000\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.2405 - val_loss: 0.4240\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1684 - val_loss: 0.4667\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.1247 - val_loss: 1.1547\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.3338 - val_loss: 0.0845\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 1.4634 - val_loss: 2.8543\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.1108 - val_loss: 0.2727\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.3497 - val_loss: 0.5821\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1116 - val_loss: 1.3711\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1556 - val_loss: 0.2189\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.1952 - val_loss: 0.8931\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.5429 - val_loss: 1.5252\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1592 - val_loss: 0.1242\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 4.0425 - val_loss: 5.9271\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.0504 - val_loss: 0.2349\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 5.8024 - val_loss: 8.5182\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.1223 - val_loss: 1.3746\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.8411 - val_loss: 1.5198\n",
            "1/1 [==============================] - 1s 886ms/step - loss: 0.3019 - val_loss: 1.4429\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.4294 - val_loss: 2.2905\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 1.2409 - val_loss: 2.1536\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 5.1017 - val_loss: 9.6928\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.3316 - val_loss: 0.5759\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.3696 - val_loss: 0.0456\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.0506 - val_loss: 0.1138\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.1507 - val_loss: 0.4624\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2207 - val_loss: 0.4503\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.9168 - val_loss: 2.1603\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.7306 - val_loss: 0.7522\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 1.2776 - val_loss: 0.3852\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.2116 - val_loss: 0.9366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5375 - val_loss: 0.9326\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.0242 - val_loss: 0.0739\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6498 - val_loss: 1.6550\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.4929 - val_loss: 1.7342\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.1575 - val_loss: 0.6184\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 3.0691 - val_loss: 2.8170\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 3.1862 - val_loss: 7.7127\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1597 - val_loss: 0.0722\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.2264 - val_loss: 0.0230\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.0604 - val_loss: 0.2528\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.2046 - val_loss: 0.3104\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 3.1174 - val_loss: 5.1799\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.0757 - val_loss: 0.0332\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 2.0256 - val_loss: 4.3542\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 4.0106 - val_loss: 8.7099\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.1685 - val_loss: 0.2458\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3263 - val_loss: 0.6009\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0425 - val_loss: 0.1998\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.3834 - val_loss: 0.2434\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6927 - val_loss: 0.7078\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0803 - val_loss: 1.0184\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 2.4228 - val_loss: 1.8981\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 3.7617 - val_loss: 7.9011\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.7135 - val_loss: 2.3503\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.7952 - val_loss: 0.0479\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.2781 - val_loss: 1.0505\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.7944 - val_loss: 0.5857\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.3096 - val_loss: 0.5651\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2794 - val_loss: 0.3031\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.3251 - val_loss: 0.1287\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 1.4901 - val_loss: 0.5139\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.1437 - val_loss: 0.4107\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.5386 - val_loss: 0.4861\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0630 - val_loss: 0.1072\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2067 - val_loss: 0.7865\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.2102 - val_loss: 0.5667\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.0977 - val_loss: 0.4691\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 1.8203 - val_loss: 3.8206\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 2.0344 - val_loss: 0.6006\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1352 - val_loss: 0.2735\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1886 - val_loss: 0.5371\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.0860 - val_loss: 0.9870\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.3212 - val_loss: 0.5150\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.3415 - val_loss: 2.4186\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0135 - val_loss: 0.6856\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 1.2412 - val_loss: 1.8468\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 1.3539 - val_loss: 0.8338\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.2784 - val_loss: 0.5666\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2577 - val_loss: 0.0538\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2669 - val_loss: 1.1518\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.4542 - val_loss: 0.1455\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 1.8506 - val_loss: 5.9647\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.3345 - val_loss: 0.7288\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.2592 - val_loss: 0.8815\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 2.7174 - val_loss: 7.0082\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.1671 - val_loss: 0.8826\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 1.7616 - val_loss: 1.0506\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1572 - val_loss: 0.9081\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 2.2435 - val_loss: 0.9404\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.6426 - val_loss: 1.0109\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.6012 - val_loss: 3.1773\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.2865 - val_loss: 0.5685\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 4.5529 - val_loss: 8.2711\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.4479 - val_loss: 2.1228\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.2651 - val_loss: 0.1647\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.1308 - val_loss: 2.1353\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.4964 - val_loss: 2.0324\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0547 - val_loss: 0.6510\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.1588 - val_loss: 0.3074\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.0322 - val_loss: 0.0346\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 1.8098 - val_loss: 2.0641\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.0242 - val_loss: 0.0528\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.0838 - val_loss: 0.1585\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4586 - val_loss: 3.3870\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3692 - val_loss: 1.1394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.5567 - val_loss: 3.1820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3623 - val_loss: 0.8633\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4104 - val_loss: 1.5447\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7577 - val_loss: 4.3188\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.4686 - val_loss: 3.1271\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6711 - val_loss: 0.9818\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.2467 - val_loss: 1.6658\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.3863 - val_loss: 0.5852\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 1.4337 - val_loss: 2.2760\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1373 - val_loss: 1.8454\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.4475 - val_loss: 0.8872\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 4.1683 - val_loss: 5.0524\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0316 - val_loss: 0.4646\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.4676 - val_loss: 0.7444\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0607 - val_loss: 0.1444\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.7511 - val_loss: 4.3974\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.3938 - val_loss: 1.4681\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.5202 - val_loss: 0.7139\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.4183 - val_loss: 0.2224\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 1.2726 - val_loss: 3.0373\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1275 - val_loss: 0.5705\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.3412 - val_loss: 0.7161\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.0377 - val_loss: 0.3372\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.2891 - val_loss: 1.2258\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.3260 - val_loss: 2.0921\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.3130 - val_loss: 1.0389\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.4323 - val_loss: 0.7034\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 1.9800 - val_loss: 4.1231\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1107 - val_loss: 0.7634\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2875 - val_loss: 0.3444\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.0071 - val_loss: 0.0179\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.0777 - val_loss: 0.1599\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.0863 - val_loss: 0.0580\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.1328 - val_loss: 0.4219\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.1594 - val_loss: 0.1726\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.8862 - val_loss: 0.6253\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0482 - val_loss: 0.1021\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.2773 - val_loss: 0.4895\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0334 - val_loss: 0.1608\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1958 - val_loss: 0.1850\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.0652 - val_loss: 0.1639\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.1824 - val_loss: 1.5452\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.1312 - val_loss: 0.1042\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.9680 - val_loss: 1.5827\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1877 - val_loss: 0.2736\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.2013 - val_loss: 0.0918\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.4973 - val_loss: 3.3475\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.9117 - val_loss: 3.2490\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.9306 - val_loss: 2.1215\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.1737 - val_loss: 0.8758\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.3730 - val_loss: 0.4604\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.4825 - val_loss: 0.2612\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.2821 - val_loss: 0.6265\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5407 - val_loss: 0.8980\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0622 - val_loss: 0.6038\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 1.3894 - val_loss: 2.8248\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.3469 - val_loss: 1.7970\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2298 - val_loss: 1.4032\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 1.0022 - val_loss: 0.5904\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 1.2114 - val_loss: 0.8970\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.3672 - val_loss: 0.7739\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 1.4607 - val_loss: 0.2795\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0426 - val_loss: 0.0987\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.2379 - val_loss: 1.2357\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1486 - val_loss: 0.2047\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0154 - val_loss: 0.1393\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.5292 - val_loss: 0.0913\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 1.8608 - val_loss: 2.2876\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0269 - val_loss: 0.0611\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0986 - val_loss: 0.4597\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.6848 - val_loss: 5.2541\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.1904 - val_loss: 0.5522\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.1331 - val_loss: 0.6262\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0882 - val_loss: 0.3033\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.2190 - val_loss: 0.3732\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.7770 - val_loss: 0.6472\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.2007 - val_loss: 0.4285\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.6833 - val_loss: 1.9115\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.3933 - val_loss: 3.5217\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2572 - val_loss: 0.9410\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.4073 - val_loss: 7.2514\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.7022 - val_loss: 7.4751\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.5672 - val_loss: 0.7659\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.7733 - val_loss: 13.1536\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.4538 - val_loss: 1.7789\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3425 - val_loss: 3.0584\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2050 - val_loss: 1.7332\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1909 - val_loss: 0.2258\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.3943 - val_loss: 2.7272\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.9056 - val_loss: 0.9944\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 4.4696 - val_loss: 5.7698\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3310 - val_loss: 2.2351\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.2555 - val_loss: 0.8380\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 2.0809 - val_loss: 6.1993\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5244 - val_loss: 1.4882\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 2.5270 - val_loss: 4.6640\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.6203 - val_loss: 6.7764\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.0994 - val_loss: 0.8558\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.2023 - val_loss: 3.7507\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 4.8448 - val_loss: 9.3141\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4129 - val_loss: 1.9705\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.2593 - val_loss: 0.1489\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1618 - val_loss: 0.9992\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5144 - val_loss: 0.8312\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6389 - val_loss: 1.2209\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.5440 - val_loss: 0.5307\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.4612 - val_loss: 0.0826\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 1.7372 - val_loss: 0.6692\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.5607 - val_loss: 0.4241\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.2118 - val_loss: 0.9643\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.0585 - val_loss: 0.1665\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.1219 - val_loss: 0.1290\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.1846 - val_loss: 0.5509\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.4390 - val_loss: 1.7465\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.5181 - val_loss: 1.1579\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 4.9556 - val_loss: 10.4942\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.4013 - val_loss: 0.7000\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.2593 - val_loss: 0.6523\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.4621 - val_loss: 5.2761\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.5759 - val_loss: 0.7991\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.1101 - val_loss: 0.9866\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 1.2566 - val_loss: 1.9162\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 1.3499 - val_loss: 1.6239\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 3.1144 - val_loss: 8.1606\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.1167 - val_loss: 0.2356\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.2081 - val_loss: 0.1488\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0580 - val_loss: 1.3906\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2624 - val_loss: 0.3888\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.3727 - val_loss: 1.5617\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2840 - val_loss: 0.2934\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 1.7104 - val_loss: 2.2376\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 1.3173 - val_loss: 0.8196\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.3994 - val_loss: 0.7185\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.8453 - val_loss: 1.9075\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0555 - val_loss: 0.1279\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.2481 - val_loss: 0.4333\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.1717 - val_loss: 0.4814\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.1257 - val_loss: 0.9803\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.3247 - val_loss: 0.1127\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 1.1093 - val_loss: 2.2279\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.1034 - val_loss: 0.3076\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.3484 - val_loss: 0.6098\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1045 - val_loss: 1.2631\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.1528 - val_loss: 0.1750\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2030 - val_loss: 0.8934\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.6104 - val_loss: 1.6999\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.1971 - val_loss: 0.1651\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 3.8780 - val_loss: 5.5660\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0449 - val_loss: 0.2419\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.4689 - val_loss: 8.4465\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.0809 - val_loss: 1.0687\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7367 - val_loss: 1.4129\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.2609 - val_loss: 1.6103\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.4225 - val_loss: 2.1023\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 1.2031 - val_loss: 2.0600\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 4.6037 - val_loss: 8.5714\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.3093 - val_loss: 0.4964\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.3524 - val_loss: 0.0362\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.0493 - val_loss: 0.1281\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1524 - val_loss: 0.4617\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.2317 - val_loss: 0.4106\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 1.1638 - val_loss: 2.6192\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.6646 - val_loss: 0.6681\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 1.6830 - val_loss: 0.5826\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.2210 - val_loss: 0.9231\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.5482 - val_loss: 0.9288\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.0155 - val_loss: 0.0445\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6056 - val_loss: 1.4927\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.4428 - val_loss: 1.5420\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.2063 - val_loss: 0.5123\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 2.9975 - val_loss: 2.7117\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 2.9706 - val_loss: 7.1011\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1815 - val_loss: 0.1025\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.2632 - val_loss: 0.0205\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.0731 - val_loss: 0.3194\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.2785 - val_loss: 0.4207\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 2.8303 - val_loss: 4.6377\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0878 - val_loss: 0.0477\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 2.1574 - val_loss: 4.5780\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 3.5860 - val_loss: 7.4663\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.2252 - val_loss: 0.3305\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.3472 - val_loss: 0.5786\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0493 - val_loss: 0.2263\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4134 - val_loss: 0.2882\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6469 - val_loss: 0.6475\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0782 - val_loss: 1.0033\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 2.2963 - val_loss: 1.7646\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 3.6722 - val_loss: 7.6276\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.6952 - val_loss: 2.2813\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.7918 - val_loss: 0.0453\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.3150 - val_loss: 1.1732\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.7558 - val_loss: 0.5358\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.3876 - val_loss: 0.6253\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.2560 - val_loss: 0.3041\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.3616 - val_loss: 0.1058\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 1.6256 - val_loss: 0.3682\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.1543 - val_loss: 0.4681\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.4795 - val_loss: 0.4535\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0688 - val_loss: 0.1188\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.2116 - val_loss: 0.7824\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.2321 - val_loss: 0.5951\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1037 - val_loss: 0.4169\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7721 - val_loss: 3.7575\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 1.8446 - val_loss: 0.3702\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.1318 - val_loss: 0.2692\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1814 - val_loss: 0.5950\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0807 - val_loss: 0.8828\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.2825 - val_loss: 0.4385\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.3187 - val_loss: 2.3089\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.0149 - val_loss: 0.8007\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 1.2600 - val_loss: 1.8770\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 1.3843 - val_loss: 0.8811\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.2545 - val_loss: 0.5089\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.2255 - val_loss: 0.0357\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.3011 - val_loss: 1.2554\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4654 - val_loss: 0.1495\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 1.8197 - val_loss: 5.9077\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.2756 - val_loss: 0.7840\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.2631 - val_loss: 0.9272\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 2.5681 - val_loss: 6.0454\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1554 - val_loss: 0.8129\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 1.7363 - val_loss: 1.0194\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.1628 - val_loss: 0.9458\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 2.2130 - val_loss: 0.9693\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6617 - val_loss: 1.0480\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.6627 - val_loss: 3.4361\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.3318 - val_loss: 0.4787\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 4.2602 - val_loss: 7.5223\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.4377 - val_loss: 2.3116\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.3249 - val_loss: 0.2185\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.1380 - val_loss: 2.1550\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.4946 - val_loss: 1.9962\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.0497 - val_loss: 0.5429\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.0802 - val_loss: 0.1771\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0488 - val_loss: 0.0364\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 1.7422 - val_loss: 2.0032\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.0197 - val_loss: 0.0399\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0809 - val_loss: 0.1298\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.4445 - val_loss: 3.3517\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.3562 - val_loss: 1.0907\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 1.5013 - val_loss: 3.1526\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.3831 - val_loss: 0.9344\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3843 - val_loss: 1.5043\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7395 - val_loss: 3.8669\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.4962 - val_loss: 3.2159\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.1817 - val_loss: 0.3796\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0260 - val_loss: 0.3750\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.2864 - val_loss: 0.4282\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.7407 - val_loss: 1.3978\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.1007 - val_loss: 2.1141\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.2718 - val_loss: 0.8279\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 3.5955 - val_loss: 3.9018\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.0368 - val_loss: 0.2156\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.3934 - val_loss: 0.6653\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.0474 - val_loss: 0.1783\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8528 - val_loss: 4.7637\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.5224 - val_loss: 1.9034\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.4453 - val_loss: 0.8091\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6340 - val_loss: 0.1469\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 1.0270 - val_loss: 2.4265\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.0711 - val_loss: 0.5466\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.4426 - val_loss: 0.8716\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0411 - val_loss: 0.3826\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.3718 - val_loss: 1.3773\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.3273 - val_loss: 2.2421\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3457 - val_loss: 1.2024\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.3162 - val_loss: 0.5462\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 1.8581 - val_loss: 3.5249\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1151 - val_loss: 0.7835\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.2272 - val_loss: 0.2907\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.0149 - val_loss: 0.0335\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0924 - val_loss: 0.2174\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0434 - val_loss: 0.0203\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.0477 - val_loss: 0.2063\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1368 - val_loss: 0.0811\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.0190 - val_loss: 0.6717\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.0536 - val_loss: 0.0988\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.2345 - val_loss: 0.4503\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.0360 - val_loss: 0.1267\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.2184 - val_loss: 0.2424\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.0658 - val_loss: 0.1524\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.2567 - val_loss: 2.0868\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1252 - val_loss: 0.1047\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 1.0813 - val_loss: 1.4862\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.2073 - val_loss: 0.2848\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.0991 - val_loss: 0.0359\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.4598 - val_loss: 3.2162\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.7902 - val_loss: 3.1647\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 1.0645 - val_loss: 2.4774\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.1498 - val_loss: 0.7604\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.4119 - val_loss: 0.4824\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.4915 - val_loss: 0.2508\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1973 - val_loss: 0.4533\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6627 - val_loss: 1.1640\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.0539 - val_loss: 0.5095\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3162 - val_loss: 2.6772\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.3048 - val_loss: 1.7152\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.2476 - val_loss: 1.5706\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.8833 - val_loss: 0.6857\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1884 - val_loss: 0.8524\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.4087 - val_loss: 0.8911\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 1.4458 - val_loss: 0.2688\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.0485 - val_loss: 0.0999\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.2449 - val_loss: 1.2456\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.1433 - val_loss: 0.2259\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0149 - val_loss: 0.1258\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.4429 - val_loss: 0.1400\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 1.7133 - val_loss: 1.9009\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.0312 - val_loss: 0.0409\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1247 - val_loss: 0.3471\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.6560 - val_loss: 5.1123\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1854 - val_loss: 0.4722\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.1092 - val_loss: 0.5476\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.0826 - val_loss: 0.3281\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.2191 - val_loss: 0.3390\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.7902 - val_loss: 0.5314\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.1951 - val_loss: 0.3796\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.5066 - val_loss: 1.7339\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.3230 - val_loss: 3.2473\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.2203 - val_loss: 0.8883\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.3864 - val_loss: 7.2162\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.4865 - val_loss: 6.0263\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.5800 - val_loss: 0.8317\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 5.0250 - val_loss: 11.2227\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4529 - val_loss: 1.8345\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3522 - val_loss: 2.9304\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.2040 - val_loss: 1.6898\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.1769 - val_loss: 0.2084\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.3705 - val_loss: 2.6684\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.9668 - val_loss: 0.8906\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 4.2349 - val_loss: 5.3626\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 1.2396 - val_loss: 2.0523\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.2613 - val_loss: 0.8652\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 1.9439 - val_loss: 5.7282\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.5709 - val_loss: 1.1229\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 2.0075 - val_loss: 3.9177\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.5853 - val_loss: 6.1959\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.1316 - val_loss: 1.1111\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 3.1839 - val_loss: 3.6099\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 4.6796 - val_loss: 8.7031\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4221 - val_loss: 2.0691\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2725 - val_loss: 0.2061\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1659 - val_loss: 1.0716\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.4985 - val_loss: 0.8515\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.6253 - val_loss: 1.3249\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.6473 - val_loss: 0.3392\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.4189 - val_loss: 0.1486\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 1.9814 - val_loss: 0.9576\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.6345 - val_loss: 0.4626\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.3072 - val_loss: 0.8016\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0679 - val_loss: 0.1989\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.1171 - val_loss: 0.1283\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.2123 - val_loss: 0.6862\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.3874 - val_loss: 1.5276\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.4861 - val_loss: 1.1567\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 4.3902 - val_loss: 9.5796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3573 - val_loss: 0.7723\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2829 - val_loss: 0.7440\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4597 - val_loss: 5.2956\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6458 - val_loss: 0.9034\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.1396 - val_loss: 0.7391\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 1.5376 - val_loss: 2.1718\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 1.1070 - val_loss: 1.3663\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 2.9700 - val_loss: 7.9911\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.1229 - val_loss: 0.1929\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2751 - val_loss: 0.2089\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0585 - val_loss: 1.2815\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.2309 - val_loss: 0.2930\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.3509 - val_loss: 1.5444\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2722 - val_loss: 0.4271\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 2.1060 - val_loss: 2.6781\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 1.4704 - val_loss: 0.6732\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.3802 - val_loss: 0.7400\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.7491 - val_loss: 1.6455\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0684 - val_loss: 0.1236\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.2333 - val_loss: 0.3902\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1657 - val_loss: 0.4706\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.1512 - val_loss: 1.0551\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.3364 - val_loss: 0.0916\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.9352 - val_loss: 1.8854\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.1098 - val_loss: 0.3190\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.3487 - val_loss: 0.5776\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.1025 - val_loss: 1.2400\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.1628 - val_loss: 0.1809\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.1870 - val_loss: 0.8286\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6497 - val_loss: 1.8575\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2041 - val_loss: 0.1440\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 4.0712 - val_loss: 5.2654\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.0487 - val_loss: 0.2128\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 5.2003 - val_loss: 8.3297\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.0710 - val_loss: 0.9866\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7319 - val_loss: 1.4296\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 0.2561 - val_loss: 1.6277\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.4157 - val_loss: 1.7042\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 1.1550 - val_loss: 1.9265\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 4.0690 - val_loss: 7.4694\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2918 - val_loss: 0.4537\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.3120 - val_loss: 0.0256\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.0408 - val_loss: 0.1413\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.1478 - val_loss: 0.4944\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.2341 - val_loss: 0.4050\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 1.0721 - val_loss: 2.4767\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.6743 - val_loss: 0.6904\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 1.7434 - val_loss: 0.5915\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2285 - val_loss: 1.0148\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5205 - val_loss: 0.8723\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.0078 - val_loss: 0.0236\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.5563 - val_loss: 1.3356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4533 - val_loss: 1.5212\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.0640 - val_loss: 0.5543\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 2.9704 - val_loss: 2.6335\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 3.1345 - val_loss: 7.4353\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.1787 - val_loss: 0.1005\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.2320 - val_loss: 0.0207\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.0331 - val_loss: 0.1562\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.2114 - val_loss: 0.3155\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 2.9925 - val_loss: 4.7940\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.0763 - val_loss: 0.0393\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 2.1550 - val_loss: 4.5464\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 3.6742 - val_loss: 7.4209\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.1798 - val_loss: 0.2613\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.3433 - val_loss: 0.4811\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.0443 - val_loss: 0.2041\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.4096 - val_loss: 0.2887\n",
            "1/1 [==============================] - 1s 886ms/step - loss: 0.6101 - val_loss: 0.6334\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.0818 - val_loss: 1.1049\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 2.0715 - val_loss: 1.5769\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 3.4522 - val_loss: 6.9804\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.6751 - val_loss: 2.2453\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.7399 - val_loss: 0.0527\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.2990 - val_loss: 1.1000\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.6835 - val_loss: 0.4496\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.4121 - val_loss: 0.5933\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.3025 - val_loss: 0.3460\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.3669 - val_loss: 0.0916\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 1.7777 - val_loss: 0.3379\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.1435 - val_loss: 0.4272\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.4352 - val_loss: 0.3984\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0565 - val_loss: 0.1018\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.2239 - val_loss: 0.8038\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.2532 - val_loss: 0.6336\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.1901 - val_loss: 0.2922\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 1.6080 - val_loss: 3.4448\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 1.8456 - val_loss: 0.2781\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.1447 - val_loss: 0.3033\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1959 - val_loss: 0.5671\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.0802 - val_loss: 0.8236\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.2683 - val_loss: 0.3697\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.3238 - val_loss: 2.3123\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.0230 - val_loss: 0.8415\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 1.1714 - val_loss: 1.6714\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.4171 - val_loss: 0.8886\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.2520 - val_loss: 0.4838\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.2139 - val_loss: 0.0388\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.3120 - val_loss: 1.2535\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.5128 - val_loss: 0.1927\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 1.9312 - val_loss: 6.1727\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.2418 - val_loss: 0.7920\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2560 - val_loss: 0.9450\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 2.5438 - val_loss: 6.6680\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.1446 - val_loss: 0.7084\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 1.7372 - val_loss: 1.0458\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1670 - val_loss: 0.9932\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 2.1795 - val_loss: 1.0100\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.7212 - val_loss: 1.0952\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.6759 - val_loss: 3.5021\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.3704 - val_loss: 0.4466\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 4.1243 - val_loss: 7.3533\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.4096 - val_loss: 2.3773\n",
            "1/1 [==============================] - 1s 893ms/step - loss: 0.2593 - val_loss: 0.1587\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1170 - val_loss: 1.9476\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.4540 - val_loss: 1.8390\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0625 - val_loss: 0.5791\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.0788 - val_loss: 0.2003\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0432 - val_loss: 0.0356\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 1.8457 - val_loss: 2.1222\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.0247 - val_loss: 0.0476\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.0791 - val_loss: 0.1412\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.4452 - val_loss: 3.3589\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.3556 - val_loss: 1.1075\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 1.4599 - val_loss: 3.1530\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.3637 - val_loss: 0.8528\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3211 - val_loss: 1.4125\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7723 - val_loss: 3.7483\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.4938 - val_loss: 3.3791\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.7958 - val_loss: 1.3901\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.2481 - val_loss: 1.4761\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2973 - val_loss: 0.3673\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 1.0576 - val_loss: 1.4210\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.1085 - val_loss: 1.8684\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.2708 - val_loss: 0.8422\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 3.6904 - val_loss: 3.9804\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1710 - val_loss: 0.8815\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.3874 - val_loss: 0.6067\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0290 - val_loss: 0.0675\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.6490 - val_loss: 4.0970\n",
            "1/1 [==============================] - 1s 886ms/step - loss: 0.4514 - val_loss: 1.6921\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.4102 - val_loss: 0.6123\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.4651 - val_loss: 0.2077\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 1.0857 - val_loss: 2.5411\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.0710 - val_loss: 0.4591\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.3899 - val_loss: 0.8132\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0433 - val_loss: 0.4442\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.3822 - val_loss: 1.3645\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.3688 - val_loss: 2.4280\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2601 - val_loss: 0.7993\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.2572 - val_loss: 0.4607\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 1.8165 - val_loss: 2.7955\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1188 - val_loss: 0.6857\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.1914 - val_loss: 0.2486\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.0079 - val_loss: 0.0230\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.0841 - val_loss: 0.1792\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.0611 - val_loss: 0.0284\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1057 - val_loss: 0.3549\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.1429 - val_loss: 0.1161\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 1.1576 - val_loss: 0.6973\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.0555 - val_loss: 0.1205\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.2324 - val_loss: 0.4531\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0343 - val_loss: 0.1060\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2193 - val_loss: 0.2764\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.0668 - val_loss: 0.1657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2695 - val_loss: 2.1767\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.1302 - val_loss: 0.0882\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 1.1008 - val_loss: 1.4534\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.2071 - val_loss: 0.2986\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.1232 - val_loss: 0.0561\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.4437 - val_loss: 3.0459\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.7712 - val_loss: 3.0052\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 1.0457 - val_loss: 2.4078\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.1604 - val_loss: 0.7948\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.3848 - val_loss: 0.4421\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.4433 - val_loss: 0.2017\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.2318 - val_loss: 0.5271\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.5864 - val_loss: 1.0023\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.0636 - val_loss: 0.5298\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 1.2851 - val_loss: 2.5887\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.3421 - val_loss: 1.7828\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.2947 - val_loss: 1.7730\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 1.0113 - val_loss: 0.5611\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 1.1604 - val_loss: 0.9123\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.4087 - val_loss: 0.8484\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 1.5370 - val_loss: 0.3042\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.0504 - val_loss: 0.1046\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2506 - val_loss: 1.2367\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.1327 - val_loss: 0.2334\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0205 - val_loss: 0.1406\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.3955 - val_loss: 0.1670\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 1.7346 - val_loss: 2.0407\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.0285 - val_loss: 0.0440\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.1249 - val_loss: 0.3536\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6331 - val_loss: 4.9654\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1738 - val_loss: 0.4526\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.1124 - val_loss: 0.5490\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1055 - val_loss: 0.4491\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.2174 - val_loss: 0.3616\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.7848 - val_loss: 0.5794\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1958 - val_loss: 0.4057\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.5622 - val_loss: 1.8281\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.3519 - val_loss: 3.4381\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.2408 - val_loss: 0.9949\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.4330 - val_loss: 7.5019\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 0.4714 - val_loss: 5.8823\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6124 - val_loss: 0.9656\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 4.7779 - val_loss: 10.1577\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.4575 - val_loss: 1.8743\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.3493 - val_loss: 2.8180\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.2011 - val_loss: 1.6310\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1848 - val_loss: 0.2095\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.3791 - val_loss: 2.7039\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.9319 - val_loss: 1.0126\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 4.0912 - val_loss: 4.9231\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 1.2220 - val_loss: 2.0405\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.2585 - val_loss: 0.8530\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 1.8992 - val_loss: 5.6498\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.5628 - val_loss: 1.1612\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 2.0252 - val_loss: 3.9856\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.5552 - val_loss: 6.3763\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.1229 - val_loss: 0.9774\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 2.8995 - val_loss: 3.2905\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 4.3545 - val_loss: 8.3989\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.4311 - val_loss: 2.1344\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.2780 - val_loss: 0.2041\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.1573 - val_loss: 0.9089\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.4560 - val_loss: 0.7496\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.4889 - val_loss: 1.1032\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6033 - val_loss: 0.4451\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.4547 - val_loss: 0.0907\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 1.9378 - val_loss: 0.9214\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5469 - val_loss: 0.4334\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.2488 - val_loss: 0.9182\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0512 - val_loss: 0.1505\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.1219 - val_loss: 0.1380\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2008 - val_loss: 0.6461\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.3889 - val_loss: 1.3743\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.4812 - val_loss: 1.0817\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 3.9098 - val_loss: 8.7537\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.3600 - val_loss: 0.7932\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.2795 - val_loss: 0.7657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4289 - val_loss: 4.9877\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.5842 - val_loss: 0.8293\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.1442 - val_loss: 0.7361\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4353 - val_loss: 2.1146\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 1.0758 - val_loss: 1.3160\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 2.7706 - val_loss: 7.4612\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.1206 - val_loss: 0.1164\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.3776 - val_loss: 0.3226\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.0692 - val_loss: 1.0135\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.2183 - val_loss: 0.2490\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.2948 - val_loss: 1.2218\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.2713 - val_loss: 0.3500\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 1.5909 - val_loss: 2.2219\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 1.5399 - val_loss: 0.6445\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.3468 - val_loss: 0.6721\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.7723 - val_loss: 1.8505\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.0717 - val_loss: 0.1473\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.2514 - val_loss: 0.4384\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.1694 - val_loss: 0.4467\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.1683 - val_loss: 0.7998\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.3033 - val_loss: 0.1617\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.7744 - val_loss: 1.3365\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0987 - val_loss: 0.3296\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.3041 - val_loss: 0.5402\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0982 - val_loss: 1.2080\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.1450 - val_loss: 0.1437\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.1921 - val_loss: 0.8339\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6830 - val_loss: 1.9818\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.2339 - val_loss: 0.1681\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 4.0508 - val_loss: 5.1416\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0482 - val_loss: 0.2461\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 4.8211 - val_loss: 7.8118\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.0640 - val_loss: 0.7966\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6749 - val_loss: 1.3029\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.2300 - val_loss: 1.9971\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.4300 - val_loss: 1.7513\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 1.1603 - val_loss: 2.2256\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 3.8887 - val_loss: 6.8758\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.3391 - val_loss: 0.4953\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.3388 - val_loss: 0.0355\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.0396 - val_loss: 0.1416\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.1483 - val_loss: 0.5188\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.2458 - val_loss: 0.3959\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 1.2766 - val_loss: 2.9093\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.6076 - val_loss: 0.6028\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 2.1198 - val_loss: 0.8170\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.2548 - val_loss: 1.0789\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.5023 - val_loss: 0.8483\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0031 - val_loss: 0.0057\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.5074 - val_loss: 1.2021\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.4772 - val_loss: 1.5252\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.0816 - val_loss: 0.4329\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9813 - val_loss: 2.5910\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 2.9615 - val_loss: 6.9839\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.1822 - val_loss: 0.1263\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.2275 - val_loss: 0.0210\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.0336 - val_loss: 0.1796\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.2325 - val_loss: 0.3562\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 2.8077 - val_loss: 4.4323\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0887 - val_loss: 0.0543\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 2.2951 - val_loss: 4.7819\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 3.3334 - val_loss: 6.5067\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2141 - val_loss: 0.3142\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3685 - val_loss: 0.4283\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.0499 - val_loss: 0.2293\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.4400 - val_loss: 0.3345\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5483 - val_loss: 0.5889\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.0868 - val_loss: 1.2468\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 1.9213 - val_loss: 1.4181\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 3.4938 - val_loss: 7.1368\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.6534 - val_loss: 2.1371\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.7394 - val_loss: 0.0560\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.3182 - val_loss: 1.1525\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.6339 - val_loss: 0.3978\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.4786 - val_loss: 0.6450\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.2796 - val_loss: 0.3545\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.4043 - val_loss: 0.0828\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 1.8342 - val_loss: 0.3180\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1466 - val_loss: 0.4007\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.4180 - val_loss: 0.4270\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0480 - val_loss: 0.0984\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2225 - val_loss: 0.8009\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2805 - val_loss: 0.6834\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.2237 - val_loss: 0.2855\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 1.7495 - val_loss: 3.5103\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 1.7961 - val_loss: 0.2246\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1416 - val_loss: 0.3119\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.1969 - val_loss: 0.6239\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.0806 - val_loss: 0.7773\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.2498 - val_loss: 0.3240\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.3248 - val_loss: 2.2871\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.0244 - val_loss: 0.9739\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 1.2003 - val_loss: 1.7188\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 1.4647 - val_loss: 0.9937\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.2318 - val_loss: 0.4413\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2022 - val_loss: 0.0471\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.3340 - val_loss: 1.3235\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.5160 - val_loss: 0.1935\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8761 - val_loss: 6.0356\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.1960 - val_loss: 0.8302\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.2754 - val_loss: 0.9661\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 2.4299 - val_loss: 6.1268\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.1434 - val_loss: 0.6966\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 1.6732 - val_loss: 0.9446\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1620 - val_loss: 0.9027\n",
            "1/1 [==============================] - 1s 886ms/step - loss: 2.1793 - val_loss: 1.0134\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.7101 - val_loss: 1.1125\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6534 - val_loss: 3.4035\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.4152 - val_loss: 0.3888\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 3.8832 - val_loss: 6.8962\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.4158 - val_loss: 2.3965\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2571 - val_loss: 0.1540\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1246 - val_loss: 2.0242\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4649 - val_loss: 1.8688\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0544 - val_loss: 0.5318\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0531 - val_loss: 0.1473\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.0523 - val_loss: 0.0397\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 1.8045 - val_loss: 2.0597\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.0235 - val_loss: 0.0450\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.0802 - val_loss: 0.1082\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.4246 - val_loss: 3.2617\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.3320 - val_loss: 0.9954\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3449 - val_loss: 2.9318\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4269 - val_loss: 1.0859\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3680 - val_loss: 1.5132\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 2.7356 - val_loss: 3.7621\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.4793 - val_loss: 3.2417\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2757 - val_loss: 0.5975\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0427 - val_loss: 0.6643\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.2791 - val_loss: 0.3934\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6435 - val_loss: 1.1870\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.1349 - val_loss: 1.0547\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.2946 - val_loss: 0.7763\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 2.2163 - val_loss: 2.4879\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0453 - val_loss: 0.3793\n",
            "1/1 [==============================] - 1s 914ms/step - loss: 0.4166 - val_loss: 0.6422\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0269 - val_loss: 0.0858\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.6678 - val_loss: 4.0513\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 0.4920 - val_loss: 1.8330\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.4027 - val_loss: 0.6786\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.4919 - val_loss: 0.1736\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 1.0389 - val_loss: 2.3418\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.0542 - val_loss: 0.4210\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4079 - val_loss: 0.8503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0441 - val_loss: 0.4527\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3983 - val_loss: 1.4608\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.3508 - val_loss: 2.4078\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.2732 - val_loss: 0.8992\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.2499 - val_loss: 0.4406\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 1.8210 - val_loss: 2.7196\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.1216 - val_loss: 0.6992\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1733 - val_loss: 0.2295\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.0090 - val_loss: 0.0244\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0861 - val_loss: 0.1861\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.0374 - val_loss: 0.0202\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.0462 - val_loss: 0.1876\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1539 - val_loss: 0.1024\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 1.2529 - val_loss: 0.7774\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0483 - val_loss: 0.1055\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2388 - val_loss: 0.4652\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.0321 - val_loss: 0.1074\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.2196 - val_loss: 0.2433\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.0664 - val_loss: 0.1411\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.2738 - val_loss: 2.1469\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.1218 - val_loss: 0.0884\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 1.1151 - val_loss: 1.4578\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.2062 - val_loss: 0.2634\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.1040 - val_loss: 0.0616\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.4143 - val_loss: 2.8699\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.7109 - val_loss: 2.8092\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 1.1131 - val_loss: 2.5577\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1723 - val_loss: 0.7740\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.4051 - val_loss: 0.4572\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.5117 - val_loss: 0.3125\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.2049 - val_loss: 0.4683\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6097 - val_loss: 1.0572\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0556 - val_loss: 0.4899\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 1.2786 - val_loss: 2.5846\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.3172 - val_loss: 1.8156\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.2631 - val_loss: 1.6603\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.9901 - val_loss: 0.5640\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 1.2165 - val_loss: 1.0523\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.4020 - val_loss: 0.8611\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 1.5429 - val_loss: 0.2774\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0473 - val_loss: 0.0941\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2468 - val_loss: 1.1860\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1344 - val_loss: 0.2307\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0194 - val_loss: 0.1402\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.3906 - val_loss: 0.1840\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 1.8701 - val_loss: 2.4465\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0276 - val_loss: 0.0444\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.1303 - val_loss: 0.3401\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.6146 - val_loss: 4.8735\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1662 - val_loss: 0.4289\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.1121 - val_loss: 0.5538\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.0952 - val_loss: 0.3956\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.2195 - val_loss: 0.3731\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.6531 - val_loss: 0.6900\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 0.2097 - val_loss: 0.4508\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.5512 - val_loss: 1.8320\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.3760 - val_loss: 3.5756\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2463 - val_loss: 1.0365\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.4532 - val_loss: 7.6790\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.5236 - val_loss: 6.0877\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6628 - val_loss: 1.1178\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 4.7252 - val_loss: 9.4347\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.4269 - val_loss: 1.8664\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3450 - val_loss: 2.8018\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.2153 - val_loss: 1.7962\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.1497 - val_loss: 0.1365\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.3453 - val_loss: 2.7075\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 1.0776 - val_loss: 0.7609\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 4.1311 - val_loss: 5.0122\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 1.1326 - val_loss: 1.6016\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2585 - val_loss: 0.8368\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 1.8667 - val_loss: 5.4991\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.5825 - val_loss: 1.1739\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 1.8878 - val_loss: 3.7214\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.5491 - val_loss: 6.1426\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.1213 - val_loss: 1.0426\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 2.8089 - val_loss: 3.1215\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 4.2058 - val_loss: 8.2115\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.4178 - val_loss: 2.2051\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.3091 - val_loss: 0.2499\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1562 - val_loss: 0.7620\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.3791 - val_loss: 0.6255\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.3615 - val_loss: 0.9101\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5177 - val_loss: 0.5546\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.5168 - val_loss: 0.0516\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 1.9215 - val_loss: 0.9492\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.4498 - val_loss: 0.3857\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.2416 - val_loss: 0.9412\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0435 - val_loss: 0.1445\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.1257 - val_loss: 0.1464\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.2129 - val_loss: 0.7240\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.4013 - val_loss: 1.2094\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4671 - val_loss: 1.0188\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 3.5999 - val_loss: 7.9220\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.3475 - val_loss: 0.7199\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.2931 - val_loss: 0.7815\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.4294 - val_loss: 4.9783\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.5380 - val_loss: 0.7747\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.1500 - val_loss: 0.7664\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 1.2405 - val_loss: 1.8611\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 0.9676 - val_loss: 1.1940\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 2.6754 - val_loss: 7.3906\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.1183 - val_loss: 0.0743\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.4059 - val_loss: 0.3668\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.0820 - val_loss: 0.8248\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.2121 - val_loss: 0.2068\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.2832 - val_loss: 1.0775\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.3252 - val_loss: 0.2905\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 1.1204 - val_loss: 1.8277\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 1.6372 - val_loss: 0.5841\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.3441 - val_loss: 0.6567\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.8009 - val_loss: 2.0427\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.1052 - val_loss: 0.2826\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.2730 - val_loss: 0.4610\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.1807 - val_loss: 0.4949\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.3720 - val_loss: 0.3980\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.3042 - val_loss: 0.2220\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.7429 - val_loss: 0.7806\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.0990 - val_loss: 0.3677\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.2772 - val_loss: 0.5047\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.0912 - val_loss: 1.1253\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1385 - val_loss: 0.1091\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.1885 - val_loss: 0.8014\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.5937 - val_loss: 1.7215\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.2711 - val_loss: 0.1930\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 3.4327 - val_loss: 4.7765\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0526 - val_loss: 0.2785\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 4.5845 - val_loss: 7.3301\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.0650 - val_loss: 0.6343\n",
            "1/1 [==============================] - 1s 1000ms/step - loss: 0.6517 - val_loss: 1.2220\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2247 - val_loss: 2.3507\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5003 - val_loss: 2.3311\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 1.2091 - val_loss: 2.6239\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 4.0508 - val_loss: 7.0983\n",
            "1/1 [==============================] - 1s 886ms/step - loss: 0.4423 - val_loss: 0.6825\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.4031 - val_loss: 0.0619\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.0535 - val_loss: 0.1094\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.1634 - val_loss: 0.5095\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.2588 - val_loss: 0.3249\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 1.1745 - val_loss: 2.6732\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.5388 - val_loss: 0.5068\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 2.1651 - val_loss: 0.9003\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.2296 - val_loss: 1.0630\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4926 - val_loss: 0.7982\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0076 - val_loss: 0.0379\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4807 - val_loss: 1.1447\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.4334 - val_loss: 1.4667\n",
            "1/1 [==============================] - 1s 1000ms/step - loss: 0.0890 - val_loss: 0.3617\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 2.9682 - val_loss: 2.6288\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 2.6527 - val_loss: 5.9227\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.1550 - val_loss: 0.1348\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.1708 - val_loss: 0.0378\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.0337 - val_loss: 0.1851\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2096 - val_loss: 0.3183\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.8131 - val_loss: 4.4964\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0951 - val_loss: 0.0597\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 2.1904 - val_loss: 4.5891\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 3.3556 - val_loss: 6.4840\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1789 - val_loss: 0.2521\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.3575 - val_loss: 0.2846\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.0370 - val_loss: 0.1552\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3843 - val_loss: 0.2721\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5628 - val_loss: 0.6799\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0891 - val_loss: 1.2292\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 1.7919 - val_loss: 1.3566\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 3.4013 - val_loss: 7.1707\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.6516 - val_loss: 2.2196\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.6738 - val_loss: 0.0721\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.3109 - val_loss: 1.1146\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.5363 - val_loss: 0.3018\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.5455 - val_loss: 0.6106\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.3109 - val_loss: 0.4443\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.3618 - val_loss: 0.0683\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 1.8067 - val_loss: 0.3337\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1406 - val_loss: 0.4288\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3311 - val_loss: 0.2952\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0482 - val_loss: 0.0897\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.2494 - val_loss: 0.8286\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3127 - val_loss: 0.7165\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.1348 - val_loss: 0.3059\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 1.4230 - val_loss: 3.1050\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 1.7252 - val_loss: 0.1882\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.1002 - val_loss: 0.2194\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1672 - val_loss: 0.5969\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0733 - val_loss: 0.7018\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.2313 - val_loss: 0.3041\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.3024 - val_loss: 2.1997\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.0639 - val_loss: 0.7258\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 1.1898 - val_loss: 1.7330\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 1.4523 - val_loss: 1.0021\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.2243 - val_loss: 0.4335\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.2093 - val_loss: 0.0614\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3560 - val_loss: 1.4757\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4425 - val_loss: 0.1501\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7942 - val_loss: 5.8400\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.3128 - val_loss: 0.8541\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.2617 - val_loss: 0.9559\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 2.3942 - val_loss: 5.4505\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.1382 - val_loss: 0.6784\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 1.7537 - val_loss: 1.0487\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1676 - val_loss: 1.0140\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 2.0855 - val_loss: 1.1676\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.7293 - val_loss: 1.0902\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.5871 - val_loss: 3.2447\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.5856 - val_loss: 0.2800\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 3.7659 - val_loss: 6.5947\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.4194 - val_loss: 2.4033\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.3129 - val_loss: 0.2050\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.1205 - val_loss: 1.9416\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.4396 - val_loss: 1.7522\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0614 - val_loss: 0.4542\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0465 - val_loss: 0.1351\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.0740 - val_loss: 0.0534\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 1.8084 - val_loss: 2.1049\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0244 - val_loss: 0.0403\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.0825 - val_loss: 0.0915\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.4303 - val_loss: 3.3208\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.3275 - val_loss: 0.9790\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 1.2428 - val_loss: 2.8404\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3936 - val_loss: 0.9961\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3597 - val_loss: 1.5154\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6850 - val_loss: 3.4845\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4838 - val_loss: 3.3064\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2923 - val_loss: 0.8053\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.0804 - val_loss: 0.8209\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.2448 - val_loss: 0.3541\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6700 - val_loss: 1.1782\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.1381 - val_loss: 0.9688\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.2480 - val_loss: 0.7320\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8746 - val_loss: 2.0318\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.0967 - val_loss: 0.5642\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3492 - val_loss: 0.5919\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.0152 - val_loss: 0.0386\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.5710 - val_loss: 3.6716\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.4906 - val_loss: 1.8452\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.3058 - val_loss: 0.5430\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.4388 - val_loss: 0.1311\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 1.1250 - val_loss: 2.7516\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0671 - val_loss: 0.5002\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.3772 - val_loss: 0.7827\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0467 - val_loss: 0.4960\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4074 - val_loss: 1.4379\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.3914 - val_loss: 2.6150\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.2820 - val_loss: 0.9157\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1842 - val_loss: 0.3365\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 1.7788 - val_loss: 2.4020\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 0.1266 - val_loss: 0.6319\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.1425 - val_loss: 0.1925\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.0084 - val_loss: 0.0253\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.0860 - val_loss: 0.1852\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0418 - val_loss: 0.0195\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.0361 - val_loss: 0.1450\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.1522 - val_loss: 0.1237\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 1.1946 - val_loss: 0.7365\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0501 - val_loss: 0.1151\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2289 - val_loss: 0.4554\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.0330 - val_loss: 0.0994\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.2257 - val_loss: 0.2479\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.0667 - val_loss: 0.1403\n",
            "1/1 [==============================] - 1s 909ms/step - loss: 0.3253 - val_loss: 2.3589\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.1176 - val_loss: 0.1062\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.9774 - val_loss: 1.5990\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1970 - val_loss: 0.2533\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0879 - val_loss: 0.0884\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.3834 - val_loss: 2.6624\n",
            "1/1 [==============================] - 1s 887ms/step - loss: 0.6437 - val_loss: 2.6917\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 1.2108 - val_loss: 2.7836\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.1802 - val_loss: 0.7679\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4519 - val_loss: 0.4654\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6492 - val_loss: 0.4948\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1651 - val_loss: 0.3813\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6874 - val_loss: 1.2387\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - val_loss: 0.4432\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 1.2708 - val_loss: 2.6228\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.2912 - val_loss: 1.8911\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.2447 - val_loss: 1.6109\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.9370 - val_loss: 0.6008\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 1.2820 - val_loss: 1.2165\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.3594 - val_loss: 0.8153\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 1.6230 - val_loss: 0.2421\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.0350 - val_loss: 0.1093\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.2135 - val_loss: 1.2389\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.1169 - val_loss: 0.1852\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.0210 - val_loss: 0.1202\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.3722 - val_loss: 0.2059\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7259 - val_loss: 2.1175\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.0246 - val_loss: 0.0483\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.1221 - val_loss: 0.3546\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6007 - val_loss: 4.7196\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.1607 - val_loss: 0.3906\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1126 - val_loss: 0.5115\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1092 - val_loss: 0.4566\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.2234 - val_loss: 0.3591\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.6234 - val_loss: 0.6983\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.1872 - val_loss: 0.3931\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.5081 - val_loss: 1.7109\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.3421 - val_loss: 3.3539\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2285 - val_loss: 0.9778\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.4209 - val_loss: 7.4577\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.4275 - val_loss: 5.5386\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.6451 - val_loss: 1.0446\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 4.8156 - val_loss: 10.4206\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.4459 - val_loss: 1.9289\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.3147 - val_loss: 2.6455\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2032 - val_loss: 1.7170\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1693 - val_loss: 0.1963\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.3976 - val_loss: 2.8300\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.9153 - val_loss: 0.9769\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 3.7919 - val_loss: 4.9519\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 1.2136 - val_loss: 2.0025\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2553 - val_loss: 0.8324\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 1.8599 - val_loss: 5.4662\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.6080 - val_loss: 1.3808\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 2.0043 - val_loss: 3.9376\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.5703 - val_loss: 6.3580\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.1564 - val_loss: 1.2042\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 2.5556 - val_loss: 2.7261\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 4.7761 - val_loss: 8.5090\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.4570 - val_loss: 2.2642\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2787 - val_loss: 0.2532\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1457 - val_loss: 0.8353\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.3720 - val_loss: 0.6126\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.4101 - val_loss: 1.1028\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.4934 - val_loss: 0.5635\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.4427 - val_loss: 0.1101\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 2.0722 - val_loss: 1.0972\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.5404 - val_loss: 0.5071\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3459 - val_loss: 0.9517\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0630 - val_loss: 0.2193\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1615 - val_loss: 0.1895\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.2457 - val_loss: 0.8099\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3545 - val_loss: 1.1728\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.4863 - val_loss: 0.9932\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 3.5933 - val_loss: 8.1835\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.3163 - val_loss: 0.6849\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2986 - val_loss: 0.6224\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.3821 - val_loss: 4.7295\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.4601 - val_loss: 0.6794\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1472 - val_loss: 0.6918\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 1.1775 - val_loss: 1.9915\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.9737 - val_loss: 1.1764\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 2.4964 - val_loss: 6.6748\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1027 - val_loss: 0.0661\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.4775 - val_loss: 0.4564\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0961 - val_loss: 0.6419\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2097 - val_loss: 0.1475\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.2858 - val_loss: 0.9830\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.4972 - val_loss: 0.1535\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.8049 - val_loss: 1.4635\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 1.9050 - val_loss: 0.5547\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.3296 - val_loss: 0.5773\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.6889 - val_loss: 1.8823\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.1025 - val_loss: 0.3051\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2694 - val_loss: 0.4675\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.1937 - val_loss: 0.4591\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.3546 - val_loss: 0.3680\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.3202 - val_loss: 0.2761\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.7741 - val_loss: 0.5774\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0942 - val_loss: 0.3481\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2330 - val_loss: 0.4309\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0932 - val_loss: 1.1769\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.1216 - val_loss: 0.0958\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.1793 - val_loss: 0.7670\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.3803 - val_loss: 1.1587\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2990 - val_loss: 0.2069\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 3.2807 - val_loss: 4.6330\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.0587 - val_loss: 0.3071\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 4.3798 - val_loss: 6.7876\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.0773 - val_loss: 0.7446\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.6026 - val_loss: 1.1070\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2279 - val_loss: 2.5296\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.6486 - val_loss: 2.9856\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 1.2737 - val_loss: 2.9214\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 3.8010 - val_loss: 6.4662\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.4928 - val_loss: 0.7800\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.4996 - val_loss: 0.1025\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.0688 - val_loss: 0.0692\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2138 - val_loss: 0.5158\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2756 - val_loss: 0.2477\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.6816 - val_loss: 1.6391\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.5220 - val_loss: 0.4581\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 1.8979 - val_loss: 0.7371\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2269 - val_loss: 1.0586\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4727 - val_loss: 0.7168\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.0275 - val_loss: 0.1185\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4219 - val_loss: 0.9298\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.4427 - val_loss: 1.4280\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0330 - val_loss: 0.3689\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 2.9972 - val_loss: 2.6757\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 2.7772 - val_loss: 5.9175\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.1485 - val_loss: 0.1542\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.1427 - val_loss: 0.0810\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0372 - val_loss: 0.1784\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1609 - val_loss: 0.2263\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 2.9071 - val_loss: 4.6812\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1045 - val_loss: 0.0954\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 2.1644 - val_loss: 4.4208\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 3.5017 - val_loss: 5.6632\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1773 - val_loss: 0.2548\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3661 - val_loss: 0.2402\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.0290 - val_loss: 0.0991\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.3167 - val_loss: 0.2034\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5971 - val_loss: 0.7645\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0883 - val_loss: 1.2294\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 1.8787 - val_loss: 1.4381\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 2.9236 - val_loss: 6.0111\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.6877 - val_loss: 2.2772\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.6035 - val_loss: 0.1104\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3531 - val_loss: 1.3020\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.4235 - val_loss: 0.1669\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.6933 - val_loss: 0.5716\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.3028 - val_loss: 0.8472\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.3378 - val_loss: 0.0612\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 1.7184 - val_loss: 0.4744\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1830 - val_loss: 0.7488\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2671 - val_loss: 0.2058\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.1243 - val_loss: 0.1926\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.3456 - val_loss: 0.8904\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.3736 - val_loss: 0.7413\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1054 - val_loss: 0.6789\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 1.2101 - val_loss: 2.9435\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 1.6973 - val_loss: 0.1847\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.1325 - val_loss: 0.2287\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.1458 - val_loss: 0.6209\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.0730 - val_loss: 0.7455\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2282 - val_loss: 0.3535\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2974 - val_loss: 2.1682\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0398 - val_loss: 0.6542\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 1.2905 - val_loss: 1.9913\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 1.4355 - val_loss: 0.9622\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2324 - val_loss: 0.4909\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2579 - val_loss: 0.0820\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3258 - val_loss: 1.4811\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.3437 - val_loss: 0.0793\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 1.6497 - val_loss: 5.4058\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2832 - val_loss: 0.7684\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2818 - val_loss: 0.8812\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 2.2242 - val_loss: 4.5811\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.1489 - val_loss: 0.7877\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 1.7313 - val_loss: 1.0070\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.1777 - val_loss: 1.0078\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 2.1186 - val_loss: 1.1721\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.6997 - val_loss: 1.0754\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.7192 - val_loss: 3.8146\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.5466 - val_loss: 0.2839\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 3.3908 - val_loss: 5.9595\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.3920 - val_loss: 2.7739\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2776 - val_loss: 0.1930\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.1177 - val_loss: 1.9069\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.4278 - val_loss: 1.6861\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0684 - val_loss: 0.4366\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.0170 - val_loss: 0.1129\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.0840 - val_loss: 0.0622\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 1.8345 - val_loss: 2.1333\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.0246 - val_loss: 0.0372\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.0839 - val_loss: 0.0841\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.4331 - val_loss: 3.3656\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.3482 - val_loss: 1.0911\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.2571 - val_loss: 2.9761\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.3616 - val_loss: 0.8701\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.3567 - val_loss: 1.5088\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 2.6760 - val_loss: 2.9868\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.4924 - val_loss: 3.4158\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.3680 - val_loss: 0.9931\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1130 - val_loss: 0.8736\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.2334 - val_loss: 0.3358\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.6638 - val_loss: 1.1049\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1786 - val_loss: 0.8601\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2498 - val_loss: 0.7098\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 1.6451 - val_loss: 1.7103\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1682 - val_loss: 0.7321\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3646 - val_loss: 0.6634\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.0154 - val_loss: 0.0371\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.5758 - val_loss: 3.5450\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.4727 - val_loss: 1.7824\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2765 - val_loss: 0.5199\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.4335 - val_loss: 0.0769\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 1.1912 - val_loss: 2.6943\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0650 - val_loss: 0.5098\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.3491 - val_loss: 0.7276\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.0361 - val_loss: 0.4156\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.3880 - val_loss: 1.5133\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.3736 - val_loss: 2.5258\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2886 - val_loss: 0.9456\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.2104 - val_loss: 0.3758\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 1.7607 - val_loss: 1.8512\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.1291 - val_loss: 0.6490\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.1460 - val_loss: 0.1973\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.0123 - val_loss: 0.0378\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.0979 - val_loss: 0.2019\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.0324 - val_loss: 0.0273\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0222 - val_loss: 0.0901\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1864 - val_loss: 0.1337\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3245 - val_loss: 0.8482\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.0454 - val_loss: 0.1049\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2232 - val_loss: 0.4536\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.0325 - val_loss: 0.0747\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2321 - val_loss: 0.2639\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0697 - val_loss: 0.1208\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.3063 - val_loss: 2.2695\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1148 - val_loss: 0.1034\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.8565 - val_loss: 1.4661\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2040 - val_loss: 0.2377\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.0894 - val_loss: 0.1053\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3769 - val_loss: 2.5854\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.6189 - val_loss: 2.6045\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 1.2293 - val_loss: 2.8260\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1585 - val_loss: 0.6783\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.4696 - val_loss: 0.4927\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.5826 - val_loss: 0.4771\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1540 - val_loss: 0.3528\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.7138 - val_loss: 1.2642\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.0518 - val_loss: 0.4130\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.2060 - val_loss: 2.4787\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2736 - val_loss: 1.7869\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2555 - val_loss: 1.6809\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.9579 - val_loss: 0.5685\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 1.3018 - val_loss: 1.3168\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.3799 - val_loss: 0.8269\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 1.6351 - val_loss: 0.2443\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0338 - val_loss: 0.1254\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2020 - val_loss: 1.3187\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.1084 - val_loss: 0.1872\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0227 - val_loss: 0.1025\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.3458 - val_loss: 0.2446\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 1.8485 - val_loss: 2.5017\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.0238 - val_loss: 0.0542\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.1178 - val_loss: 0.3725\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.6172 - val_loss: 4.8139\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.1618 - val_loss: 0.4126\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.1121 - val_loss: 0.5449\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0984 - val_loss: 0.4247\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2273 - val_loss: 0.3885\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.5521 - val_loss: 0.8972\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.1910 - val_loss: 0.4166\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5238 - val_loss: 1.7962\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3610 - val_loss: 3.4867\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2339 - val_loss: 1.0535\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.4408 - val_loss: 7.5727\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5303 - val_loss: 6.1192\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.6723 - val_loss: 1.1461\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 4.8595 - val_loss: 9.9932\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.4456 - val_loss: 1.9978\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.3320 - val_loss: 2.5536\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2153 - val_loss: 1.7989\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1472 - val_loss: 0.1231\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3562 - val_loss: 2.7688\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 1.0397 - val_loss: 0.7633\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 3.7353 - val_loss: 4.4776\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 1.0134 - val_loss: 1.4358\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2667 - val_loss: 0.8448\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 1.8497 - val_loss: 5.3748\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.6164 - val_loss: 1.4631\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 2.0240 - val_loss: 3.8540\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.5494 - val_loss: 6.1713\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1523 - val_loss: 1.2393\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 2.3943 - val_loss: 2.5083\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 4.5380 - val_loss: 7.1560\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.4542 - val_loss: 2.3835\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.3188 - val_loss: 0.2882\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.1361 - val_loss: 0.6749\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2856 - val_loss: 0.4849\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.3485 - val_loss: 0.9572\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.5486 - val_loss: 0.4159\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.4762 - val_loss: 0.0955\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 2.4602 - val_loss: 1.5785\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.4719 - val_loss: 0.4512\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2732 - val_loss: 1.0315\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.0394 - val_loss: 0.1307\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1509 - val_loss: 0.1803\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2126 - val_loss: 0.6840\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.4039 - val_loss: 0.9627\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.4908 - val_loss: 1.0384\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 3.2265 - val_loss: 6.6842\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3453 - val_loss: 0.8127\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.3467 - val_loss: 0.6226\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.4038 - val_loss: 4.8399\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.5121 - val_loss: 0.7677\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1903 - val_loss: 0.6704\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 1.1727 - val_loss: 1.8229\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.9140 - val_loss: 1.0841\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 2.2616 - val_loss: 6.7223\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.0971 - val_loss: 0.0409\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5820 - val_loss: 0.5861\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.1250 - val_loss: 0.4891\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2286 - val_loss: 0.1165\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3298 - val_loss: 1.0032\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.7732 - val_loss: 0.1811\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.6141 - val_loss: 1.0971\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 1.6666 - val_loss: 0.5408\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.3073 - val_loss: 0.5721\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.5374 - val_loss: 1.6209\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.0874 - val_loss: 0.2716\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2534 - val_loss: 0.4818\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.2001 - val_loss: 0.5081\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.4825 - val_loss: 0.2584\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3601 - val_loss: 0.3966\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.8271 - val_loss: 0.4549\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0950 - val_loss: 0.3455\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.1786 - val_loss: 0.3685\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.1515 - val_loss: 1.5330\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.0980 - val_loss: 0.1081\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.1841 - val_loss: 0.8220\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.3483 - val_loss: 0.9047\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2672 - val_loss: 0.1985\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 2.9617 - val_loss: 4.3717\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0584 - val_loss: 0.3352\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 4.4100 - val_loss: 6.8712\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.0638 - val_loss: 0.6099\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.6474 - val_loss: 1.2147\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2319 - val_loss: 2.6060\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6347 - val_loss: 3.1208\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 1.3326 - val_loss: 3.1894\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 4.1820 - val_loss: 7.3198\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5136 - val_loss: 0.8657\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5352 - val_loss: 0.1204\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.0813 - val_loss: 0.0692\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.2423 - val_loss: 0.5053\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2955 - val_loss: 0.1981\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.4385 - val_loss: 1.0412\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4980 - val_loss: 0.3794\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 1.6141 - val_loss: 0.6026\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2249 - val_loss: 0.9965\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.5389 - val_loss: 0.8129\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.0296 - val_loss: 0.1115\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.4560 - val_loss: 1.0752\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.4136 - val_loss: 1.4223\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0433 - val_loss: 0.3968\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 2.8756 - val_loss: 2.5765\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 2.6569 - val_loss: 5.5003\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.1350 - val_loss: 0.1575\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1232 - val_loss: 0.1010\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.0405 - val_loss: 0.1993\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1738 - val_loss: 0.2418\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 2.9087 - val_loss: 4.7279\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.1173 - val_loss: 0.0987\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 2.0195 - val_loss: 4.1910\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 3.5123 - val_loss: 5.8254\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1484 - val_loss: 0.2123\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.3424 - val_loss: 0.2449\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0293 - val_loss: 0.0743\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2756 - val_loss: 0.1750\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6367 - val_loss: 0.7992\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.0919 - val_loss: 1.3257\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 1.8759 - val_loss: 1.4380\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 2.8945 - val_loss: 6.0729\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.7047 - val_loss: 2.3375\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.6173 - val_loss: 0.0938\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.3465 - val_loss: 1.2799\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4178 - val_loss: 0.1769\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.7072 - val_loss: 0.6251\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2820 - val_loss: 0.7783\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.3847 - val_loss: 0.0533\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 1.8350 - val_loss: 0.4238\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.2054 - val_loss: 0.8237\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2745 - val_loss: 0.2422\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.1327 - val_loss: 0.2185\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.3607 - val_loss: 0.8806\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4280 - val_loss: 0.8095\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1227 - val_loss: 0.7359\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 1.0561 - val_loss: 2.6805\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 1.6671 - val_loss: 0.1143\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1496 - val_loss: 0.2527\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.1448 - val_loss: 0.6036\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0736 - val_loss: 0.7067\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2167 - val_loss: 0.3167\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2919 - val_loss: 2.1279\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0360 - val_loss: 0.7168\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 1.2664 - val_loss: 1.9614\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 1.4850 - val_loss: 1.0768\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2184 - val_loss: 0.4588\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.2420 - val_loss: 0.0600\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.3471 - val_loss: 1.5689\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.3441 - val_loss: 0.0833\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 1.5530 - val_loss: 5.2217\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.2774 - val_loss: 0.8000\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.2921 - val_loss: 0.8171\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 2.1481 - val_loss: 3.8735\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.1499 - val_loss: 0.7715\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 1.7371 - val_loss: 0.9885\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1763 - val_loss: 1.0026\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 2.0686 - val_loss: 1.2555\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.7035 - val_loss: 1.0655\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.7730 - val_loss: 4.0560\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.6119 - val_loss: 0.2682\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 3.4572 - val_loss: 6.0006\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.3839 - val_loss: 2.9195\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2836 - val_loss: 0.1816\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.1205 - val_loss: 1.9867\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.4475 - val_loss: 1.7953\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.0533 - val_loss: 0.4408\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0130 - val_loss: 0.0882\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0772 - val_loss: 0.0486\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 1.7938 - val_loss: 2.0774\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.0168 - val_loss: 0.0290\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.0853 - val_loss: 0.0984\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.4398 - val_loss: 3.3643\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3492 - val_loss: 1.0888\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 1.2541 - val_loss: 3.0089\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.3567 - val_loss: 0.8592\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.3396 - val_loss: 1.4778\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 2.6701 - val_loss: 2.8505\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.5044 - val_loss: 3.4541\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2630 - val_loss: 0.6141\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0695 - val_loss: 0.7156\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.2048 - val_loss: 0.2595\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.6594 - val_loss: 1.0813\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.2913 - val_loss: 0.5545\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2526 - val_loss: 0.7157\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.4146 - val_loss: 1.5714\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1710 - val_loss: 0.8370\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3226 - val_loss: 0.6191\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.0106 - val_loss: 0.0198\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.4776 - val_loss: 3.0200\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.4820 - val_loss: 1.8065\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2218 - val_loss: 0.4592\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3463 - val_loss: 0.0761\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 1.2388 - val_loss: 2.8220\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.0418 - val_loss: 0.3805\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.3131 - val_loss: 0.6682\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.0331 - val_loss: 0.3972\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3724 - val_loss: 1.5196\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.3828 - val_loss: 2.5725\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2801 - val_loss: 0.9206\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2114 - val_loss: 0.3710\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.7174 - val_loss: 2.2190\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.1320 - val_loss: 0.6025\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1241 - val_loss: 0.1644\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.0111 - val_loss: 0.0315\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0924 - val_loss: 0.1755\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0320 - val_loss: 0.0246\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0271 - val_loss: 0.0993\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.2014 - val_loss: 0.1257\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.4172 - val_loss: 0.8391\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.0401 - val_loss: 0.1056\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.2260 - val_loss: 0.4619\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0314 - val_loss: 0.0799\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.2339 - val_loss: 0.2529\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.0736 - val_loss: 0.1087\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3168 - val_loss: 2.3162\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.1128 - val_loss: 0.1071\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.7747 - val_loss: 1.5884\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.1851 - val_loss: 0.1999\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.0897 - val_loss: 0.1400\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.3583 - val_loss: 2.4965\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5786 - val_loss: 2.5424\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 1.3006 - val_loss: 2.9987\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.1351 - val_loss: 0.5910\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5211 - val_loss: 0.5151\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5638 - val_loss: 0.4396\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1303 - val_loss: 0.2980\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.7624 - val_loss: 1.3489\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.0427 - val_loss: 0.3905\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 1.2222 - val_loss: 2.5187\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2572 - val_loss: 1.7935\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2451 - val_loss: 1.6673\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.9052 - val_loss: 0.6014\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 1.2658 - val_loss: 1.2387\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.4126 - val_loss: 0.9212\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 1.6280 - val_loss: 0.2337\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0282 - val_loss: 0.1449\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1838 - val_loss: 1.3860\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.1036 - val_loss: 0.1856\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0292 - val_loss: 0.0847\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3265 - val_loss: 0.2624\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 1.8109 - val_loss: 2.3799\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.0251 - val_loss: 0.0617\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.1187 - val_loss: 0.3694\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6438 - val_loss: 4.9511\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.1665 - val_loss: 0.4330\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.1090 - val_loss: 0.5366\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.0944 - val_loss: 0.4054\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.2298 - val_loss: 0.3625\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.5424 - val_loss: 0.7965\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.1693 - val_loss: 0.3532\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.5072 - val_loss: 1.7362\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3545 - val_loss: 3.4595\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.2338 - val_loss: 1.0468\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.4399 - val_loss: 7.5645\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.5128 - val_loss: 5.9033\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6438 - val_loss: 1.0416\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.4537 - val_loss: 8.9599\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4497 - val_loss: 2.0031\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3131 - val_loss: 2.3418\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.2091 - val_loss: 1.7521\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.1559 - val_loss: 0.1424\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.3766 - val_loss: 2.8074\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 1.0493 - val_loss: 0.7276\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 3.5517 - val_loss: 4.3695\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 1.0341 - val_loss: 1.1930\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2618 - val_loss: 0.8322\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 1.7522 - val_loss: 5.0174\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.6367 - val_loss: 1.4081\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.8732 - val_loss: 3.6323\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.5251 - val_loss: 6.0046\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.1182 - val_loss: 1.0059\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 2.2031 - val_loss: 2.2901\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 4.0547 - val_loss: 7.0964\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.4627 - val_loss: 2.5360\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3732 - val_loss: 0.4264\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1423 - val_loss: 0.5484\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2382 - val_loss: 0.3790\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2735 - val_loss: 0.7590\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.4366 - val_loss: 0.7413\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.5699 - val_loss: 0.0770\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 2.3503 - val_loss: 1.4507\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.4115 - val_loss: 0.4252\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.2232 - val_loss: 1.0714\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.0238 - val_loss: 0.0808\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.1798 - val_loss: 0.2365\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2132 - val_loss: 0.6690\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.3020 - val_loss: 1.1961\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.4943 - val_loss: 0.8419\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 3.1816 - val_loss: 6.4445\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3099 - val_loss: 0.6718\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3736 - val_loss: 0.6799\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4432 - val_loss: 5.3121\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4259 - val_loss: 0.6521\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1805 - val_loss: 0.9492\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.6641 - val_loss: 0.9939\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.8119 - val_loss: 0.9486\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 1.9419 - val_loss: 6.3921\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1072 - val_loss: 0.0359\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.5307 - val_loss: 0.5529\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1126 - val_loss: 0.5211\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2206 - val_loss: 0.1083\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.3140 - val_loss: 0.9519\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.9096 - val_loss: 0.6193\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4301 - val_loss: 0.6984\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 1.4562 - val_loss: 0.5973\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3084 - val_loss: 0.6408\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4831 - val_loss: 1.4211\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.0654 - val_loss: 0.0709\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2083 - val_loss: 0.3880\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.1766 - val_loss: 0.4942\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.1187 - val_loss: 0.7493\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2779 - val_loss: 0.3986\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.7729 - val_loss: 0.5585\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0949 - val_loss: 0.3508\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1613 - val_loss: 0.3366\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.1307 - val_loss: 1.6457\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0821 - val_loss: 0.1665\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.2241 - val_loss: 1.0081\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3740 - val_loss: 0.9878\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1914 - val_loss: 0.0875\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 2.4990 - val_loss: 3.1515\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.0482 - val_loss: 0.3147\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 4.6505 - val_loss: 6.8984\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0489 - val_loss: 0.6906\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.7728 - val_loss: 1.4821\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.2296 - val_loss: 2.3796\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5553 - val_loss: 2.8989\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 1.2282 - val_loss: 2.8444\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 4.1009 - val_loss: 6.1222\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4172 - val_loss: 0.6789\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.4676 - val_loss: 0.0776\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.0612 - val_loss: 0.0471\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2400 - val_loss: 0.6059\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.2612 - val_loss: 0.2223\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.6446 - val_loss: 1.6577\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4833 - val_loss: 0.3651\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 2.4434 - val_loss: 1.0707\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2311 - val_loss: 0.9554\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5512 - val_loss: 0.8602\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.0259 - val_loss: 0.1074\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.4671 - val_loss: 1.0887\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3802 - val_loss: 1.2881\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.1184 - val_loss: 0.3873\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 2.5533 - val_loss: 2.1490\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 2.6029 - val_loss: 5.4358\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.1604 - val_loss: 0.1439\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.1815 - val_loss: 0.0444\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0781 - val_loss: 0.3643\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.2986 - val_loss: 0.4347\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 2.6682 - val_loss: 4.2117\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1159 - val_loss: 0.0856\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 2.3550 - val_loss: 4.7795\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 3.2663 - val_loss: 5.7735\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.2118 - val_loss: 0.3127\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3933 - val_loss: 0.2159\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0369 - val_loss: 0.1453\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.3618 - val_loss: 0.2641\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.5440 - val_loss: 0.6720\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.1173 - val_loss: 1.4878\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 1.5986 - val_loss: 1.2318\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 3.1252 - val_loss: 6.2757\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6628 - val_loss: 2.3273\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.5916 - val_loss: 0.0989\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.3178 - val_loss: 1.1346\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3696 - val_loss: 0.1857\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.6290 - val_loss: 0.5825\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2846 - val_loss: 0.5996\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.3575 - val_loss: 0.0651\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 2.1290 - val_loss: 0.3822\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1623 - val_loss: 0.6361\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3047 - val_loss: 0.2809\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0936 - val_loss: 0.1609\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.2895 - val_loss: 0.8119\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.4335 - val_loss: 0.9284\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.1135 - val_loss: 0.2468\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 1.1937 - val_loss: 2.7350\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 1.7729 - val_loss: 0.1300\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1396 - val_loss: 0.2556\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.1439 - val_loss: 0.5662\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.0746 - val_loss: 0.6764\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2097 - val_loss: 0.2685\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.3024 - val_loss: 2.1859\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0233 - val_loss: 0.8501\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 1.1626 - val_loss: 1.7304\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 1.5136 - val_loss: 1.1353\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2082 - val_loss: 0.4085\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2055 - val_loss: 0.0541\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3687 - val_loss: 1.5996\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.4184 - val_loss: 0.1333\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 1.6356 - val_loss: 5.4321\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.1692 - val_loss: 0.9034\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2794 - val_loss: 0.8387\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 2.3019 - val_loss: 4.6256\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.1481 - val_loss: 0.7704\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 1.7689 - val_loss: 1.0004\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.1703 - val_loss: 0.9641\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 2.0679 - val_loss: 1.2883\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.6554 - val_loss: 1.0149\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.5855 - val_loss: 3.2199\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.5543 - val_loss: 0.2787\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 3.0484 - val_loss: 5.2416\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.3889 - val_loss: 2.6634\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.2606 - val_loss: 0.1521\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.1228 - val_loss: 2.0444\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.4615 - val_loss: 1.8466\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.0436 - val_loss: 0.4585\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.0324 - val_loss: 0.0946\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.0732 - val_loss: 0.0458\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 1.7936 - val_loss: 2.1825\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.0166 - val_loss: 0.0310\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.0891 - val_loss: 0.0765\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.4189 - val_loss: 3.2383\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3188 - val_loss: 0.9231\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 1.1731 - val_loss: 2.7615\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.4142 - val_loss: 1.0953\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.4087 - val_loss: 1.6288\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 2.8036 - val_loss: 3.7469\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.4849 - val_loss: 3.3912\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2391 - val_loss: 0.2571\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.0461 - val_loss: 0.2844\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.2393 - val_loss: 0.2250\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.5215 - val_loss: 1.0571\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.1637 - val_loss: 0.5886\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2598 - val_loss: 0.7769\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.8971 - val_loss: 0.7725\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0515 - val_loss: 0.3785\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2909 - val_loss: 0.5908\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.0148 - val_loss: 0.0810\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.5053 - val_loss: 3.1659\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.5001 - val_loss: 1.8462\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.4609 - val_loss: 0.6728\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3884 - val_loss: 0.0808\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 1.1864 - val_loss: 2.6824\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.0404 - val_loss: 0.4116\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.3148 - val_loss: 0.5932\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0341 - val_loss: 0.3631\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3553 - val_loss: 1.4467\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.4113 - val_loss: 2.5613\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3412 - val_loss: 1.2426\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.2681 - val_loss: 0.4260\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.9559 - val_loss: 4.2423\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.1185 - val_loss: 0.6256\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.1386 - val_loss: 0.1762\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0110 - val_loss: 0.0250\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0843 - val_loss: 0.1558\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.0319 - val_loss: 0.0237\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.0298 - val_loss: 0.1059\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2105 - val_loss: 0.1754\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.2580 - val_loss: 0.8080\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.0362 - val_loss: 0.1007\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2123 - val_loss: 0.4476\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.0303 - val_loss: 0.1159\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2048 - val_loss: 0.2064\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.0731 - val_loss: 0.1354\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.2816 - val_loss: 2.1544\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.1123 - val_loss: 0.1259\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.7837 - val_loss: 2.0027\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.1760 - val_loss: 0.1529\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.0897 - val_loss: 0.1684\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3357 - val_loss: 2.2935\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5304 - val_loss: 2.3152\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 1.3941 - val_loss: 3.1965\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.1395 - val_loss: 0.5673\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.5648 - val_loss: 0.5566\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5431 - val_loss: 0.4216\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1096 - val_loss: 0.2536\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.7771 - val_loss: 1.3617\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.0346 - val_loss: 0.3741\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 1.2279 - val_loss: 2.5308\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2502 - val_loss: 1.8147\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.2238 - val_loss: 1.5936\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.9855 - val_loss: 0.5531\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 1.2750 - val_loss: 1.0539\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.3873 - val_loss: 0.8682\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.5667 - val_loss: 0.2204\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0280 - val_loss: 0.1164\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1974 - val_loss: 1.2602\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.1118 - val_loss: 0.1941\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0223 - val_loss: 0.0909\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.3307 - val_loss: 0.2567\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 1.9001 - val_loss: 2.7032\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.0222 - val_loss: 0.0666\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.1208 - val_loss: 0.3603\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.6216 - val_loss: 4.8527\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1565 - val_loss: 0.4007\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1096 - val_loss: 0.5293\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1015 - val_loss: 0.4283\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2335 - val_loss: 0.3691\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.5619 - val_loss: 1.0547\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.1793 - val_loss: 0.3920\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4805 - val_loss: 1.6864\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3720 - val_loss: 3.5068\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.2332 - val_loss: 1.0235\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4193 - val_loss: 7.4490\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.6846 - val_loss: 7.0697\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6431 - val_loss: 0.9772\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 5.2620 - val_loss: 12.7186\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4282 - val_loss: 1.9885\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.3042 - val_loss: 2.1385\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2285 - val_loss: 2.0040\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1176 - val_loss: 0.0679\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3510 - val_loss: 2.8318\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 1.0522 - val_loss: 0.5800\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 3.4425 - val_loss: 4.3244\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 1.1443 - val_loss: 1.1392\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2808 - val_loss: 0.8736\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 1.7315 - val_loss: 4.9592\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.6403 - val_loss: 1.7730\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 2.1200 - val_loss: 3.8816\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.5396 - val_loss: 6.0427\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0895 - val_loss: 0.8844\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 2.1814 - val_loss: 2.2483\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 3.9679 - val_loss: 6.9625\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.4585 - val_loss: 2.5040\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.3753 - val_loss: 0.4281\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1281 - val_loss: 0.5076\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2046 - val_loss: 0.3324\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2811 - val_loss: 0.7644\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.4639 - val_loss: 0.5187\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.5690 - val_loss: 0.0858\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 2.0331 - val_loss: 1.1310\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4406 - val_loss: 0.4601\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2454 - val_loss: 1.1115\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.0726 - val_loss: 0.2474\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1550 - val_loss: 0.1895\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2139 - val_loss: 0.6925\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4862 - val_loss: 0.6516\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.5064 - val_loss: 1.0982\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 3.2485 - val_loss: 6.8505\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.3521 - val_loss: 0.6877\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.4342 - val_loss: 0.8290\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.4028 - val_loss: 5.0500\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4056 - val_loss: 0.6484\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1969 - val_loss: 0.8091\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.0382 - val_loss: 1.7568\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.6815 - val_loss: 0.8945\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 2.0357 - val_loss: 6.1174\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.0811 - val_loss: 0.1238\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.5495 - val_loss: 0.5621\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.1007 - val_loss: 0.5245\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2204 - val_loss: 0.0834\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3144 - val_loss: 1.0268\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.4988 - val_loss: 0.1601\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.5151 - val_loss: 0.8741\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 1.7216 - val_loss: 0.5675\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3524 - val_loss: 0.6608\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5136 - val_loss: 1.4478\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0795 - val_loss: 0.2258\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2240 - val_loss: 0.3693\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1835 - val_loss: 0.5240\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.3245 - val_loss: 0.4034\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2789 - val_loss: 0.3240\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.6729 - val_loss: 0.6777\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.0943 - val_loss: 0.3455\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.1743 - val_loss: 0.3314\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.1557 - val_loss: 1.7015\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.0850 - val_loss: 0.1089\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.1744 - val_loss: 0.7829\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3882 - val_loss: 1.0154\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.2630 - val_loss: 0.1447\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 2.8971 - val_loss: 3.4758\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.0483 - val_loss: 0.2773\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 4.5549 - val_loss: 6.6528\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.0623 - val_loss: 0.7963\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.6764 - val_loss: 1.2695\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2277 - val_loss: 2.6520\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.4084 - val_loss: 2.2778\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 1.3361 - val_loss: 3.2588\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 3.8952 - val_loss: 6.0262\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.4896 - val_loss: 0.8397\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.5731 - val_loss: 0.1354\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.0858 - val_loss: 0.0573\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.2866 - val_loss: 0.5579\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2948 - val_loss: 0.1660\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3950 - val_loss: 0.9859\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5011 - val_loss: 0.3026\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 2.2752 - val_loss: 0.9754\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2017 - val_loss: 0.9020\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.5848 - val_loss: 0.8563\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.0310 - val_loss: 0.1280\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.4601 - val_loss: 1.0280\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.3903 - val_loss: 1.2919\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.0375 - val_loss: 0.4801\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 2.5773 - val_loss: 2.1869\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 2.8178 - val_loss: 5.3489\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.1467 - val_loss: 0.1539\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.1343 - val_loss: 0.0916\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.0403 - val_loss: 0.1910\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1797 - val_loss: 0.2435\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 3.0348 - val_loss: 4.9425\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1962 - val_loss: 0.2570\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 2.0124 - val_loss: 4.1642\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 3.3633 - val_loss: 4.9643\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1133 - val_loss: 0.1688\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3843 - val_loss: 0.1768\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.0299 - val_loss: 0.0911\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.3202 - val_loss: 0.2320\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5688 - val_loss: 0.6922\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.0868 - val_loss: 1.1365\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 1.5619 - val_loss: 1.1633\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 2.8561 - val_loss: 6.0217\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.6433 - val_loss: 2.2573\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.5155 - val_loss: 0.1566\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.3473 - val_loss: 1.2586\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3338 - val_loss: 0.1020\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.7439 - val_loss: 0.5690\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3164 - val_loss: 0.8328\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3476 - val_loss: 0.0568\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 1.9067 - val_loss: 0.3959\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2004 - val_loss: 0.8073\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2521 - val_loss: 0.1354\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.1285 - val_loss: 0.2094\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.3783 - val_loss: 0.8915\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.4874 - val_loss: 0.9069\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.1237 - val_loss: 0.7515\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.8315 - val_loss: 2.1911\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 1.6056 - val_loss: 0.1082\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.1350 - val_loss: 0.2193\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1421 - val_loss: 0.5232\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.0730 - val_loss: 0.6936\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2101 - val_loss: 0.2934\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3003 - val_loss: 2.1438\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.0361 - val_loss: 0.7154\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 1.1981 - val_loss: 1.8220\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 1.5314 - val_loss: 1.2169\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2227 - val_loss: 0.4677\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2678 - val_loss: 0.0890\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3692 - val_loss: 1.6981\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.2858 - val_loss: 0.0558\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 1.4969 - val_loss: 5.0847\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.2771 - val_loss: 0.8402\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2849 - val_loss: 0.8077\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 2.3590 - val_loss: 4.0341\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.1616 - val_loss: 0.9004\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 1.8152 - val_loss: 1.0591\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.1788 - val_loss: 1.0501\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 2.0514 - val_loss: 1.3869\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6522 - val_loss: 0.9878\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5781 - val_loss: 3.2715\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.6059 - val_loss: 0.2529\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 2.9760 - val_loss: 4.9085\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3888 - val_loss: 2.8015\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2818 - val_loss: 0.1809\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.1138 - val_loss: 1.9385\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.4294 - val_loss: 1.7068\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.0571 - val_loss: 0.4107\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.0175 - val_loss: 0.0884\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.0859 - val_loss: 0.0594\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 1.8260 - val_loss: 2.2184\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.0166 - val_loss: 0.0260\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.1008 - val_loss: 0.0711\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4261 - val_loss: 3.3396\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.3282 - val_loss: 0.9761\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.1335 - val_loss: 2.7492\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.3938 - val_loss: 0.9995\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.4368 - val_loss: 1.6881\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 2.6998 - val_loss: 3.1155\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.4772 - val_loss: 3.4129\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2073 - val_loss: 0.6032\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.0353 - val_loss: 0.5498\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1584 - val_loss: 0.1564\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6722 - val_loss: 1.0893\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.4066 - val_loss: 0.2582\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2518 - val_loss: 0.7004\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.8771 - val_loss: 0.7788\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.1325 - val_loss: 0.6923\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.3065 - val_loss: 0.6142\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.0076 - val_loss: 0.0110\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4185 - val_loss: 2.7284\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.4419 - val_loss: 1.6649\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.4045 - val_loss: 0.4041\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.3124 - val_loss: 0.1240\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.9904 - val_loss: 2.2306\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.0577 - val_loss: 0.4586\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2933 - val_loss: 0.5414\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0310 - val_loss: 0.3222\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3359 - val_loss: 1.3658\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.4399 - val_loss: 2.6703\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.3918 - val_loss: 1.3997\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.2379 - val_loss: 0.3769\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 1.7328 - val_loss: 2.9904\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.1180 - val_loss: 0.6463\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.1539 - val_loss: 0.2052\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.0233 - val_loss: 0.0694\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.1129 - val_loss: 0.2384\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.0354 - val_loss: 0.0493\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0122 - val_loss: 0.0268\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.2278 - val_loss: 0.1700\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4130 - val_loss: 0.5046\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.0489 - val_loss: 0.1222\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2220 - val_loss: 0.4716\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.0302 - val_loss: 0.1265\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2121 - val_loss: 0.1882\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.0801 - val_loss: 0.1345\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2575 - val_loss: 1.9916\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.1194 - val_loss: 0.1280\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.7770 - val_loss: 1.6964\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.1774 - val_loss: 0.1132\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0914 - val_loss: 0.1974\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.3295 - val_loss: 2.3038\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.5127 - val_loss: 2.2858\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 1.4251 - val_loss: 3.2761\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.1310 - val_loss: 0.5512\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.6124 - val_loss: 0.6074\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.5681 - val_loss: 0.4561\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.0942 - val_loss: 0.2280\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.7925 - val_loss: 1.3623\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.0398 - val_loss: 0.3690\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 1.1986 - val_loss: 2.4529\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.2368 - val_loss: 1.7436\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.2471 - val_loss: 1.7014\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 1.0142 - val_loss: 0.5212\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 1.2853 - val_loss: 1.1361\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3983 - val_loss: 0.8655\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 1.5504 - val_loss: 0.1822\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.0235 - val_loss: 0.1315\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.1744 - val_loss: 1.3293\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.1065 - val_loss: 0.1619\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.0275 - val_loss: 0.0838\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3684 - val_loss: 0.2320\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 1.8076 - val_loss: 2.4680\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.0227 - val_loss: 0.0784\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.1104 - val_loss: 0.3821\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.6291 - val_loss: 4.8798\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1578 - val_loss: 0.4145\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.1138 - val_loss: 0.5268\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.1023 - val_loss: 0.4326\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2251 - val_loss: 0.3728\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.5348 - val_loss: 0.9418\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1724 - val_loss: 0.3702\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4609 - val_loss: 1.6737\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3530 - val_loss: 3.4494\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2248 - val_loss: 0.9969\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.4219 - val_loss: 7.5093\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.5799 - val_loss: 6.1253\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6463 - val_loss: 0.9911\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 4.6506 - val_loss: 10.8833\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.4286 - val_loss: 1.9810\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.2883 - val_loss: 2.1413\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2184 - val_loss: 1.9347\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1294 - val_loss: 0.1027\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.3789 - val_loss: 2.9101\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 1.1455 - val_loss: 0.5056\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 3.3401 - val_loss: 4.3554\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 1.0045 - val_loss: 0.6676\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2696 - val_loss: 0.8480\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 1.7184 - val_loss: 4.8453\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.6414 - val_loss: 1.7698\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 2.1254 - val_loss: 3.5988\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.5201 - val_loss: 5.7264\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.1156 - val_loss: 1.2131\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 2.1254 - val_loss: 2.1451\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 3.8294 - val_loss: 5.7507\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.4474 - val_loss: 2.6388\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4328 - val_loss: 0.5186\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1400 - val_loss: 0.4192\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.1953 - val_loss: 0.2978\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2444 - val_loss: 0.6631\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4286 - val_loss: 0.8785\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.5860 - val_loss: 0.0898\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 2.7852 - val_loss: 1.9729\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.4519 - val_loss: 0.4743\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.2171 - val_loss: 1.2716\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.0220 - val_loss: 0.0792\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.1864 - val_loss: 0.2444\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2073 - val_loss: 0.6242\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.3523 - val_loss: 1.0556\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.5432 - val_loss: 1.0291\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 2.9525 - val_loss: 5.5713\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.3276 - val_loss: 0.6874\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4307 - val_loss: 0.8604\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.4223 - val_loss: 5.1873\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3506 - val_loss: 0.5965\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2044 - val_loss: 0.9824\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.9687 - val_loss: 1.5979\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.7081 - val_loss: 0.8571\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 1.8718 - val_loss: 6.1457\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.0913 - val_loss: 0.0962\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6009 - val_loss: 0.6478\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1042 - val_loss: 0.5889\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2212 - val_loss: 0.1259\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.2872 - val_loss: 0.8897\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.8736 - val_loss: 0.5457\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.3976 - val_loss: 0.6940\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 1.2638 - val_loss: 0.6847\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.3105 - val_loss: 0.6381\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.4531 - val_loss: 1.3321\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.0616 - val_loss: 0.0808\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.1988 - val_loss: 0.3347\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.1729 - val_loss: 0.5242\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.1169 - val_loss: 0.8708\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.2758 - val_loss: 0.4055\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6944 - val_loss: 0.8587\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.1030 - val_loss: 0.3926\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.1919 - val_loss: 0.3780\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1864 - val_loss: 2.0302\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.0747 - val_loss: 0.2113\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2673 - val_loss: 1.1329\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.3760 - val_loss: 0.8214\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1781 - val_loss: 0.0625\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 2.6175 - val_loss: 3.3474\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0573 - val_loss: 0.3451\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 4.3256 - val_loss: 5.7661\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0575 - val_loss: 0.8321\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.8116 - val_loss: 1.5428\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2322 - val_loss: 2.4529\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5613 - val_loss: 2.9843\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 1.2512 - val_loss: 2.9418\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 3.5975 - val_loss: 5.4363\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.4112 - val_loss: 0.6942\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.5471 - val_loss: 0.1208\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.0874 - val_loss: 0.0527\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.3234 - val_loss: 0.6388\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2907 - val_loss: 0.1518\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3635 - val_loss: 0.9767\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4758 - val_loss: 0.2675\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 2.1678 - val_loss: 0.5548\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2021 - val_loss: 0.8434\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.5846 - val_loss: 0.8938\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.0270 - val_loss: 0.1179\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.4641 - val_loss: 1.0338\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3711 - val_loss: 1.2607\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.0216 - val_loss: 0.5599\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 2.3595 - val_loss: 1.9520\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 3.3564 - val_loss: 6.9279\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.1410 - val_loss: 0.1214\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.1346 - val_loss: 0.1062\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.0343 - val_loss: 0.1588\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.1577 - val_loss: 0.2034\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 3.1479 - val_loss: 5.2479\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1177 - val_loss: 0.1423\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 1.9679 - val_loss: 3.9166\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 3.3775 - val_loss: 5.4891\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0752 - val_loss: 0.0928\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.3790 - val_loss: 0.1933\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0314 - val_loss: 0.0200\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2419 - val_loss: 0.1378\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.6708 - val_loss: 0.8676\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1419 - val_loss: 0.7890\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 1.7509 - val_loss: 1.2960\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 2.7449 - val_loss: 6.0058\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7342 - val_loss: 2.4256\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5017 - val_loss: 0.1750\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3172 - val_loss: 1.1805\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.3004 - val_loss: 0.0672\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.7463 - val_loss: 0.5396\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3360 - val_loss: 0.9183\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.3545 - val_loss: 0.0699\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 1.6271 - val_loss: 0.5654\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1914 - val_loss: 0.7617\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.2582 - val_loss: 0.1372\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.1081 - val_loss: 0.1603\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3792 - val_loss: 0.8964\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.4759 - val_loss: 0.9067\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.0714 - val_loss: 0.5297\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.6786 - val_loss: 1.7141\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.6948 - val_loss: 0.2150\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.0952 - val_loss: 0.1435\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.1554 - val_loss: 0.4348\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.0723 - val_loss: 0.7217\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.2206 - val_loss: 0.3138\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.3234 - val_loss: 2.2196\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0432 - val_loss: 0.6424\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.0958 - val_loss: 1.4470\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 1.5478 - val_loss: 1.1657\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2443 - val_loss: 0.4701\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.4096 - val_loss: 0.1620\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.3591 - val_loss: 1.6300\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2104 - val_loss: 0.0257\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 1.7725 - val_loss: 5.8844\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.4852 - val_loss: 0.8497\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2770 - val_loss: 1.1713\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 2.3416 - val_loss: 4.8095\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1708 - val_loss: 0.8956\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 1.9731 - val_loss: 1.3819\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2199 - val_loss: 1.4371\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 1.9263 - val_loss: 1.5626\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.8250 - val_loss: 1.0832\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.8782 - val_loss: 4.2777\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.8339 - val_loss: 0.3209\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 3.7889 - val_loss: 5.9073\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4034 - val_loss: 2.4150\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2305 - val_loss: 0.1328\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1167 - val_loss: 2.0619\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.4585 - val_loss: 1.9049\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.0400 - val_loss: 0.5464\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0403 - val_loss: 0.0882\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.0438 - val_loss: 0.0217\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.7401 - val_loss: 2.0860\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.0110 - val_loss: 0.0377\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.0856 - val_loss: 0.1512\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.4754 - val_loss: 3.4557\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3872 - val_loss: 1.2257\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.4297 - val_loss: 3.3426\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.3649 - val_loss: 0.9753\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2787 - val_loss: 1.3543\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 2.5483 - val_loss: 2.7774\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.5503 - val_loss: 3.8285\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1830 - val_loss: 0.2816\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0403 - val_loss: 0.2788\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.2048 - val_loss: 0.1774\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.4998 - val_loss: 0.9831\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.0806 - val_loss: 1.5082\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.2702 - val_loss: 0.8205\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 1.4917 - val_loss: 0.9764\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.0403 - val_loss: 0.1798\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3176 - val_loss: 0.5803\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.0371 - val_loss: 0.2201\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 1.1607 - val_loss: 5.0259\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.5439 - val_loss: 1.9290\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.5652 - val_loss: 0.6136\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4201 - val_loss: 0.1400\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 1.0515 - val_loss: 2.8015\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.0332 - val_loss: 0.3292\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.3454 - val_loss: 0.5934\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0294 - val_loss: 0.3047\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.3282 - val_loss: 1.4712\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.3963 - val_loss: 2.4373\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.5221 - val_loss: 1.8289\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.3072 - val_loss: 0.4876\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 1.8628 - val_loss: 3.8642\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.1151 - val_loss: 0.6670\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.1939 - val_loss: 0.2481\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.0207 - val_loss: 0.0487\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1192 - val_loss: 0.2397\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0332 - val_loss: 0.0401\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0343 - val_loss: 0.1249\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2761 - val_loss: 0.2569\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 1.2820 - val_loss: 0.9459\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.0402 - val_loss: 0.1038\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.1796 - val_loss: 0.3994\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.0310 - val_loss: 0.0999\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.2118 - val_loss: 0.2546\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.0668 - val_loss: 0.1452\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.2705 - val_loss: 2.0988\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.1136 - val_loss: 0.1517\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.7913 - val_loss: 1.6975\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1718 - val_loss: 0.1668\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.0916 - val_loss: 0.1869\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.3209 - val_loss: 2.2639\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.5160 - val_loss: 2.1835\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 1.3481 - val_loss: 3.0993\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.1373 - val_loss: 0.5886\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5630 - val_loss: 0.6075\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.5092 - val_loss: 0.3341\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.1019 - val_loss: 0.2756\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.8595 - val_loss: 1.4778\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0426 - val_loss: 0.3605\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 1.1737 - val_loss: 2.4274\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.2436 - val_loss: 1.7632\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.2204 - val_loss: 1.5603\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.8700 - val_loss: 0.6218\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 1.2361 - val_loss: 1.1484\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.3849 - val_loss: 0.8721\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 1.6099 - val_loss: 0.2422\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.0282 - val_loss: 0.1465\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2008 - val_loss: 1.3270\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1039 - val_loss: 0.2110\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0338 - val_loss: 0.0773\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3013 - val_loss: 0.3036\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 1.7230 - val_loss: 2.3180\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0263 - val_loss: 0.0595\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1237 - val_loss: 0.3488\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6225 - val_loss: 4.8503\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.1568 - val_loss: 0.3806\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1063 - val_loss: 0.5253\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.1017 - val_loss: 0.4349\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2314 - val_loss: 0.3485\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.5050 - val_loss: 0.9192\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.1754 - val_loss: 0.3744\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.4408 - val_loss: 1.6740\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.3450 - val_loss: 3.3732\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2063 - val_loss: 0.9631\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.4070 - val_loss: 7.4902\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.6294 - val_loss: 6.6550\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.6707 - val_loss: 1.0658\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 4.4655 - val_loss: 9.9059\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4356 - val_loss: 1.9740\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.2908 - val_loss: 2.0810\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2214 - val_loss: 1.9097\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1410 - val_loss: 0.0984\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.3430 - val_loss: 2.8446\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 1.0346 - val_loss: 0.5801\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 3.4919 - val_loss: 4.2536\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.0657 - val_loss: 0.9465\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.2653 - val_loss: 0.8045\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 1.5668 - val_loss: 4.5378\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6094 - val_loss: 1.4026\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.9737 - val_loss: 3.7620\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4717 - val_loss: 6.1035\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.1414 - val_loss: 1.1247\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 1.8794 - val_loss: 1.9371\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 3.4854 - val_loss: 6.2253\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4896 - val_loss: 2.5671\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3810 - val_loss: 0.5129\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1199 - val_loss: 0.4117\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.1593 - val_loss: 0.2308\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2592 - val_loss: 0.7017\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.3693 - val_loss: 0.9613\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5740 - val_loss: 0.0587\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 2.1223 - val_loss: 1.3683\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.4974 - val_loss: 0.6103\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.2451 - val_loss: 0.9234\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.0335 - val_loss: 0.1438\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.2012 - val_loss: 0.2714\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2394 - val_loss: 0.7890\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3524 - val_loss: 0.8629\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.5159 - val_loss: 0.8853\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 3.0684 - val_loss: 6.0034\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.3158 - val_loss: 0.5713\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.4150 - val_loss: 0.5427\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.4868 - val_loss: 5.9604\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.2946 - val_loss: 0.5299\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.1929 - val_loss: 1.1000\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.5733 - val_loss: 0.8079\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.7641 - val_loss: 0.8205\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 2.1007 - val_loss: 6.9940\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.0981 - val_loss: 0.0623\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.7361 - val_loss: 0.8412\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.1368 - val_loss: 0.5390\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2602 - val_loss: 0.1597\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2957 - val_loss: 0.7705\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 1.1660 - val_loss: 0.9867\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.3554 - val_loss: 0.5733\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.7304 - val_loss: 0.8853\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.2850 - val_loss: 0.6112\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.3620 - val_loss: 1.0683\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0662 - val_loss: 0.0535\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1864 - val_loss: 0.3262\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.1736 - val_loss: 0.4679\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1090 - val_loss: 0.9887\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2577 - val_loss: 0.4580\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.6333 - val_loss: 0.6541\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1038 - val_loss: 0.3992\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.1795 - val_loss: 0.3541\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.1848 - val_loss: 2.1031\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.0730 - val_loss: 0.2367\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.2955 - val_loss: 1.2373\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.3722 - val_loss: 0.7568\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.1822 - val_loss: 0.0497\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 2.0668 - val_loss: 2.3080\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.0793 - val_loss: 0.4002\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 4.7418 - val_loss: 6.5555\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0512 - val_loss: 0.7571\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.8850 - val_loss: 1.6881\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.2361 - val_loss: 2.3304\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.6099 - val_loss: 3.3325\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 1.2402 - val_loss: 2.8986\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 4.1805 - val_loss: 6.2770\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3803 - val_loss: 0.6197\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.4697 - val_loss: 0.0799\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0610 - val_loss: 0.0415\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.2650 - val_loss: 0.6502\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.2660 - val_loss: 0.2058\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.4129 - val_loss: 1.0949\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4717 - val_loss: 0.3462\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 2.2895 - val_loss: 1.0470\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.2326 - val_loss: 0.9448\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6040 - val_loss: 0.9798\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.0064 - val_loss: 0.0355\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.4662 - val_loss: 1.1197\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.3927 - val_loss: 1.4007\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2509 - val_loss: 0.3070\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 2.4381 - val_loss: 1.9491\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 2.5795 - val_loss: 5.1247\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.1560 - val_loss: 0.1476\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1625 - val_loss: 0.0481\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0743 - val_loss: 0.3650\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3442 - val_loss: 0.5054\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 2.7551 - val_loss: 4.2724\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1291 - val_loss: 0.1227\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 2.3826 - val_loss: 4.8350\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 3.4757 - val_loss: 6.5153\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.1985 - val_loss: 0.2858\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4722 - val_loss: 0.1522\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.0399 - val_loss: 0.1355\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3793 - val_loss: 0.2860\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.5035 - val_loss: 0.6722\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.1052 - val_loss: 1.3446\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 1.3932 - val_loss: 1.0915\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 2.8581 - val_loss: 5.9492\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.6896 - val_loss: 2.4095\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.5724 - val_loss: 0.1156\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.2807 - val_loss: 0.9983\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.3177 - val_loss: 0.1588\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.6109 - val_loss: 0.4906\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4040 - val_loss: 0.5639\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3374 - val_loss: 0.0666\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 2.1553 - val_loss: 0.4289\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.1464 - val_loss: 0.6197\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2733 - val_loss: 0.1708\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.0818 - val_loss: 0.1359\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3359 - val_loss: 0.8590\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4351 - val_loss: 0.9265\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.0853 - val_loss: 0.6331\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.7660 - val_loss: 2.0091\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 1.5512 - val_loss: 0.1046\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.1212 - val_loss: 0.1988\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.1468 - val_loss: 0.4291\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0737 - val_loss: 0.7078\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.2174 - val_loss: 0.2970\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.3301 - val_loss: 2.2870\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0176 - val_loss: 0.7346\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 1.0640 - val_loss: 1.5795\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 1.4780 - val_loss: 1.1181\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2255 - val_loss: 0.4684\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.3147 - val_loss: 0.0980\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3645 - val_loss: 1.7084\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.2507 - val_loss: 0.0389\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 1.4984 - val_loss: 5.1328\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.3793 - val_loss: 0.7816\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.3047 - val_loss: 0.8288\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 2.2563 - val_loss: 4.7394\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.1719 - val_loss: 0.9431\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 1.8338 - val_loss: 1.1049\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.1787 - val_loss: 1.0802\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.9929 - val_loss: 1.5291\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.6631 - val_loss: 0.9513\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6737 - val_loss: 3.7351\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.6973 - val_loss: 0.2726\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 3.4022 - val_loss: 5.6599\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3770 - val_loss: 2.7715\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2546 - val_loss: 0.1625\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.1122 - val_loss: 1.9587\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.4310 - val_loss: 1.7452\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.0552 - val_loss: 0.4344\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0261 - val_loss: 0.0682\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.0742 - val_loss: 0.0442\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 1.7179 - val_loss: 2.0888\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0119 - val_loss: 0.0237\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.0949 - val_loss: 0.0808\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.4315 - val_loss: 3.3020\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.3284 - val_loss: 0.9840\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1702 - val_loss: 2.8416\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4277 - val_loss: 1.1951\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.4106 - val_loss: 1.6174\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7314 - val_loss: 3.4551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5079 - val_loss: 3.6032\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.4698 - val_loss: 0.9941\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.2514 - val_loss: 1.6324\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.1785 - val_loss: 0.1829\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.7366 - val_loss: 1.0295\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3499 - val_loss: 0.6348\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.2327 - val_loss: 0.7067\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.9478 - val_loss: 0.7413\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1915 - val_loss: 0.9160\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.3550 - val_loss: 0.7276\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.0070 - val_loss: 0.0039\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.3518 - val_loss: 2.4435\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.4470 - val_loss: 1.6721\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.1428 - val_loss: 0.2748\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.3025 - val_loss: 0.2500\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 1.0944 - val_loss: 2.3557\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.0618 - val_loss: 0.5222\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.4997 - val_loss: 0.8829\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0798 - val_loss: 0.7040\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.5406 - val_loss: 1.5646\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4980 - val_loss: 2.9985\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2367 - val_loss: 0.7294\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1273 - val_loss: 0.2602\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 2.3284 - val_loss: 1.5617\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1460 - val_loss: 0.6231\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.1653 - val_loss: 0.2462\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.0237 - val_loss: 0.0914\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.1496 - val_loss: 0.3274\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.0487 - val_loss: 0.0837\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.0096 - val_loss: 0.0225\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.2516 - val_loss: 0.2185\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.7783 - val_loss: 0.5899\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.0788 - val_loss: 0.1764\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.1749 - val_loss: 0.4005\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.0353 - val_loss: 0.0551\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.2654 - val_loss: 0.3398\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.0689 - val_loss: 0.1226\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.3159 - val_loss: 2.2467\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.1240 - val_loss: 0.1676\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.7494 - val_loss: 1.4267\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2047 - val_loss: 0.2326\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.1155 - val_loss: 0.1396\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3427 - val_loss: 2.3607\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5654 - val_loss: 2.3373\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 1.2545 - val_loss: 2.8711\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.1319 - val_loss: 0.5702\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.4800 - val_loss: 0.4617\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.5264 - val_loss: 0.3096\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.1252 - val_loss: 0.3035\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.7418 - val_loss: 1.2471\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.0453 - val_loss: 0.3775\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 1.1600 - val_loss: 2.3787\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.2518 - val_loss: 1.7563\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2323 - val_loss: 1.5712\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 1.0388 - val_loss: 0.4974\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.9910 - val_loss: 0.7888\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3859 - val_loss: 0.8406\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.6213 - val_loss: 0.2098\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.0224 - val_loss: 0.1323\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.1715 - val_loss: 1.3319\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.1041 - val_loss: 0.1599\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.0340 - val_loss: 0.0753\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3629 - val_loss: 0.2358\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 1.6681 - val_loss: 1.9809\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0222 - val_loss: 0.0800\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1192 - val_loss: 0.3464\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.6174 - val_loss: 4.7900\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.1555 - val_loss: 0.3846\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.1120 - val_loss: 0.4862\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.1081 - val_loss: 0.4546\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.2264 - val_loss: 0.3589\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.5149 - val_loss: 0.5982\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.1516 - val_loss: 0.3067\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.4796 - val_loss: 1.6723\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3532 - val_loss: 3.4033\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2213 - val_loss: 0.9801\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.4299 - val_loss: 7.5035\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.4476 - val_loss: 5.6188\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.6375 - val_loss: 0.9526\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 4.3153 - val_loss: 7.9289\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.4278 - val_loss: 1.9272\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2490 - val_loss: 2.1595\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2162 - val_loss: 1.8430\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1589 - val_loss: 0.1904\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4478 - val_loss: 3.0696\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.8514 - val_loss: 0.8701\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 3.1098 - val_loss: 4.1574\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 1.1165 - val_loss: 1.4763\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2503 - val_loss: 0.8123\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 1.6819 - val_loss: 4.8698\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6447 - val_loss: 1.4638\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 1.8812 - val_loss: 3.7508\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.5335 - val_loss: 6.2448\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.0994 - val_loss: 0.7676\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 1.9725 - val_loss: 2.0544\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 3.0950 - val_loss: 5.9088\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.4502 - val_loss: 2.3938\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.3454 - val_loss: 0.3438\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.1208 - val_loss: 0.3976\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1633 - val_loss: 0.2444\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2604 - val_loss: 0.6666\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4416 - val_loss: 1.4451\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.5954 - val_loss: 0.0635\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 2.0536 - val_loss: 1.1465\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.4386 - val_loss: 0.4910\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.1611 - val_loss: 1.1571\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0160 - val_loss: 0.0180\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2125 - val_loss: 0.2939\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1911 - val_loss: 0.5265\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3491 - val_loss: 1.6259\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5110 - val_loss: 0.8109\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 2.9894 - val_loss: 5.7283\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.3549 - val_loss: 0.5846\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.4422 - val_loss: 0.6429\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.5118 - val_loss: 5.9860\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.2894 - val_loss: 0.5150\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.1813 - val_loss: 1.3337\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6709 - val_loss: 0.9182\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.6737 - val_loss: 0.7615\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 1.6749 - val_loss: 5.9178\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.1152 - val_loss: 0.1266\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5517 - val_loss: 0.6314\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0975 - val_loss: 0.6830\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2183 - val_loss: 0.1459\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.2654 - val_loss: 0.8155\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.9491 - val_loss: 0.7438\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3555 - val_loss: 0.5834\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.8555 - val_loss: 0.7206\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.3044 - val_loss: 0.6683\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3915 - val_loss: 1.1133\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.0771 - val_loss: 0.0467\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.1778 - val_loss: 0.2669\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.1639 - val_loss: 0.5049\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1281 - val_loss: 0.9647\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2603 - val_loss: 0.3579\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.7355 - val_loss: 0.7075\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.1017 - val_loss: 0.4031\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1965 - val_loss: 0.3673\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.1365 - val_loss: 1.7590\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0580 - val_loss: 0.1599\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2446 - val_loss: 1.0822\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.3618 - val_loss: 0.8473\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.1895 - val_loss: 0.0558\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 2.1130 - val_loss: 2.3746\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0659 - val_loss: 0.3430\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 4.3000 - val_loss: 5.5502\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.0488 - val_loss: 0.7471\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.8291 - val_loss: 1.5859\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2367 - val_loss: 2.6488\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.5490 - val_loss: 2.9370\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 1.2845 - val_loss: 3.0786\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 3.1097 - val_loss: 4.7368\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.4308 - val_loss: 0.7668\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.5384 - val_loss: 0.1249\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.0818 - val_loss: 0.0513\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.3177 - val_loss: 0.6791\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2997 - val_loss: 0.1275\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2828 - val_loss: 0.7860\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.5206 - val_loss: 0.2633\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4452 - val_loss: 0.1950\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1804 - val_loss: 0.9286\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6078 - val_loss: 0.9651\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0175 - val_loss: 0.0532\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4649 - val_loss: 1.1632\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.3699 - val_loss: 1.4691\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0947 - val_loss: 0.4252\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 2.4194 - val_loss: 1.9559\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 2.4382 - val_loss: 3.2613\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1241 - val_loss: 0.1401\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.1376 - val_loss: 0.0687\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.0487 - val_loss: 0.2903\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2558 - val_loss: 0.4010\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 2.8163 - val_loss: 4.3428\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1763 - val_loss: 0.2162\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 2.2017 - val_loss: 4.6042\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 3.4996 - val_loss: 6.2386\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1659 - val_loss: 0.2194\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.4286 - val_loss: 0.1591\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0404 - val_loss: 0.1000\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.3163 - val_loss: 0.2209\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.5785 - val_loss: 0.7426\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.0985 - val_loss: 1.3126\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 1.4513 - val_loss: 1.1619\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 2.9947 - val_loss: 5.4675\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.7244 - val_loss: 2.6407\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6083 - val_loss: 0.1219\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2078 - val_loss: 0.7286\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.3499 - val_loss: 0.2822\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.4639 - val_loss: 0.5262\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.3515 - val_loss: 0.4614\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.3738 - val_loss: 0.1166\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 3.2766 - val_loss: 0.4558\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1208 - val_loss: 0.3535\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3147 - val_loss: 0.2394\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0493 - val_loss: 0.0997\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.2665 - val_loss: 0.8341\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.4621 - val_loss: 0.9489\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.0589 - val_loss: 0.3711\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.8620 - val_loss: 2.0578\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 1.5904 - val_loss: 0.1353\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.1172 - val_loss: 0.2147\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.1716 - val_loss: 0.4442\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.0733 - val_loss: 0.6359\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.2053 - val_loss: 0.2388\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3240 - val_loss: 2.2549\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0450 - val_loss: 0.7823\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.9835 - val_loss: 1.3545\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 1.5498 - val_loss: 1.1803\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2060 - val_loss: 0.3972\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.2613 - val_loss: 0.0843\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.3911 - val_loss: 1.7317\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.2976 - val_loss: 0.0650\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 1.6220 - val_loss: 5.4521\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4017 - val_loss: 0.7908\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.2866 - val_loss: 1.0001\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 2.3887 - val_loss: 5.2872\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.1577 - val_loss: 0.8855\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 1.8580 - val_loss: 1.1487\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.1782 - val_loss: 1.0560\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 2.0159 - val_loss: 1.4950\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6518 - val_loss: 0.9843\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5456 - val_loss: 3.2247\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.7249 - val_loss: 0.2406\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 3.2664 - val_loss: 5.4961\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.4091 - val_loss: 2.4160\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2500 - val_loss: 0.1507\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1151 - val_loss: 2.0075\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4358 - val_loss: 1.7560\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.0491 - val_loss: 0.4601\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0673 - val_loss: 0.1151\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.0689 - val_loss: 0.0411\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 1.6972 - val_loss: 2.0036\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.0134 - val_loss: 0.0295\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1014 - val_loss: 0.0713\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.4034 - val_loss: 3.1378\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.3063 - val_loss: 0.8508\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 1.1099 - val_loss: 2.6101\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4819 - val_loss: 1.3698\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.4931 - val_loss: 1.7976\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 2.7175 - val_loss: 3.9561\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.4749 - val_loss: 3.2966\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.3592 - val_loss: 0.0916\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.0862 - val_loss: 0.1421\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2680 - val_loss: 0.1637\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.4454 - val_loss: 0.9520\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.1153 - val_loss: 1.4773\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.2759 - val_loss: 0.8856\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.5142 - val_loss: 0.2386\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0189 - val_loss: 0.2171\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.2967 - val_loss: 0.6466\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0145 - val_loss: 0.0998\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.4618 - val_loss: 2.9463\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.5065 - val_loss: 1.8397\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2673 - val_loss: 0.5982\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.4237 - val_loss: 0.2944\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 1.0830 - val_loss: 2.2665\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.0737 - val_loss: 0.5092\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5598 - val_loss: 0.8862\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.0834 - val_loss: 0.6602\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.5179 - val_loss: 1.5829\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4837 - val_loss: 2.8976\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2542 - val_loss: 0.9137\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.1581 - val_loss: 0.3081\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 1.6961 - val_loss: 2.1674\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1387 - val_loss: 0.6578\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1382 - val_loss: 0.1929\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.0187 - val_loss: 0.0672\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.1405 - val_loss: 0.2834\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.0397 - val_loss: 0.0419\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.0183 - val_loss: 0.0618\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1783 - val_loss: 0.1262\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.8165 - val_loss: 0.5731\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.0713 - val_loss: 0.1741\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.2065 - val_loss: 0.3996\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.0333 - val_loss: 0.0714\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.3103 - val_loss: 0.3184\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0648 - val_loss: 0.1615\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.2801 - val_loss: 2.0896\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1302 - val_loss: 0.2197\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.7343 - val_loss: 1.4443\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 0.2050 - val_loss: 0.2282\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.0938 - val_loss: 0.1378\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3452 - val_loss: 2.3827\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.5505 - val_loss: 2.2021\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 1.3116 - val_loss: 3.0206\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.1287 - val_loss: 0.4880\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.5073 - val_loss: 0.6026\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.4651 - val_loss: 0.2049\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1281 - val_loss: 0.3020\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.8779 - val_loss: 1.4885\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.0487 - val_loss: 0.3590\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.1235 - val_loss: 2.2853\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2425 - val_loss: 1.6355\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.2353 - val_loss: 1.6157\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.8376 - val_loss: 0.6565\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 1.0388 - val_loss: 0.8900\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4371 - val_loss: 0.9675\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 1.6061 - val_loss: 0.2774\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.0392 - val_loss: 0.1289\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2298 - val_loss: 1.2760\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.1100 - val_loss: 0.2512\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0421 - val_loss: 0.0946\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.2619 - val_loss: 0.3697\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 1.9365 - val_loss: 2.7291\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.0335 - val_loss: 0.0473\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.1484 - val_loss: 0.2962\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6059 - val_loss: 4.8236\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.1598 - val_loss: 0.3625\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.1015 - val_loss: 0.5166\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1260 - val_loss: 0.4964\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2449 - val_loss: 0.3563\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.4557 - val_loss: 0.9341\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.1759 - val_loss: 0.3653\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4078 - val_loss: 1.5807\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.3379 - val_loss: 3.4241\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.2212 - val_loss: 1.0236\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.4602 - val_loss: 7.8676\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.6067 - val_loss: 6.3887\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.7126 - val_loss: 1.2309\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 4.3130 - val_loss: 6.9317\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.4181 - val_loss: 1.9965\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.2936 - val_loss: 2.0531\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2326 - val_loss: 2.0303\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1223 - val_loss: 0.0711\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3520 - val_loss: 2.8771\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 1.0910 - val_loss: 0.5406\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 3.0942 - val_loss: 4.0615\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.9724 - val_loss: 0.8903\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.2907 - val_loss: 0.8946\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 1.6593 - val_loss: 4.6940\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6537 - val_loss: 1.7147\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 1.9928 - val_loss: 3.8210\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5305 - val_loss: 6.2636\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.1063 - val_loss: 1.0547\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 1.9028 - val_loss: 1.9677\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 2.8621 - val_loss: 4.7874\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.4440 - val_loss: 2.4957\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3708 - val_loss: 0.4141\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1203 - val_loss: 0.3224\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1392 - val_loss: 0.1975\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.2438 - val_loss: 0.5883\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4155 - val_loss: 1.0897\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6039 - val_loss: 0.0749\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 2.7404 - val_loss: 1.8966\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4547 - val_loss: 0.5168\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.1941 - val_loss: 1.0474\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.0230 - val_loss: 0.0867\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.2086 - val_loss: 0.2936\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.2180 - val_loss: 0.6510\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3443 - val_loss: 1.2288\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.6018 - val_loss: 1.0565\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 2.7450 - val_loss: 4.6777\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.3315 - val_loss: 0.6165\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.4892 - val_loss: 1.1288\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.4199 - val_loss: 5.2720\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3149 - val_loss: 0.5889\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.1905 - val_loss: 1.0250\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.6295 - val_loss: 0.9021\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5424 - val_loss: 0.6613\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 1.6352 - val_loss: 5.4146\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.1064 - val_loss: 0.0748\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.5993 - val_loss: 0.6840\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.1127 - val_loss: 0.6581\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.2270 - val_loss: 0.1638\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2665 - val_loss: 0.7701\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.9821 - val_loss: 0.7993\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.3157 - val_loss: 0.5232\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.7761 - val_loss: 0.7283\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.3011 - val_loss: 0.6516\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3818 - val_loss: 1.1271\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.0746 - val_loss: 0.0465\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.1845 - val_loss: 0.2913\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.1720 - val_loss: 0.5545\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.1170 - val_loss: 1.0034\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.2566 - val_loss: 0.3923\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6610 - val_loss: 0.5700\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.1059 - val_loss: 0.4228\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.2080 - val_loss: 0.4010\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.1275 - val_loss: 1.6978\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.0553 - val_loss: 0.1517\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2663 - val_loss: 1.1710\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.3373 - val_loss: 0.7254\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.1719 - val_loss: 0.0514\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 1.9616 - val_loss: 2.1919\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.0664 - val_loss: 0.3726\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 4.5434 - val_loss: 5.7161\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.0489 - val_loss: 0.7888\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.9523 - val_loss: 1.8291\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.2435 - val_loss: 2.2331\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4592 - val_loss: 2.6543\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 1.2303 - val_loss: 2.7771\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 3.0682 - val_loss: 4.5739\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.3632 - val_loss: 0.6694\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.4722 - val_loss: 0.0946\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.0758 - val_loss: 0.0509\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.2996 - val_loss: 0.6430\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.3024 - val_loss: 0.1205\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.2677 - val_loss: 0.6925\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4837 - val_loss: 0.1932\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.2626 - val_loss: 0.1462\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.1767 - val_loss: 0.8682\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.6428 - val_loss: 0.9933\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0231 - val_loss: 0.0656\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.4706 - val_loss: 1.1637\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.3712 - val_loss: 1.4956\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.0977 - val_loss: 0.4619\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 2.3894 - val_loss: 1.9461\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 2.5830 - val_loss: 2.2181\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.1253 - val_loss: 0.1588\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.1174 - val_loss: 0.0917\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0354 - val_loss: 0.2297\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.2152 - val_loss: 0.3495\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 2.9095 - val_loss: 4.5859\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.1282 - val_loss: 0.1283\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 1.9770 - val_loss: 4.2936\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 3.0768 - val_loss: 4.8509\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.1398 - val_loss: 0.2107\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.4214 - val_loss: 0.1960\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.0474 - val_loss: 0.1596\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3903 - val_loss: 0.3266\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5146 - val_loss: 0.5908\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.1318 - val_loss: 1.5867\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 1.2010 - val_loss: 0.8861\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 3.0340 - val_loss: 5.5908\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6041 - val_loss: 2.2705\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5222 - val_loss: 0.1372\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.2788 - val_loss: 0.9676\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3042 - val_loss: 0.1702\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5944 - val_loss: 0.5736\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3016 - val_loss: 0.5216\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3759 - val_loss: 0.0796\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 3.2777 - val_loss: 0.5457\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.1387 - val_loss: 0.5288\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.3007 - val_loss: 0.1876\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0670 - val_loss: 0.1198\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2953 - val_loss: 0.8497\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.4859 - val_loss: 1.0094\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.0558 - val_loss: 0.3479\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.7730 - val_loss: 1.8738\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 1.5592 - val_loss: 0.0615\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.1138 - val_loss: 0.2130\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.1457 - val_loss: 0.4176\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.0743 - val_loss: 0.6568\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.2050 - val_loss: 0.2398\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.3195 - val_loss: 2.2215\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0245 - val_loss: 0.8813\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.9744 - val_loss: 1.3473\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 1.5953 - val_loss: 1.3448\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2031 - val_loss: 0.3968\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2335 - val_loss: 0.0699\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4110 - val_loss: 1.8243\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3492 - val_loss: 0.1030\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 1.5218 - val_loss: 5.1277\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2887 - val_loss: 0.8222\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.2926 - val_loss: 0.8614\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 2.0746 - val_loss: 4.0168\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.1574 - val_loss: 0.8553\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.9272 - val_loss: 1.1253\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.1800 - val_loss: 1.0689\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.9800 - val_loss: 1.5476\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.6382 - val_loss: 0.9656\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.6159 - val_loss: 3.5601\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.7096 - val_loss: 0.2394\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 2.8320 - val_loss: 4.5764\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3852 - val_loss: 2.6769\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.2452 - val_loss: 0.1383\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.1177 - val_loss: 2.0324\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4463 - val_loss: 1.7976\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.0436 - val_loss: 0.4488\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.0302 - val_loss: 0.0689\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.0728 - val_loss: 0.0411\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.7611 - val_loss: 2.1909\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.0096 - val_loss: 0.0205\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.1111 - val_loss: 0.0968\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4221 - val_loss: 3.2522\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.3118 - val_loss: 0.8869\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 1.1329 - val_loss: 2.7012\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4726 - val_loss: 1.3464\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.4499 - val_loss: 1.6730\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 2.8641 - val_loss: 3.7972\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5004 - val_loss: 3.5052\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.1658 - val_loss: 0.5171\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 0.0308 - val_loss: 0.6348\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1922 - val_loss: 0.2551\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.7415 - val_loss: 1.3192\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.2848 - val_loss: 1.2742\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.2658 - val_loss: 0.6305\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.5114 - val_loss: 0.3607\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.0901 - val_loss: 0.5624\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.2975 - val_loss: 0.5086\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.0037 - val_loss: 0.0127\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.2735 - val_loss: 2.0311\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5004 - val_loss: 1.8948\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.1205 - val_loss: 0.1945\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.2203 - val_loss: 0.1811\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.2179 - val_loss: 2.7450\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0565 - val_loss: 0.3851\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4763 - val_loss: 0.8726\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.0788 - val_loss: 0.7130\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.5434 - val_loss: 1.5973\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.5268 - val_loss: 3.2138\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.2223 - val_loss: 0.5893\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0837 - val_loss: 0.1749\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.7744 - val_loss: 1.0468\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.1809 - val_loss: 0.5128\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0682 - val_loss: 0.1056\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0050 - val_loss: 0.0241\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.0931 - val_loss: 0.1847\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0324 - val_loss: 0.0308\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 0.0281 - val_loss: 0.0661\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.2308 - val_loss: 0.2423\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.6561 - val_loss: 0.5374\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.0601 - val_loss: 0.1723\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.2240 - val_loss: 0.4644\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.0318 - val_loss: 0.0750\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2724 - val_loss: 0.3184\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0802 - val_loss: 0.0767\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.3007 - val_loss: 2.2380\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1138 - val_loss: 0.1351\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.7644 - val_loss: 1.5481\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.1771 - val_loss: 0.2118\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.1127 - val_loss: 0.2274\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3060 - val_loss: 2.1733\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4957 - val_loss: 2.1024\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 1.3649 - val_loss: 3.1157\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.1246 - val_loss: 0.5010\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.5965 - val_loss: 0.5691\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.4661 - val_loss: 0.2039\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.1047 - val_loss: 0.2826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights\n",
        "model.save_weights('checkpoints/scen1_end_lstm_128_gradual_epochs')"
      ],
      "metadata": {
        "id": "crrrwrakE2Jw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "#### LOAD MODEL ####\n",
        "####################\n",
        "\n",
        "# Define architecture again\n",
        "model1 = keras.Sequential()\n",
        "model1.add(keras.layers.Masking(mask_value=0.0, input_shape=(100, 46)))\n",
        "model1.add(keras.layers.LSTM(units=128))\n",
        "model1.add(keras.layers.Dense(units=2, activation='linear'))\n",
        "\n",
        "# Compile model\n",
        "model1.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Load weights\n",
        "model1.load_weights('checkpoints/scen1_end_lstm_128_gradual_epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKr5tdTEmc0_",
        "outputId": "7ff07bc2-ba4d-40b2-aa03-309c5dc4c63e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 128)\n",
            "(None, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mse_list = []\n",
        "\n",
        "for i in range(240):\n",
        "  mse = model1.evaluate(X_val[i], y_val[i], verbose=2, batch_size=300)\n",
        "  print('Sub #'+str((i-i%8)/8),' Vid #'+str(i%8))\n",
        "  rmse = np.sqrt(mse)\n",
        "  print(\"Model RMSE:\", rmse)\n",
        "  mse_list.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hjBru8f-msRJ",
        "outputId": "c3e574e4-6717-42c7-a4f2-fe334f6e2683"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 1.6619 - 128ms/epoch - 128ms/step\n",
            "Sub #0.0  Vid #0\n",
            "Model RMSE: 1.2891324111013773\n",
            "1/1 - 0s - loss: 0.3211 - 128ms/epoch - 128ms/step\n",
            "Sub #0.0  Vid #1\n",
            "Model RMSE: 0.5666706388932672\n",
            "1/1 - 0s - loss: 2.0603 - 128ms/epoch - 128ms/step\n",
            "Sub #0.0  Vid #2\n",
            "Model RMSE: 1.4353819460422965\n",
            "1/1 - 0s - loss: 1.3378 - 129ms/epoch - 129ms/step\n",
            "Sub #0.0  Vid #3\n",
            "Model RMSE: 1.1566158952939047\n",
            "1/1 - 0s - loss: 1.7211 - 129ms/epoch - 129ms/step\n",
            "Sub #0.0  Vid #4\n",
            "Model RMSE: 1.3119148584919704\n",
            "1/1 - 0s - loss: 0.9915 - 129ms/epoch - 129ms/step\n",
            "Sub #0.0  Vid #5\n",
            "Model RMSE: 0.9957597958109019\n",
            "1/1 - 0s - loss: 0.4816 - 132ms/epoch - 132ms/step\n",
            "Sub #0.0  Vid #6\n",
            "Model RMSE: 0.6939895130513942\n",
            "1/1 - 0s - loss: 1.2735 - 129ms/epoch - 129ms/step\n",
            "Sub #0.0  Vid #7\n",
            "Model RMSE: 1.1285162123232615\n",
            "1/1 - 0s - loss: 0.1944 - 135ms/epoch - 135ms/step\n",
            "Sub #1.0  Vid #0\n",
            "Model RMSE: 0.44092868187817275\n",
            "1/1 - 0s - loss: 0.0767 - 129ms/epoch - 129ms/step\n",
            "Sub #1.0  Vid #1\n",
            "Model RMSE: 0.2769468314850631\n",
            "1/1 - 0s - loss: 1.1495 - 127ms/epoch - 127ms/step\n",
            "Sub #1.0  Vid #2\n",
            "Model RMSE: 1.0721552223944035\n",
            "1/1 - 0s - loss: 0.2444 - 127ms/epoch - 127ms/step\n",
            "Sub #1.0  Vid #3\n",
            "Model RMSE: 0.49432622869114407\n",
            "1/1 - 0s - loss: 0.1031 - 128ms/epoch - 128ms/step\n",
            "Sub #1.0  Vid #4\n",
            "Model RMSE: 0.32112892125320414\n",
            "1/1 - 0s - loss: 0.3201 - 125ms/epoch - 125ms/step\n",
            "Sub #1.0  Vid #5\n",
            "Model RMSE: 0.5657885372995731\n",
            "1/1 - 0s - loss: 3.2767 - 130ms/epoch - 130ms/step\n",
            "Sub #1.0  Vid #6\n",
            "Model RMSE: 1.8101659413137137\n",
            "1/1 - 0s - loss: 0.0326 - 133ms/epoch - 133ms/step\n",
            "Sub #1.0  Vid #7\n",
            "Model RMSE: 0.18042054131056975\n",
            "1/1 - 0s - loss: 0.1755 - 133ms/epoch - 133ms/step\n",
            "Sub #2.0  Vid #0\n",
            "Model RMSE: 0.4188898756788966\n",
            "1/1 - 0s - loss: 4.3125 - 129ms/epoch - 129ms/step\n",
            "Sub #2.0  Vid #1\n",
            "Model RMSE: 2.0766507993227656\n",
            "1/1 - 0s - loss: 0.2133 - 130ms/epoch - 130ms/step\n",
            "Sub #2.0  Vid #2\n",
            "Model RMSE: 0.46186375091956533\n",
            "1/1 - 0s - loss: 0.2919 - 127ms/epoch - 127ms/step\n",
            "Sub #2.0  Vid #3\n",
            "Model RMSE: 0.5402757288178351\n",
            "1/1 - 0s - loss: 0.9932 - 132ms/epoch - 132ms/step\n",
            "Sub #2.0  Vid #4\n",
            "Model RMSE: 0.9965905241017958\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-daf879f39dd3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#model1.reset_states()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sub #'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' Vid #'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2031\u001b[0m                 \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m                 \u001b[0;31m# iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2033\u001b[0;31m                 data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   2034\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2035\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             )\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrab_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# Default optimizations are disabled to avoid the overhead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2238\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     return _ParallelMapDataset(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     concrete_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m    233\u001b[0m         *args, **kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m       func_outputs = nest.map_structure(\n\u001b[0m\u001b[1;32m   1220\u001b[0m           convert, func_outputs, expand_composites=True)\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1175\u001b[0m               \"ExtensionType.\")\n\u001b[1;32m   1176\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mmark_as_return\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# of a new identity operation that the stateful operations definitely don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# depend on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_returned_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4104\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4105\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4106\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   4107\u001b[0m         \"Identity\", input=input, name=name)\n\u001b[1;32m   4108\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    752\u001b[0m   \u001b[0;34m\"\"\"Implementation of apply_op that returns output_structure, op.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m   \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetOpDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mop_type_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_GetOpDef\u001b[0;34m(op_type_name, keywords)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m     \u001b[0mproducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def_versions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgraph_def_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3423\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3424\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3425\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3426\u001b[0m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GraphVersions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3427\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m<\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "### EVALUATE ON VALIDATION SET ###\n",
        "##################################\n",
        "\n",
        "mse_list = []\n",
        "\n",
        "for i in range(240):\n",
        "  model.reset_states()\n",
        "  mse = model.evaluate(X_val[i], y_val[i], verbose=2, batch_size=300)\n",
        "  print('Sub #'+str((i-i%8)/8),' Vid #'+str(i%8))\n",
        "  rmse = np.sqrt(mse)\n",
        "  print(\"Model RMSE:\", rmse)\n",
        "  mse_list.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzfyrQs4DhPc",
        "outputId": "c620ba94-3a1c-48ca-ff31-9d116d3c10be"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 1.6619 - 128ms/epoch - 128ms/step\n",
            "Sub #0.0  Vid #0\n",
            "Model RMSE: 1.2891324111013773\n",
            "1/1 - 0s - loss: 0.3211 - 134ms/epoch - 134ms/step\n",
            "Sub #0.0  Vid #1\n",
            "Model RMSE: 0.5666706388932672\n",
            "1/1 - 0s - loss: 2.0603 - 124ms/epoch - 124ms/step\n",
            "Sub #0.0  Vid #2\n",
            "Model RMSE: 1.4353819460422965\n",
            "1/1 - 0s - loss: 1.3378 - 134ms/epoch - 134ms/step\n",
            "Sub #0.0  Vid #3\n",
            "Model RMSE: 1.1566158952939047\n",
            "1/1 - 0s - loss: 1.7211 - 132ms/epoch - 132ms/step\n",
            "Sub #0.0  Vid #4\n",
            "Model RMSE: 1.3119148584919704\n",
            "1/1 - 0s - loss: 0.9915 - 126ms/epoch - 126ms/step\n",
            "Sub #0.0  Vid #5\n",
            "Model RMSE: 0.9957597958109019\n",
            "1/1 - 0s - loss: 0.4816 - 136ms/epoch - 136ms/step\n",
            "Sub #0.0  Vid #6\n",
            "Model RMSE: 0.6939895130513942\n",
            "1/1 - 0s - loss: 1.2735 - 134ms/epoch - 134ms/step\n",
            "Sub #0.0  Vid #7\n",
            "Model RMSE: 1.1285162123232615\n",
            "1/1 - 0s - loss: 0.1944 - 130ms/epoch - 130ms/step\n",
            "Sub #1.0  Vid #0\n",
            "Model RMSE: 0.44092868187817275\n",
            "1/1 - 0s - loss: 0.0767 - 133ms/epoch - 133ms/step\n",
            "Sub #1.0  Vid #1\n",
            "Model RMSE: 0.2769468314850631\n",
            "1/1 - 0s - loss: 1.1495 - 134ms/epoch - 134ms/step\n",
            "Sub #1.0  Vid #2\n",
            "Model RMSE: 1.0721552223944035\n",
            "1/1 - 0s - loss: 0.2444 - 126ms/epoch - 126ms/step\n",
            "Sub #1.0  Vid #3\n",
            "Model RMSE: 0.49432622869114407\n",
            "1/1 - 0s - loss: 0.1031 - 135ms/epoch - 135ms/step\n",
            "Sub #1.0  Vid #4\n",
            "Model RMSE: 0.32112892125320414\n",
            "1/1 - 0s - loss: 0.3201 - 144ms/epoch - 144ms/step\n",
            "Sub #1.0  Vid #5\n",
            "Model RMSE: 0.5657885372995731\n",
            "1/1 - 0s - loss: 3.2767 - 129ms/epoch - 129ms/step\n",
            "Sub #1.0  Vid #6\n",
            "Model RMSE: 1.8101659413137137\n",
            "1/1 - 0s - loss: 0.0326 - 134ms/epoch - 134ms/step\n",
            "Sub #1.0  Vid #7\n",
            "Model RMSE: 0.18042054131056975\n",
            "1/1 - 0s - loss: 0.1755 - 132ms/epoch - 132ms/step\n",
            "Sub #2.0  Vid #0\n",
            "Model RMSE: 0.4188898756788966\n",
            "1/1 - 0s - loss: 4.3125 - 123ms/epoch - 123ms/step\n",
            "Sub #2.0  Vid #1\n",
            "Model RMSE: 2.0766507993227656\n",
            "1/1 - 0s - loss: 0.2133 - 133ms/epoch - 133ms/step\n",
            "Sub #2.0  Vid #2\n",
            "Model RMSE: 0.46186375091956533\n",
            "1/1 - 0s - loss: 0.2919 - 126ms/epoch - 126ms/step\n",
            "Sub #2.0  Vid #3\n",
            "Model RMSE: 0.5402757288178351\n",
            "1/1 - 0s - loss: 0.9932 - 126ms/epoch - 126ms/step\n",
            "Sub #2.0  Vid #4\n",
            "Model RMSE: 0.9965905241017958\n",
            "1/1 - 0s - loss: 0.2487 - 128ms/epoch - 128ms/step\n",
            "Sub #2.0  Vid #5\n",
            "Model RMSE: 0.49868045972211594\n",
            "1/1 - 0s - loss: 2.3561 - 132ms/epoch - 132ms/step\n",
            "Sub #2.0  Vid #6\n",
            "Model RMSE: 1.5349562808343682\n",
            "1/1 - 0s - loss: 0.1455 - 134ms/epoch - 134ms/step\n",
            "Sub #2.0  Vid #7\n",
            "Model RMSE: 0.3813826072394282\n",
            "1/1 - 0s - loss: 1.3494 - 124ms/epoch - 124ms/step\n",
            "Sub #3.0  Vid #0\n",
            "Model RMSE: 1.1616297140679515\n",
            "1/1 - 0s - loss: 2.4898 - 130ms/epoch - 130ms/step\n",
            "Sub #3.0  Vid #1\n",
            "Model RMSE: 1.5778992746403824\n",
            "1/1 - 0s - loss: 0.6331 - 122ms/epoch - 122ms/step\n",
            "Sub #3.0  Vid #2\n",
            "Model RMSE: 0.7956446705294665\n",
            "1/1 - 0s - loss: 6.9238 - 136ms/epoch - 136ms/step\n",
            "Sub #3.0  Vid #3\n",
            "Model RMSE: 2.631305025300076\n",
            "1/1 - 0s - loss: 9.8615 - 121ms/epoch - 121ms/step\n",
            "Sub #3.0  Vid #4\n",
            "Model RMSE: 3.1403002215173963\n",
            "1/1 - 0s - loss: 0.7735 - 124ms/epoch - 124ms/step\n",
            "Sub #3.0  Vid #5\n",
            "Model RMSE: 0.8795090367285053\n",
            "1/1 - 0s - loss: 13.5033 - 123ms/epoch - 123ms/step\n",
            "Sub #3.0  Vid #6\n",
            "Model RMSE: 3.6746884220413127\n",
            "1/1 - 0s - loss: 1.6251 - 120ms/epoch - 120ms/step\n",
            "Sub #3.0  Vid #7\n",
            "Model RMSE: 1.2747942010428632\n",
            "1/1 - 0s - loss: 1.4869 - 124ms/epoch - 124ms/step\n",
            "Sub #4.0  Vid #0\n",
            "Model RMSE: 1.219402529798239\n",
            "1/1 - 0s - loss: 2.1469 - 122ms/epoch - 122ms/step\n",
            "Sub #4.0  Vid #1\n",
            "Model RMSE: 1.4652247225942565\n",
            "1/1 - 0s - loss: 0.2983 - 120ms/epoch - 120ms/step\n",
            "Sub #4.0  Vid #2\n",
            "Model RMSE: 0.5461358388417592\n",
            "1/1 - 0s - loss: 3.9159 - 130ms/epoch - 130ms/step\n",
            "Sub #4.0  Vid #3\n",
            "Model RMSE: 1.978857645370859\n",
            "1/1 - 0s - loss: 1.6059 - 121ms/epoch - 121ms/step\n",
            "Sub #4.0  Vid #4\n",
            "Model RMSE: 1.2672366959397825\n",
            "1/1 - 0s - loss: 3.4649 - 127ms/epoch - 127ms/step\n",
            "Sub #4.0  Vid #5\n",
            "Model RMSE: 1.8614211164303662\n",
            "1/1 - 0s - loss: 5.6073 - 123ms/epoch - 123ms/step\n",
            "Sub #4.0  Vid #6\n",
            "Model RMSE: 2.367978004933353\n",
            "1/1 - 0s - loss: 0.6045 - 129ms/epoch - 129ms/step\n",
            "Sub #4.0  Vid #7\n",
            "Model RMSE: 0.7775207778018767\n",
            "1/1 - 0s - loss: 4.5370 - 122ms/epoch - 122ms/step\n",
            "Sub #5.0  Vid #0\n",
            "Model RMSE: 2.130024747391333\n",
            "1/1 - 0s - loss: 1.1334 - 120ms/epoch - 120ms/step\n",
            "Sub #5.0  Vid #1\n",
            "Model RMSE: 1.0646068776930628\n",
            "1/1 - 0s - loss: 3.6325 - 131ms/epoch - 131ms/step\n",
            "Sub #5.0  Vid #2\n",
            "Model RMSE: 1.9059226583618187\n",
            "1/1 - 0s - loss: 6.5929 - 130ms/epoch - 130ms/step\n",
            "Sub #5.0  Vid #3\n",
            "Model RMSE: 2.567661483574534\n",
            "1/1 - 0s - loss: 1.8889 - 121ms/epoch - 121ms/step\n",
            "Sub #5.0  Vid #4\n",
            "Model RMSE: 1.3743897297526537\n",
            "1/1 - 0s - loss: 3.2955 - 125ms/epoch - 125ms/step\n",
            "Sub #5.0  Vid #5\n",
            "Model RMSE: 1.8153471453422942\n",
            "1/1 - 0s - loss: 9.5495 - 122ms/epoch - 122ms/step\n",
            "Sub #5.0  Vid #6\n",
            "Model RMSE: 3.0902255240795697\n",
            "1/1 - 0s - loss: 1.2002 - 125ms/epoch - 125ms/step\n",
            "Sub #5.0  Vid #7\n",
            "Model RMSE: 1.095517991145022\n",
            "1/1 - 0s - loss: 0.2141 - 137ms/epoch - 137ms/step\n",
            "Sub #6.0  Vid #0\n",
            "Model RMSE: 0.46271360207411566\n",
            "1/1 - 0s - loss: 0.1353 - 129ms/epoch - 129ms/step\n",
            "Sub #6.0  Vid #1\n",
            "Model RMSE: 0.36780364509625546\n",
            "1/1 - 0s - loss: 0.0272 - 123ms/epoch - 123ms/step\n",
            "Sub #6.0  Vid #2\n",
            "Model RMSE: 0.16493999735816023\n",
            "1/1 - 0s - loss: 0.8749 - 126ms/epoch - 126ms/step\n",
            "Sub #6.0  Vid #3\n",
            "Model RMSE: 0.9353748712923196\n",
            "1/1 - 0s - loss: 3.0703 - 121ms/epoch - 121ms/step\n",
            "Sub #6.0  Vid #4\n",
            "Model RMSE: 1.7522302448793499\n",
            "1/1 - 0s - loss: 0.2943 - 129ms/epoch - 129ms/step\n",
            "Sub #6.0  Vid #5\n",
            "Model RMSE: 0.5424824190147634\n",
            "1/1 - 0s - loss: 0.6942 - 124ms/epoch - 124ms/step\n",
            "Sub #6.0  Vid #6\n",
            "Model RMSE: 0.8331644642119025\n",
            "1/1 - 0s - loss: 1.2935 - 129ms/epoch - 129ms/step\n",
            "Sub #6.0  Vid #7\n",
            "Model RMSE: 1.1373066119453386\n",
            "1/1 - 0s - loss: 0.3516 - 119ms/epoch - 119ms/step\n",
            "Sub #7.0  Vid #0\n",
            "Model RMSE: 0.5929624705428197\n",
            "1/1 - 0s - loss: 0.2501 - 122ms/epoch - 122ms/step\n",
            "Sub #7.0  Vid #1\n",
            "Model RMSE: 0.5001317089177146\n",
            "1/1 - 0s - loss: 1.3397 - 122ms/epoch - 122ms/step\n",
            "Sub #7.0  Vid #2\n",
            "Model RMSE: 1.1574614081324344\n",
            "1/1 - 0s - loss: 1.9505 - 126ms/epoch - 126ms/step\n",
            "Sub #7.0  Vid #3\n",
            "Model RMSE: 1.3966144207777613\n",
            "1/1 - 0s - loss: 2.0482 - 125ms/epoch - 125ms/step\n",
            "Sub #7.0  Vid #4\n",
            "Model RMSE: 1.4311593405983007\n",
            "1/1 - 0s - loss: 2.8110 - 130ms/epoch - 130ms/step\n",
            "Sub #7.0  Vid #5\n",
            "Model RMSE: 1.676605235441257\n",
            "1/1 - 0s - loss: 8.8352 - 121ms/epoch - 121ms/step\n",
            "Sub #7.0  Vid #6\n",
            "Model RMSE: 2.972408088822358\n",
            "1/1 - 0s - loss: 1.1339 - 130ms/epoch - 130ms/step\n",
            "Sub #7.0  Vid #7\n",
            "Model RMSE: 1.064838416687224\n",
            "1/1 - 0s - loss: 0.5663 - 126ms/epoch - 126ms/step\n",
            "Sub #8.0  Vid #0\n",
            "Model RMSE: 0.7524959041952909\n",
            "1/1 - 0s - loss: 4.2012 - 127ms/epoch - 127ms/step\n",
            "Sub #8.0  Vid #1\n",
            "Model RMSE: 2.0496937220589926\n",
            "1/1 - 0s - loss: 0.0429 - 121ms/epoch - 121ms/step\n",
            "Sub #8.0  Vid #2\n",
            "Model RMSE: 0.20723706936963207\n",
            "1/1 - 0s - loss: 1.1619 - 124ms/epoch - 124ms/step\n",
            "Sub #8.0  Vid #3\n",
            "Model RMSE: 1.0779347459190913\n",
            "1/1 - 0s - loss: 3.1537 - 123ms/epoch - 123ms/step\n",
            "Sub #8.0  Vid #4\n",
            "Model RMSE: 1.775873334706513\n",
            "1/1 - 0s - loss: 2.3477 - 127ms/epoch - 127ms/step\n",
            "Sub #8.0  Vid #5\n",
            "Model RMSE: 1.5322269515066826\n",
            "1/1 - 0s - loss: 5.6611 - 131ms/epoch - 131ms/step\n",
            "Sub #8.0  Vid #6\n",
            "Model RMSE: 2.379303897389489\n",
            "1/1 - 0s - loss: 0.1852 - 122ms/epoch - 122ms/step\n",
            "Sub #8.0  Vid #7\n",
            "Model RMSE: 0.43038291144543445\n",
            "1/1 - 0s - loss: 0.2038 - 120ms/epoch - 120ms/step\n",
            "Sub #9.0  Vid #0\n",
            "Model RMSE: 0.4514421916529332\n",
            "1/1 - 0s - loss: 0.8044 - 128ms/epoch - 128ms/step\n",
            "Sub #9.0  Vid #1\n",
            "Model RMSE: 0.8968997566448235\n",
            "1/1 - 0s - loss: 0.1139 - 123ms/epoch - 123ms/step\n",
            "Sub #9.0  Vid #2\n",
            "Model RMSE: 0.33755391493829473\n",
            "1/1 - 0s - loss: 1.0344 - 122ms/epoch - 122ms/step\n",
            "Sub #9.0  Vid #3\n",
            "Model RMSE: 1.0170634720011833\n",
            "1/1 - 0s - loss: 0.8618 - 122ms/epoch - 122ms/step\n",
            "Sub #9.0  Vid #4\n",
            "Model RMSE: 0.928349533921334\n",
            "1/1 - 0s - loss: 0.7722 - 136ms/epoch - 136ms/step\n",
            "Sub #9.0  Vid #5\n",
            "Model RMSE: 0.8787549036901188\n",
            "1/1 - 0s - loss: 3.2928 - 124ms/epoch - 124ms/step\n",
            "Sub #9.0  Vid #6\n",
            "Model RMSE: 1.8146139510937047\n",
            "1/1 - 0s - loss: 0.7593 - 122ms/epoch - 122ms/step\n",
            "Sub #9.0  Vid #7\n",
            "Model RMSE: 0.8714004797673475\n",
            "1/1 - 0s - loss: 1.1402 - 120ms/epoch - 120ms/step\n",
            "Sub #10.0  Vid #0\n",
            "Model RMSE: 1.0678113127878504\n",
            "1/1 - 0s - loss: 0.0245 - 124ms/epoch - 124ms/step\n",
            "Sub #10.0  Vid #1\n",
            "Model RMSE: 0.15659344597647834\n",
            "1/1 - 0s - loss: 0.3130 - 133ms/epoch - 133ms/step\n",
            "Sub #10.0  Vid #2\n",
            "Model RMSE: 0.5594566189769092\n",
            "1/1 - 0s - loss: 0.5947 - 124ms/epoch - 124ms/step\n",
            "Sub #10.0  Vid #3\n",
            "Model RMSE: 0.7711541350276515\n",
            "1/1 - 0s - loss: 1.3792 - 120ms/epoch - 120ms/step\n",
            "Sub #10.0  Vid #4\n",
            "Model RMSE: 1.1743993908276393\n",
            "1/1 - 0s - loss: 0.2747 - 120ms/epoch - 120ms/step\n",
            "Sub #10.0  Vid #5\n",
            "Model RMSE: 0.5241276475678927\n",
            "1/1 - 0s - loss: 2.6527 - 124ms/epoch - 124ms/step\n",
            "Sub #10.0  Vid #6\n",
            "Model RMSE: 1.6287205725212295\n",
            "1/1 - 0s - loss: 0.4910 - 121ms/epoch - 121ms/step\n",
            "Sub #10.0  Vid #7\n",
            "Model RMSE: 0.700684891011702\n",
            "1/1 - 0s - loss: 0.6600 - 121ms/epoch - 121ms/step\n",
            "Sub #11.0  Vid #0\n",
            "Model RMSE: 0.8123991977077262\n",
            "1/1 - 0s - loss: 1.4976 - 124ms/epoch - 124ms/step\n",
            "Sub #11.0  Vid #1\n",
            "Model RMSE: 1.2237569223895877\n",
            "1/1 - 0s - loss: 0.1316 - 121ms/epoch - 121ms/step\n",
            "Sub #11.0  Vid #2\n",
            "Model RMSE: 0.36270343810445815\n",
            "1/1 - 0s - loss: 1.6141 - 120ms/epoch - 120ms/step\n",
            "Sub #11.0  Vid #3\n",
            "Model RMSE: 1.2704701868888209\n",
            "1/1 - 0s - loss: 1.2821 - 122ms/epoch - 122ms/step\n",
            "Sub #11.0  Vid #4\n",
            "Model RMSE: 1.1322996359752031\n",
            "1/1 - 0s - loss: 0.1537 - 126ms/epoch - 126ms/step\n",
            "Sub #11.0  Vid #5\n",
            "Model RMSE: 0.39203401122901554\n",
            "1/1 - 0s - loss: 5.8615 - 121ms/epoch - 121ms/step\n",
            "Sub #11.0  Vid #6\n",
            "Model RMSE: 2.4210576801007355\n",
            "1/1 - 0s - loss: 0.4824 - 122ms/epoch - 122ms/step\n",
            "Sub #11.0  Vid #7\n",
            "Model RMSE: 0.6945262277977254\n",
            "1/1 - 0s - loss: 4.9878 - 125ms/epoch - 125ms/step\n",
            "Sub #12.0  Vid #0\n",
            "Model RMSE: 2.2333418585012\n",
            "1/1 - 0s - loss: 0.4595 - 130ms/epoch - 130ms/step\n",
            "Sub #12.0  Vid #1\n",
            "Model RMSE: 0.677841112158176\n",
            "1/1 - 0s - loss: 2.6063 - 123ms/epoch - 123ms/step\n",
            "Sub #12.0  Vid #2\n",
            "Model RMSE: 1.6143919882654003\n",
            "1/1 - 0s - loss: 1.1807 - 120ms/epoch - 120ms/step\n",
            "Sub #12.0  Vid #3\n",
            "Model RMSE: 1.086617346172876\n",
            "1/1 - 0s - loss: 2.3634 - 131ms/epoch - 131ms/step\n",
            "Sub #12.0  Vid #4\n",
            "Model RMSE: 1.5373346534457553\n",
            "1/1 - 0s - loss: 2.0404 - 121ms/epoch - 121ms/step\n",
            "Sub #12.0  Vid #5\n",
            "Model RMSE: 1.4284274692888403\n",
            "1/1 - 0s - loss: 10.7919 - 123ms/epoch - 123ms/step\n",
            "Sub #12.0  Vid #6\n",
            "Model RMSE: 3.2850971738241297\n",
            "1/1 - 0s - loss: 0.4063 - 119ms/epoch - 119ms/step\n",
            "Sub #12.0  Vid #7\n",
            "Model RMSE: 0.6373958147222154\n",
            "1/1 - 0s - loss: 0.1572 - 128ms/epoch - 128ms/step\n",
            "Sub #13.0  Vid #0\n",
            "Model RMSE: 0.39643314575565725\n",
            "1/1 - 0s - loss: 0.0655 - 124ms/epoch - 124ms/step\n",
            "Sub #13.0  Vid #1\n",
            "Model RMSE: 0.25594527862707894\n",
            "1/1 - 0s - loss: 1.1170 - 122ms/epoch - 122ms/step\n",
            "Sub #13.0  Vid #2\n",
            "Model RMSE: 1.0568923509325137\n",
            "1/1 - 0s - loss: 0.4372 - 123ms/epoch - 123ms/step\n",
            "Sub #13.0  Vid #3\n",
            "Model RMSE: 0.6611951745061415\n",
            "1/1 - 0s - loss: 1.1939 - 125ms/epoch - 125ms/step\n",
            "Sub #13.0  Vid #4\n",
            "Model RMSE: 1.0926735076348788\n",
            "1/1 - 0s - loss: 1.2099 - 122ms/epoch - 122ms/step\n",
            "Sub #13.0  Vid #5\n",
            "Model RMSE: 1.0999772047802043\n",
            "1/1 - 0s - loss: 1.2935 - 124ms/epoch - 124ms/step\n",
            "Sub #13.0  Vid #6\n",
            "Model RMSE: 1.1373076077082604\n",
            "1/1 - 0s - loss: 1.7071 - 122ms/epoch - 122ms/step\n",
            "Sub #13.0  Vid #7\n",
            "Model RMSE: 1.3065777180443956\n",
            "1/1 - 0s - loss: 0.4586 - 122ms/epoch - 122ms/step\n",
            "Sub #14.0  Vid #0\n",
            "Model RMSE: 0.6771732392897759\n",
            "1/1 - 0s - loss: 0.2491 - 122ms/epoch - 122ms/step\n",
            "Sub #14.0  Vid #1\n",
            "Model RMSE: 0.49913341706284453\n",
            "1/1 - 0s - loss: 0.6486 - 122ms/epoch - 122ms/step\n",
            "Sub #14.0  Vid #2\n",
            "Model RMSE: 0.8053836218825203\n",
            "1/1 - 0s - loss: 1.3789 - 123ms/epoch - 123ms/step\n",
            "Sub #14.0  Vid #3\n",
            "Model RMSE: 1.1742810281670646\n",
            "1/1 - 0s - loss: 0.8158 - 120ms/epoch - 120ms/step\n",
            "Sub #14.0  Vid #4\n",
            "Model RMSE: 0.9032288211162969\n",
            "1/1 - 0s - loss: 3.1329 - 125ms/epoch - 125ms/step\n",
            "Sub #14.0  Vid #5\n",
            "Model RMSE: 1.770006398119381\n",
            "1/1 - 0s - loss: 13.1134 - 122ms/epoch - 122ms/step\n",
            "Sub #14.0  Vid #6\n",
            "Model RMSE: 3.621247157660973\n",
            "1/1 - 0s - loss: 0.2987 - 124ms/epoch - 124ms/step\n",
            "Sub #14.0  Vid #7\n",
            "Model RMSE: 0.5465609329838043\n",
            "1/1 - 0s - loss: 0.2574 - 123ms/epoch - 123ms/step\n",
            "Sub #15.0  Vid #0\n",
            "Model RMSE: 0.5073626065898615\n",
            "1/1 - 0s - loss: 0.1868 - 122ms/epoch - 122ms/step\n",
            "Sub #15.0  Vid #1\n",
            "Model RMSE: 0.43225475138341324\n",
            "1/1 - 0s - loss: 0.2118 - 121ms/epoch - 121ms/step\n",
            "Sub #15.0  Vid #2\n",
            "Model RMSE: 0.4602025525253974\n",
            "1/1 - 0s - loss: 5.9415 - 121ms/epoch - 121ms/step\n",
            "Sub #15.0  Vid #3\n",
            "Model RMSE: 2.437518682163732\n",
            "1/1 - 0s - loss: 0.1709 - 121ms/epoch - 121ms/step\n",
            "Sub #15.0  Vid #4\n",
            "Model RMSE: 0.4133920099284463\n",
            "1/1 - 0s - loss: 2.8828 - 122ms/epoch - 122ms/step\n",
            "Sub #15.0  Vid #5\n",
            "Model RMSE: 1.6978684244927957\n",
            "1/1 - 0s - loss: 4.3221 - 126ms/epoch - 126ms/step\n",
            "Sub #15.0  Vid #6\n",
            "Model RMSE: 2.078969224666247\n",
            "1/1 - 0s - loss: 0.0687 - 122ms/epoch - 122ms/step\n",
            "Sub #15.0  Vid #7\n",
            "Model RMSE: 0.26206773293545205\n",
            "1/1 - 0s - loss: 0.9069 - 122ms/epoch - 122ms/step\n",
            "Sub #16.0  Vid #0\n",
            "Model RMSE: 0.9522901850118373\n",
            "1/1 - 0s - loss: 0.1732 - 129ms/epoch - 129ms/step\n",
            "Sub #16.0  Vid #1\n",
            "Model RMSE: 0.41621975972184655\n",
            "1/1 - 0s - loss: 0.3536 - 124ms/epoch - 124ms/step\n",
            "Sub #16.0  Vid #2\n",
            "Model RMSE: 0.5946159823738086\n",
            "1/1 - 0s - loss: 0.6972 - 121ms/epoch - 121ms/step\n",
            "Sub #16.0  Vid #3\n",
            "Model RMSE: 0.8349797832303009\n",
            "1/1 - 0s - loss: 1.6214 - 123ms/epoch - 123ms/step\n",
            "Sub #16.0  Vid #4\n",
            "Model RMSE: 1.2733330713058788\n",
            "1/1 - 0s - loss: 2.2461 - 121ms/epoch - 121ms/step\n",
            "Sub #16.0  Vid #5\n",
            "Model RMSE: 1.4986871696327673\n",
            "1/1 - 0s - loss: 9.1894 - 122ms/epoch - 122ms/step\n",
            "Sub #16.0  Vid #6\n",
            "Model RMSE: 3.031409190608916\n",
            "1/1 - 0s - loss: 3.7302 - 122ms/epoch - 122ms/step\n",
            "Sub #16.0  Vid #7\n",
            "Model RMSE: 1.9313622747580637\n",
            "1/1 - 0s - loss: 0.3915 - 120ms/epoch - 120ms/step\n",
            "Sub #17.0  Vid #0\n",
            "Model RMSE: 0.6256664061206213\n",
            "1/1 - 0s - loss: 1.0347 - 122ms/epoch - 122ms/step\n",
            "Sub #17.0  Vid #1\n",
            "Model RMSE: 1.0171923354542265\n",
            "1/1 - 0s - loss: 0.0974 - 122ms/epoch - 122ms/step\n",
            "Sub #17.0  Vid #2\n",
            "Model RMSE: 0.31206120440372487\n",
            "1/1 - 0s - loss: 0.2781 - 123ms/epoch - 123ms/step\n",
            "Sub #17.0  Vid #3\n",
            "Model RMSE: 0.5273547701213991\n",
            "1/1 - 0s - loss: 0.9679 - 123ms/epoch - 123ms/step\n",
            "Sub #17.0  Vid #4\n",
            "Model RMSE: 0.9838319521823266\n",
            "1/1 - 0s - loss: 0.1869 - 121ms/epoch - 121ms/step\n",
            "Sub #17.0  Vid #5\n",
            "Model RMSE: 0.4322809329098264\n",
            "1/1 - 0s - loss: 2.4486 - 120ms/epoch - 120ms/step\n",
            "Sub #17.0  Vid #6\n",
            "Model RMSE: 1.5648025332053963\n",
            "1/1 - 0s - loss: 0.7480 - 124ms/epoch - 124ms/step\n",
            "Sub #17.0  Vid #7\n",
            "Model RMSE: 0.8648848333482033\n",
            "1/1 - 0s - loss: 0.1815 - 126ms/epoch - 126ms/step\n",
            "Sub #18.0  Vid #0\n",
            "Model RMSE: 0.4260361984324825\n",
            "1/1 - 0s - loss: 0.1638 - 126ms/epoch - 126ms/step\n",
            "Sub #18.0  Vid #1\n",
            "Model RMSE: 0.40466336211458337\n",
            "1/1 - 0s - loss: 0.7430 - 123ms/epoch - 123ms/step\n",
            "Sub #18.0  Vid #2\n",
            "Model RMSE: 0.8619553408062233\n",
            "1/1 - 0s - loss: 0.7856 - 121ms/epoch - 121ms/step\n",
            "Sub #18.0  Vid #3\n",
            "Model RMSE: 0.886352328915263\n",
            "1/1 - 0s - loss: 1.2154 - 122ms/epoch - 122ms/step\n",
            "Sub #18.0  Vid #4\n",
            "Model RMSE: 1.1024611034149217\n",
            "1/1 - 0s - loss: 2.7334 - 123ms/epoch - 123ms/step\n",
            "Sub #18.0  Vid #5\n",
            "Model RMSE: 1.653306396570016\n",
            "1/1 - 0s - loss: 2.1295 - 122ms/epoch - 122ms/step\n",
            "Sub #18.0  Vid #6\n",
            "Model RMSE: 1.4592859245088348\n",
            "1/1 - 0s - loss: 0.1805 - 124ms/epoch - 124ms/step\n",
            "Sub #18.0  Vid #7\n",
            "Model RMSE: 0.42490576933608937\n",
            "1/1 - 0s - loss: 0.4155 - 122ms/epoch - 122ms/step\n",
            "Sub #19.0  Vid #0\n",
            "Model RMSE: 0.6445755914405246\n",
            "1/1 - 0s - loss: 1.0492 - 121ms/epoch - 121ms/step\n",
            "Sub #19.0  Vid #1\n",
            "Model RMSE: 1.0243182869387588\n",
            "1/1 - 0s - loss: 0.5038 - 123ms/epoch - 123ms/step\n",
            "Sub #19.0  Vid #2\n",
            "Model RMSE: 0.7098082492355459\n",
            "1/1 - 0s - loss: 2.6736 - 122ms/epoch - 122ms/step\n",
            "Sub #19.0  Vid #3\n",
            "Model RMSE: 1.6351282225793526\n",
            "1/1 - 0s - loss: 0.4739 - 121ms/epoch - 121ms/step\n",
            "Sub #19.0  Vid #4\n",
            "Model RMSE: 0.6883810856406242\n",
            "1/1 - 0s - loss: 1.6941 - 122ms/epoch - 122ms/step\n",
            "Sub #19.0  Vid #5\n",
            "Model RMSE: 1.3015823417699037\n",
            "1/1 - 0s - loss: 0.8447 - 123ms/epoch - 123ms/step\n",
            "Sub #19.0  Vid #6\n",
            "Model RMSE: 0.9190618621502283\n",
            "1/1 - 0s - loss: 0.7843 - 121ms/epoch - 121ms/step\n",
            "Sub #19.0  Vid #7\n",
            "Model RMSE: 0.8856040905817492\n",
            "1/1 - 0s - loss: 0.0557 - 121ms/epoch - 121ms/step\n",
            "Sub #20.0  Vid #0\n",
            "Model RMSE: 0.23601126907051476\n",
            "1/1 - 0s - loss: 1.5603 - 121ms/epoch - 121ms/step\n",
            "Sub #20.0  Vid #1\n",
            "Model RMSE: 1.2491318549017056\n",
            "1/1 - 0s - loss: 0.0940 - 124ms/epoch - 124ms/step\n",
            "Sub #20.0  Vid #2\n",
            "Model RMSE: 0.3065633980274171\n",
            "1/1 - 0s - loss: 4.8741 - 125ms/epoch - 125ms/step\n",
            "Sub #20.0  Vid #3\n",
            "Model RMSE: 2.2077430320010345\n",
            "1/1 - 0s - loss: 0.6633 - 121ms/epoch - 121ms/step\n",
            "Sub #20.0  Vid #4\n",
            "Model RMSE: 0.814441086202148\n",
            "1/1 - 0s - loss: 0.5293 - 122ms/epoch - 122ms/step\n",
            "Sub #20.0  Vid #5\n",
            "Model RMSE: 0.7275544644972048\n",
            "1/1 - 0s - loss: 5.4035 - 122ms/epoch - 122ms/step\n",
            "Sub #20.0  Vid #6\n",
            "Model RMSE: 2.32454339332637\n",
            "1/1 - 0s - loss: 0.9687 - 123ms/epoch - 123ms/step\n",
            "Sub #20.0  Vid #7\n",
            "Model RMSE: 0.9842424152034541\n",
            "1/1 - 0s - loss: 1.3660 - 126ms/epoch - 126ms/step\n",
            "Sub #21.0  Vid #0\n",
            "Model RMSE: 1.1687474031470513\n",
            "1/1 - 0s - loss: 1.1805 - 124ms/epoch - 124ms/step\n",
            "Sub #21.0  Vid #1\n",
            "Model RMSE: 1.08651493006778\n",
            "1/1 - 0s - loss: 1.7711 - 124ms/epoch - 124ms/step\n",
            "Sub #21.0  Vid #2\n",
            "Model RMSE: 1.3308286635894795\n",
            "1/1 - 0s - loss: 0.5656 - 124ms/epoch - 124ms/step\n",
            "Sub #21.0  Vid #3\n",
            "Model RMSE: 0.7520669429891601\n",
            "1/1 - 0s - loss: 3.7018 - 123ms/epoch - 123ms/step\n",
            "Sub #21.0  Vid #4\n",
            "Model RMSE: 1.9240143196897512\n",
            "1/1 - 0s - loss: 1.0254 - 122ms/epoch - 122ms/step\n",
            "Sub #21.0  Vid #5\n",
            "Model RMSE: 1.0126246222577853\n",
            "1/1 - 0s - loss: 5.5604 - 123ms/epoch - 123ms/step\n",
            "Sub #21.0  Vid #6\n",
            "Model RMSE: 2.3580492349520625\n",
            "1/1 - 0s - loss: 2.9773 - 124ms/epoch - 124ms/step\n",
            "Sub #21.0  Vid #7\n",
            "Model RMSE: 1.7254792003942099\n",
            "1/1 - 0s - loss: 0.1544 - 122ms/epoch - 122ms/step\n",
            "Sub #22.0  Vid #0\n",
            "Model RMSE: 0.3928940863237816\n",
            "1/1 - 0s - loss: 1.7552 - 127ms/epoch - 127ms/step\n",
            "Sub #22.0  Vid #1\n",
            "Model RMSE: 1.324846057226235\n",
            "1/1 - 0s - loss: 1.4493 - 124ms/epoch - 124ms/step\n",
            "Sub #22.0  Vid #2\n",
            "Model RMSE: 1.2038520498780594\n",
            "1/1 - 0s - loss: 0.2697 - 127ms/epoch - 127ms/step\n",
            "Sub #22.0  Vid #3\n",
            "Model RMSE: 0.5193168082844175\n",
            "1/1 - 0s - loss: 0.0497 - 122ms/epoch - 122ms/step\n",
            "Sub #22.0  Vid #4\n",
            "Model RMSE: 0.222829826358115\n",
            "1/1 - 0s - loss: 0.1423 - 124ms/epoch - 124ms/step\n",
            "Sub #22.0  Vid #5\n",
            "Model RMSE: 0.3771760903744788\n",
            "1/1 - 0s - loss: 2.3188 - 123ms/epoch - 123ms/step\n",
            "Sub #22.0  Vid #6\n",
            "Model RMSE: 1.5227519522469506\n",
            "1/1 - 0s - loss: 0.0730 - 125ms/epoch - 125ms/step\n",
            "Sub #22.0  Vid #7\n",
            "Model RMSE: 0.27010654475387136\n",
            "1/1 - 0s - loss: 0.0455 - 122ms/epoch - 122ms/step\n",
            "Sub #23.0  Vid #0\n",
            "Model RMSE: 0.2134183764233435\n",
            "1/1 - 0s - loss: 3.4310 - 125ms/epoch - 125ms/step\n",
            "Sub #23.0  Vid #1\n",
            "Model RMSE: 1.852299089026097\n",
            "1/1 - 0s - loss: 0.7556 - 123ms/epoch - 123ms/step\n",
            "Sub #23.0  Vid #2\n",
            "Model RMSE: 0.8692341272014653\n",
            "1/1 - 0s - loss: 1.7766 - 122ms/epoch - 122ms/step\n",
            "Sub #23.0  Vid #3\n",
            "Model RMSE: 1.3328945461121833\n",
            "1/1 - 0s - loss: 2.3348 - 123ms/epoch - 123ms/step\n",
            "Sub #23.0  Vid #4\n",
            "Model RMSE: 1.5280080457994827\n",
            "1/1 - 0s - loss: 2.5848 - 124ms/epoch - 124ms/step\n",
            "Sub #23.0  Vid #5\n",
            "Model RMSE: 1.6077465966956364\n",
            "1/1 - 0s - loss: 8.8992 - 123ms/epoch - 123ms/step\n",
            "Sub #23.0  Vid #6\n",
            "Model RMSE: 2.983149571504385\n",
            "1/1 - 0s - loss: 2.1356 - 122ms/epoch - 122ms/step\n",
            "Sub #23.0  Vid #7\n",
            "Model RMSE: 1.461373085731386\n",
            "1/1 - 0s - loss: 0.2610 - 124ms/epoch - 124ms/step\n",
            "Sub #24.0  Vid #0\n",
            "Model RMSE: 0.5109015192550975\n",
            "1/1 - 0s - loss: 0.1614 - 124ms/epoch - 124ms/step\n",
            "Sub #24.0  Vid #1\n",
            "Model RMSE: 0.40177582963258834\n",
            "1/1 - 0s - loss: 0.2816 - 124ms/epoch - 124ms/step\n",
            "Sub #24.0  Vid #2\n",
            "Model RMSE: 0.5307052006674587\n",
            "1/1 - 0s - loss: 0.3717 - 121ms/epoch - 121ms/step\n",
            "Sub #24.0  Vid #3\n",
            "Model RMSE: 0.6096919287086177\n",
            "1/1 - 0s - loss: 7.3584 - 123ms/epoch - 123ms/step\n",
            "Sub #24.0  Vid #4\n",
            "Model RMSE: 2.712636805305863\n",
            "1/1 - 0s - loss: 1.1763 - 122ms/epoch - 122ms/step\n",
            "Sub #24.0  Vid #5\n",
            "Model RMSE: 1.0845565797776873\n",
            "1/1 - 0s - loss: 9.4066 - 122ms/epoch - 122ms/step\n",
            "Sub #24.0  Vid #6\n",
            "Model RMSE: 3.067024314453144\n",
            "1/1 - 0s - loss: 1.4786 - 124ms/epoch - 124ms/step\n",
            "Sub #24.0  Vid #7\n",
            "Model RMSE: 1.2159969829597188\n",
            "1/1 - 0s - loss: 0.9136 - 134ms/epoch - 134ms/step\n",
            "Sub #25.0  Vid #0\n",
            "Model RMSE: 0.9558436596275763\n",
            "1/1 - 0s - loss: 0.3986 - 124ms/epoch - 124ms/step\n",
            "Sub #25.0  Vid #1\n",
            "Model RMSE: 0.6313253282226124\n",
            "1/1 - 0s - loss: 1.0662 - 122ms/epoch - 122ms/step\n",
            "Sub #25.0  Vid #2\n",
            "Model RMSE: 1.0325477410794803\n",
            "1/1 - 0s - loss: 1.6582 - 121ms/epoch - 121ms/step\n",
            "Sub #25.0  Vid #3\n",
            "Model RMSE: 1.2877223591312466\n",
            "1/1 - 0s - loss: 0.5514 - 124ms/epoch - 124ms/step\n",
            "Sub #25.0  Vid #4\n",
            "Model RMSE: 0.7425882161200769\n",
            "1/1 - 0s - loss: 0.2332 - 124ms/epoch - 124ms/step\n",
            "Sub #25.0  Vid #5\n",
            "Model RMSE: 0.48290972425173423\n",
            "1/1 - 0s - loss: 8.5218 - 122ms/epoch - 122ms/step\n",
            "Sub #25.0  Vid #6\n",
            "Model RMSE: 2.9192136996574227\n",
            "1/1 - 0s - loss: 0.2137 - 125ms/epoch - 125ms/step\n",
            "Sub #25.0  Vid #7\n",
            "Model RMSE: 0.46226119049147557\n",
            "1/1 - 0s - loss: 0.1785 - 123ms/epoch - 123ms/step\n",
            "Sub #26.0  Vid #0\n",
            "Model RMSE: 0.42244524739229156\n",
            "1/1 - 0s - loss: 0.0422 - 123ms/epoch - 123ms/step\n",
            "Sub #26.0  Vid #1\n",
            "Model RMSE: 0.20551093614847643\n",
            "1/1 - 0s - loss: 1.1102 - 124ms/epoch - 124ms/step\n",
            "Sub #26.0  Vid #2\n",
            "Model RMSE: 1.053682031668078\n",
            "1/1 - 0s - loss: 2.4036 - 126ms/epoch - 126ms/step\n",
            "Sub #26.0  Vid #3\n",
            "Model RMSE: 1.550369323291949\n",
            "1/1 - 0s - loss: 2.9292 - 126ms/epoch - 126ms/step\n",
            "Sub #26.0  Vid #4\n",
            "Model RMSE: 1.7114783699347165\n",
            "1/1 - 0s - loss: 0.6312 - 125ms/epoch - 125ms/step\n",
            "Sub #26.0  Vid #5\n",
            "Model RMSE: 0.7944561768119717\n",
            "1/1 - 0s - loss: 8.1035 - 122ms/epoch - 122ms/step\n",
            "Sub #26.0  Vid #6\n",
            "Model RMSE: 2.8466669569826832\n",
            "1/1 - 0s - loss: 0.8439 - 121ms/epoch - 121ms/step\n",
            "Sub #26.0  Vid #7\n",
            "Model RMSE: 0.9186438817092426\n",
            "1/1 - 0s - loss: 0.3977 - 121ms/epoch - 121ms/step\n",
            "Sub #27.0  Vid #0\n",
            "Model RMSE: 0.630664263808241\n",
            "1/1 - 0s - loss: 0.2282 - 123ms/epoch - 123ms/step\n",
            "Sub #27.0  Vid #1\n",
            "Model RMSE: 0.4777217117839608\n",
            "1/1 - 0s - loss: 0.3329 - 124ms/epoch - 124ms/step\n",
            "Sub #27.0  Vid #2\n",
            "Model RMSE: 0.5770136486997752\n",
            "1/1 - 0s - loss: 0.1994 - 122ms/epoch - 122ms/step\n",
            "Sub #27.0  Vid #3\n",
            "Model RMSE: 0.44650839126087793\n",
            "1/1 - 0s - loss: 0.1635 - 122ms/epoch - 122ms/step\n",
            "Sub #27.0  Vid #4\n",
            "Model RMSE: 0.4043528568743796\n",
            "1/1 - 0s - loss: 0.5705 - 121ms/epoch - 121ms/step\n",
            "Sub #27.0  Vid #5\n",
            "Model RMSE: 0.7553076886997228\n",
            "1/1 - 0s - loss: 1.1968 - 123ms/epoch - 123ms/step\n",
            "Sub #27.0  Vid #6\n",
            "Model RMSE: 1.0939964561718827\n",
            "1/1 - 0s - loss: 0.0786 - 122ms/epoch - 122ms/step\n",
            "Sub #27.0  Vid #7\n",
            "Model RMSE: 0.280295434281321\n",
            "1/1 - 0s - loss: 0.2948 - 123ms/epoch - 123ms/step\n",
            "Sub #28.0  Vid #0\n",
            "Model RMSE: 0.5429452026530429\n",
            "1/1 - 0s - loss: 0.2656 - 123ms/epoch - 123ms/step\n",
            "Sub #28.0  Vid #1\n",
            "Model RMSE: 0.5153858901970532\n",
            "1/1 - 0s - loss: 0.2570 - 121ms/epoch - 121ms/step\n",
            "Sub #28.0  Vid #2\n",
            "Model RMSE: 0.5069474408164227\n",
            "1/1 - 0s - loss: 0.4123 - 122ms/epoch - 122ms/step\n",
            "Sub #28.0  Vid #3\n",
            "Model RMSE: 0.642138507579904\n",
            "1/1 - 0s - loss: 1.8911 - 123ms/epoch - 123ms/step\n",
            "Sub #28.0  Vid #4\n",
            "Model RMSE: 1.375163502075366\n",
            "1/1 - 0s - loss: 0.3709 - 122ms/epoch - 122ms/step\n",
            "Sub #28.0  Vid #5\n",
            "Model RMSE: 0.6090054736541283\n",
            "1/1 - 0s - loss: 1.3084 - 121ms/epoch - 121ms/step\n",
            "Sub #28.0  Vid #6\n",
            "Model RMSE: 1.143870348409308\n",
            "1/1 - 0s - loss: 0.3383 - 124ms/epoch - 124ms/step\n",
            "Sub #28.0  Vid #7\n",
            "Model RMSE: 0.5816057172948792\n",
            "1/1 - 0s - loss: 0.0556 - 124ms/epoch - 124ms/step\n",
            "Sub #29.0  Vid #0\n",
            "Model RMSE: 0.23577152471032845\n",
            "1/1 - 0s - loss: 2.7442 - 123ms/epoch - 123ms/step\n",
            "Sub #29.0  Vid #1\n",
            "Model RMSE: 1.6565699718100306\n",
            "1/1 - 0s - loss: 2.6854 - 123ms/epoch - 123ms/step\n",
            "Sub #29.0  Vid #2\n",
            "Model RMSE: 1.638704247319728\n",
            "1/1 - 0s - loss: 2.6598 - 128ms/epoch - 128ms/step\n",
            "Sub #29.0  Vid #3\n",
            "Model RMSE: 1.6308859086305223\n",
            "1/1 - 0s - loss: 0.4418 - 126ms/epoch - 126ms/step\n",
            "Sub #29.0  Vid #4\n",
            "Model RMSE: 0.6646563399184473\n",
            "1/1 - 0s - loss: 0.4407 - 124ms/epoch - 124ms/step\n",
            "Sub #29.0  Vid #5\n",
            "Model RMSE: 0.6638700767425038\n",
            "1/1 - 0s - loss: 0.2073 - 124ms/epoch - 124ms/step\n",
            "Sub #29.0  Vid #6\n",
            "Model RMSE: 0.45526099726022357\n",
            "1/1 - 0s - loss: 0.2826 - 122ms/epoch - 122ms/step\n",
            "Sub #29.0  Vid #7\n",
            "Model RMSE: 0.5316111234822228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(np.mean(mse_list)) # RMSE for validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tptL2Tn6Xfgd",
        "outputId": "0166d22b-40af-46e7-8d67-b990cd51b9ef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.318983333146173"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "#### PREDICT TEST VALENCE AND AROUSAL ####\n",
        "##########################################\n",
        "preds_dict = []\n",
        "\n",
        "time = np.arange(10000, 40050, 50)\n",
        "\n",
        "for i in range(240):\n",
        "  sub_no = sub_list_train[int((i-i%8)/8)]\n",
        "  vid_no = vid_list_train[int(i%8)]\n",
        "\n",
        "  print('Subject ', sub_no,'; vid ',vid_no)\n",
        "\n",
        "  preds = model1.predict_on_batch(X_test[i])\n",
        "\n",
        "  df = pd.DataFrame(np.column_stack((time,preds)))\n",
        "\n",
        "  df.columns = ['time','valence','arousal']\n",
        "\n",
        "\n",
        "  filename = 'data/scenario_1/test/annotations/sub_'+ str(sub_no) + '_vid_' + str(vid_no) + '.csv'\n",
        "  df.to_csv(filename, index=False)\n",
        "  #break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCMXg47mDKmJ",
        "outputId": "75690f53-a60c-4f82-b975-67b176ed428a"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject  1 ; vid  1\n",
            "Subject  1 ; vid  9\n",
            "Subject  1 ; vid  10\n",
            "Subject  1 ; vid  11\n",
            "Subject  1 ; vid  13\n",
            "Subject  1 ; vid  14\n",
            "Subject  1 ; vid  18\n",
            "Subject  1 ; vid  20\n",
            "Subject  4 ; vid  1\n",
            "Subject  4 ; vid  9\n",
            "Subject  4 ; vid  10\n",
            "Subject  4 ; vid  11\n",
            "Subject  4 ; vid  13\n",
            "Subject  4 ; vid  14\n",
            "Subject  4 ; vid  18\n",
            "Subject  4 ; vid  20\n",
            "Subject  6 ; vid  1\n",
            "Subject  6 ; vid  9\n",
            "Subject  6 ; vid  10\n",
            "Subject  6 ; vid  11\n",
            "Subject  6 ; vid  13\n",
            "Subject  6 ; vid  14\n",
            "Subject  6 ; vid  18\n",
            "Subject  6 ; vid  20\n",
            "Subject  7 ; vid  1\n",
            "Subject  7 ; vid  9\n",
            "Subject  7 ; vid  10\n",
            "Subject  7 ; vid  11\n",
            "Subject  7 ; vid  13\n",
            "Subject  7 ; vid  14\n",
            "Subject  7 ; vid  18\n",
            "Subject  7 ; vid  20\n",
            "Subject  8 ; vid  1\n",
            "Subject  8 ; vid  9\n",
            "Subject  8 ; vid  10\n",
            "Subject  8 ; vid  11\n",
            "Subject  8 ; vid  13\n",
            "Subject  8 ; vid  14\n",
            "Subject  8 ; vid  18\n",
            "Subject  8 ; vid  20\n",
            "Subject  9 ; vid  1\n",
            "Subject  9 ; vid  9\n",
            "Subject  9 ; vid  10\n",
            "Subject  9 ; vid  11\n",
            "Subject  9 ; vid  13\n",
            "Subject  9 ; vid  14\n",
            "Subject  9 ; vid  18\n",
            "Subject  9 ; vid  20\n",
            "Subject  11 ; vid  1\n",
            "Subject  11 ; vid  9\n",
            "Subject  11 ; vid  10\n",
            "Subject  11 ; vid  11\n",
            "Subject  11 ; vid  13\n",
            "Subject  11 ; vid  14\n",
            "Subject  11 ; vid  18\n",
            "Subject  11 ; vid  20\n",
            "Subject  12 ; vid  1\n",
            "Subject  12 ; vid  9\n",
            "Subject  12 ; vid  10\n",
            "Subject  12 ; vid  11\n",
            "Subject  12 ; vid  13\n",
            "Subject  12 ; vid  14\n",
            "Subject  12 ; vid  18\n",
            "Subject  12 ; vid  20\n",
            "Subject  13 ; vid  1\n",
            "Subject  13 ; vid  9\n",
            "Subject  13 ; vid  10\n",
            "Subject  13 ; vid  11\n",
            "Subject  13 ; vid  13\n",
            "Subject  13 ; vid  14\n",
            "Subject  13 ; vid  18\n",
            "Subject  13 ; vid  20\n",
            "Subject  14 ; vid  1\n",
            "Subject  14 ; vid  9\n",
            "Subject  14 ; vid  10\n",
            "Subject  14 ; vid  11\n",
            "Subject  14 ; vid  13\n",
            "Subject  14 ; vid  14\n",
            "Subject  14 ; vid  18\n",
            "Subject  14 ; vid  20\n",
            "Subject  17 ; vid  1\n",
            "Subject  17 ; vid  9\n",
            "Subject  17 ; vid  10\n",
            "Subject  17 ; vid  11\n",
            "Subject  17 ; vid  13\n",
            "Subject  17 ; vid  14\n",
            "Subject  17 ; vid  18\n",
            "Subject  17 ; vid  20\n",
            "Subject  18 ; vid  1\n",
            "Subject  18 ; vid  9\n",
            "Subject  18 ; vid  10\n",
            "Subject  18 ; vid  11\n",
            "Subject  18 ; vid  13\n",
            "Subject  18 ; vid  14\n",
            "Subject  18 ; vid  18\n",
            "Subject  18 ; vid  20\n",
            "Subject  19 ; vid  1\n",
            "Subject  19 ; vid  9\n",
            "Subject  19 ; vid  10\n",
            "Subject  19 ; vid  11\n",
            "Subject  19 ; vid  13\n",
            "Subject  19 ; vid  14\n",
            "Subject  19 ; vid  18\n",
            "Subject  19 ; vid  20\n",
            "Subject  20 ; vid  1\n",
            "Subject  20 ; vid  9\n",
            "Subject  20 ; vid  10\n",
            "Subject  20 ; vid  11\n",
            "Subject  20 ; vid  13\n",
            "Subject  20 ; vid  14\n",
            "Subject  20 ; vid  18\n",
            "Subject  20 ; vid  20\n",
            "Subject  22 ; vid  1\n",
            "Subject  22 ; vid  9\n",
            "Subject  22 ; vid  10\n",
            "Subject  22 ; vid  11\n",
            "Subject  22 ; vid  13\n",
            "Subject  22 ; vid  14\n",
            "Subject  22 ; vid  18\n",
            "Subject  22 ; vid  20\n",
            "Subject  26 ; vid  1\n",
            "Subject  26 ; vid  9\n",
            "Subject  26 ; vid  10\n",
            "Subject  26 ; vid  11\n",
            "Subject  26 ; vid  13\n",
            "Subject  26 ; vid  14\n",
            "Subject  26 ; vid  18\n",
            "Subject  26 ; vid  20\n",
            "Subject  28 ; vid  1\n",
            "Subject  28 ; vid  9\n",
            "Subject  28 ; vid  10\n",
            "Subject  28 ; vid  11\n",
            "Subject  28 ; vid  13\n",
            "Subject  28 ; vid  14\n",
            "Subject  28 ; vid  18\n",
            "Subject  28 ; vid  20\n",
            "Subject  29 ; vid  1\n",
            "Subject  29 ; vid  9\n",
            "Subject  29 ; vid  10\n",
            "Subject  29 ; vid  11\n",
            "Subject  29 ; vid  13\n",
            "Subject  29 ; vid  14\n",
            "Subject  29 ; vid  18\n",
            "Subject  29 ; vid  20\n",
            "Subject  30 ; vid  1\n",
            "Subject  30 ; vid  9\n",
            "Subject  30 ; vid  10\n",
            "Subject  30 ; vid  11\n",
            "Subject  30 ; vid  13\n",
            "Subject  30 ; vid  14\n",
            "Subject  30 ; vid  18\n",
            "Subject  30 ; vid  20\n",
            "Subject  31 ; vid  1\n",
            "Subject  31 ; vid  9\n",
            "Subject  31 ; vid  10\n",
            "Subject  31 ; vid  11\n",
            "Subject  31 ; vid  13\n",
            "Subject  31 ; vid  14\n",
            "Subject  31 ; vid  18\n",
            "Subject  31 ; vid  20\n",
            "Subject  32 ; vid  1\n",
            "Subject  32 ; vid  9\n",
            "Subject  32 ; vid  10\n",
            "Subject  32 ; vid  11\n",
            "Subject  32 ; vid  13\n",
            "Subject  32 ; vid  14\n",
            "Subject  32 ; vid  18\n",
            "Subject  32 ; vid  20\n",
            "Subject  33 ; vid  1\n",
            "Subject  33 ; vid  9\n",
            "Subject  33 ; vid  10\n",
            "Subject  33 ; vid  11\n",
            "Subject  33 ; vid  13\n",
            "Subject  33 ; vid  14\n",
            "Subject  33 ; vid  18\n",
            "Subject  33 ; vid  20\n",
            "Subject  34 ; vid  1\n",
            "Subject  34 ; vid  9\n",
            "Subject  34 ; vid  10\n",
            "Subject  34 ; vid  11\n",
            "Subject  34 ; vid  13\n",
            "Subject  34 ; vid  14\n",
            "Subject  34 ; vid  18\n",
            "Subject  34 ; vid  20\n",
            "Subject  35 ; vid  1\n",
            "Subject  35 ; vid  9\n",
            "Subject  35 ; vid  10\n",
            "Subject  35 ; vid  11\n",
            "Subject  35 ; vid  13\n",
            "Subject  35 ; vid  14\n",
            "Subject  35 ; vid  18\n",
            "Subject  35 ; vid  20\n",
            "Subject  36 ; vid  1\n",
            "Subject  36 ; vid  9\n",
            "Subject  36 ; vid  10\n",
            "Subject  36 ; vid  11\n",
            "Subject  36 ; vid  13\n",
            "Subject  36 ; vid  14\n",
            "Subject  36 ; vid  18\n",
            "Subject  36 ; vid  20\n",
            "Subject  37 ; vid  1\n",
            "Subject  37 ; vid  9\n",
            "Subject  37 ; vid  10\n",
            "Subject  37 ; vid  11\n",
            "Subject  37 ; vid  13\n",
            "Subject  37 ; vid  14\n",
            "Subject  37 ; vid  18\n",
            "Subject  37 ; vid  20\n",
            "Subject  38 ; vid  1\n",
            "Subject  38 ; vid  9\n",
            "Subject  38 ; vid  10\n",
            "Subject  38 ; vid  11\n",
            "Subject  38 ; vid  13\n",
            "Subject  38 ; vid  14\n",
            "Subject  38 ; vid  18\n",
            "Subject  38 ; vid  20\n",
            "Subject  41 ; vid  1\n",
            "Subject  41 ; vid  9\n",
            "Subject  41 ; vid  10\n",
            "Subject  41 ; vid  11\n",
            "Subject  41 ; vid  13\n",
            "Subject  41 ; vid  14\n",
            "Subject  41 ; vid  18\n",
            "Subject  41 ; vid  20\n",
            "Subject  43 ; vid  1\n",
            "Subject  43 ; vid  9\n",
            "Subject  43 ; vid  10\n",
            "Subject  43 ; vid  11\n",
            "Subject  43 ; vid  13\n",
            "Subject  43 ; vid  14\n",
            "Subject  43 ; vid  18\n",
            "Subject  43 ; vid  20\n",
            "Subject  45 ; vid  1\n",
            "Subject  45 ; vid  9\n",
            "Subject  45 ; vid  10\n",
            "Subject  45 ; vid  11\n",
            "Subject  45 ; vid  13\n",
            "Subject  45 ; vid  14\n",
            "Subject  45 ; vid  18\n",
            "Subject  45 ; vid  20\n"
          ]
        }
      ]
    }
  ]
}